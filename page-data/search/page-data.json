{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\n## ë“¤ì–´ê°€ë©°\në¨¸ì‹  ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•  ë•Œ ê¸€ë¡œë²Œ ìƒìˆ˜(constants)ë¥¼ ì •ì˜í•´ì•¼ í•  ì¼ì´ ìƒê¸´ë‹¤. ì˜ˆë¥¼ ë“¤ë©´ ì‹œí€€ìŠ¤ ë°ì´í„°ì˜ ê²½ìš° ìµœëŒ€ ê¸¸ì´ `max_length`ë¥¼ ì„¤ì •í•˜ê³  ë°ì´í„°ë¥¼ ì¡°ê±´ì— ë”°ë¼ ì„¤ì •í•´ë‘” ìµœëŒ€ ê¸¸ì´ë¡œ ìë¥¸ë‹¤(truncate)ë˜ì§€ vocabulary íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³  ë˜ ê²°ê³¼ê°’ì„ ì €ì¥í•  íŒŒì¼ ê²½ë¡œë¥¼ ì„¤ì •í•´ë‘”ë‹¤ë˜ì§€ í•˜ëŠ” ê²ƒì´ë‹¤. ë” ë³´í¸ì ìœ¼ë¡œëŠ” í•™ìŠµì„ ìœ„í•œ `batch_size`ê³¼ `epoch`ë¥¼ ì •í•´ë‘˜ í•„ìš”ê°€ ìˆë‹¤. ì—¬ëŸ¬ ë…¸íŠ¸ë¶ì—ì„œ ì´ëŸ° ì„¤ì •ê°’(configuration)ë“¤ì´ ë§ì•„ì§ˆ ê²½ìš° 1ï¸âƒ£class í˜•íƒœë¡œ ì €ì¥í•´ë‘ê³  ë¶ˆëŸ¬ì„œ ì“°ê±°ë‚˜ 2ï¸âƒ£parserë¡œ ì²˜ë¦¬í•˜ëŠ” ê²½ìš°ë¥¼ ë³´ì•˜ëŠ”ë° í›„ìì˜ ê²½ìš°ëŠ” ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»í•˜ê³  ìˆì—ˆë‹¤. ê·¸ëŸ¬ë‹¤ê°€ Pythonì˜ ë‚´ì¥ íŒ¨í‚¤ì§€ì¸ `configparser`ë¥¼ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ì˜ìƒì„ ì°¾ì•„ ë°°ìš´ ì ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤.\n\n> [configparserì— ëŒ€í•œ ì¹œì ˆí•œ ì„¤ëª… ì˜ìƒ & ê¸€ ë³´ê¸°](https://kishstats.com/python/2018/03/07/python-config-parser.html)\n\n## configparser í™œìš©í•˜ê¸°\n\n### 1. Config íŒŒì¼ ì“°ê¸°\n\nê°€ì¥ ë¨¼ì € í•  ì¼ì€ `ConfigParser` ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤.\n```python\nfrom configparser import ConfigParser\n\nconfig = ConfigParser()\n```\n\në‹¤ìŒê³¼ ê°™ì´ `section`ê³¼ `option`ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.\n- config['option_name'] = { 'option_name': value }\n\n```python\n# section for settings\nconfig['settings'] = {\n    # config options of settings section.\n    'debug': 'true',\n    'secret_key': 'abc123',\n    'log_path': '/my_app/log'\n}\n\n# section for database\nconfig['db'] = {\n    'db_name': 'myapp_dev',\n    'db_host': 'localhost',\n    'db_port': '8889'\n}\n\n# section for files\nconfig['files'] = {\n    'use_cdn': 'false',\n    'images_path': '/my_app/images'\n}\n```\n\nconfiguration ê°ì²´ì— ë‚´ìš© ì‘ì„±ì„ ëë‚´ë©´ íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•´ íŒŒì¼ í˜•íƒœë¡œ ì €ì¥í•œë‹¤.\n```python\n# write a config file \nwith open('./dev.ini', 'w') as f:\n      config.write(f)\n```\n\n### 2. Config íŒŒì¼ ì½ê¸°\n\në§ˆì°¬ê°€ì§€ë¡œ ê°ì²´ë¥¼ ìƒì„±í•œ í›„, ì €ì¥í•œ Config íŒŒì¼ì„ ì½ì–´ë“¤ì¸ë‹¤.\n- parser.read('file_name')\n\n```python\nfrom configparser import ConfigParser\n\nparser = ConfigParser()\nparser.read('dev.ini')\n```\n\ní•„ìš”í•œ ì„¹ì…˜ê³¼ íŒŒì¼ì„ ë‹¤ìŒê³¼ ê°™ì´ ì½ì„ ìˆ˜ ìˆë‹¤.\n- parser.sections()\n- parser.options('section_name')\n- parser.get('section_name', 'option_name')\n\n```python\nprint(parser.sections())  # ['settings', 'db', 'files']\nprint(parser.options('settings'))  # ['debug', 'secret_key', 'log_path']\nprint(parser.get('settings', 'secret_key'))  # abc123\nprint('db' in parser)  # True\n```\n\níŠ¹ì • ìë£Œê°’ìœ¼ë¡œ ë°”ë¡œ ì½ì–´ë“¤ì¼ ìˆ˜ ìˆëŠ” í•¨ìˆ˜ê°€ ìˆë‹¤.\n- parser.getint()\n- parser.getfloat()\n- parser.getboolean()\n\nì´ í•¨ìˆ˜ë“¤ì˜ ì¸ìë¡œ `fallback`ì„ ì„¤ì •í•  ìˆ˜ ìˆëŠ”ë°, ì½ì–´ë“¤ì´ë ¤ëŠ” ê°’ì´ parser ë‚´ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° default ê°’ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ê°’ì´ë‹¤. ì´ë¦„ì²˜ëŸ¼ Python `dict`ì—ì„œ `get(key, (default_value))` í•¨ìˆ˜ë¥¼ ì“°ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•˜ë‹¤. (ê±°ì˜ ê°™ë‹¤.)\n\n```python\nprint(parser.get('db', 'db_port'), type(parser.get('db', 'db_port')))  # 8889 <class 'str'>\nprint(int(parser.get('db', 'db_port')))  # 8889 (as int)\nprint(parser.getint('db', 'db_default_port')) # 8889 (as int)\nprint(parser.getint('db', 'db_default_port', fallback=3306))  # 3306\n```\n\n## 3. String Interpolation ì‚¬ìš©í•˜ê¸°\n\nì˜ˆë¥¼ ë“¤ì–´ì„œ configë¥¼ ì„¤ì •í•˜ëŠ” ë„ì¤‘ì— ë‹¤ë¥¸ sectionì˜ optionì˜ ê°’ì„ ë¶ˆëŸ¬ì™€ì„œ ë¬¸ìì—´ ì•ˆì—ì„œ í™œìš©í•˜ê³  ì‹¶ë‹¤ë©´ `ConfigParser()`ê°€ ë¬¸ìì—´ì„ í•´ì„í•˜ë„ë¡ ì¸ìë¥¼ ì „ë‹¬í•´ì•¼ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ `settings` sectionì— ìˆëŠ” optionê°’ì„ `files` sectionì—ì„œ ì´ìš©í•˜ê³ ì í•œë‹¤. \n\n- '${section_name : option_name}other_strings'\n\n```python\nfrom configparser import ConfigParser\n\nconfig = ConfigParser()\n\nconfig['settings'] = {\n    'debug': 'true',\n    'secret_key': 'abc123',\n    'log_path': '/my_app/log',\n    'python_version': '3',\n    'packages_path': '/usr/local'\n}\n\n# ...\n\nconfig['files'] = {\n    'use_cdn': 'false',\n    'images_path': '/my_app/images',\n    'python_path': '${settings:packages_path}/bin/python${settings:python_version}'\n}\n```\n\nê·¸ëŸ¬ë©´ Config íŒŒì¼ì„ ì½ì„ ë•Œ ë¬¸ìì—´ì„ í•´ì„í•  ìˆ˜ ìˆë„ë¡ `ConfigParser`ì— ì¸ì `ExtendedInterpolation()`ì„ ì „ë‹¬í•œë‹¤. (method callì´ ë˜ì–´ì•¼ í•œë‹¤.)\n\n```python\nfrom configparser import ConfigParser, ExtendedInterpolation\n\nparser = ConfigParser(interpolation=ExtendedInterpolation())\nparser.read('dev.ini')\n\nprint(parser.get('files', 'python_path'))  # /usr/local/bin/python3\n```\n\n> [More about Interpolation on Python docs](https://docs.python.org/ko/3/library/configparser.html#interpolation-of-values)\n\n\n## ë‚˜ê°€ë©°\n`ConfigParser`ì—ì„œ `section`ì´ë‚˜ `option`ì„ ì½ì–´ë“¤ì´ëŠ” ê²ƒì€ Pandasë¡œ `DataFrame`ì˜ `index`ì™€ `column`ì„ ì½ì–´ë“¤ì´ëŠ” ê²ƒê³¼ ë¹„ìŠ·í–ˆë‹¤. ìƒˆë¡œìš´ ë‚´ìš©ì„ ì´í•´í•˜ëŠ”ë°ì— ê¸°ì¡´ì˜ ì§€ì‹ì´ ë„ì›€ì´ ë˜ê³  ìˆë‹¤. ì´ ê¸°ëŠ¥ì€ íŠ¹íˆ ì•± ê°œë°œì—ì„œ ì„¤ì •ê°’ì„ ëª¨ì•„ë‘ê¸° ìœ„í•´ ìœ ìš©í•˜ê²Œ ì“°ì¼ ê²ƒ ê°™ë‹¤. \n\nì‚¬ì‹¤ parserëŠ” ì—¬ëŸ¬ê°€ì§€ê°€ ìˆëŠ”ë°: `parser`, `argparse`, `configparser` ë“±ì´ ìˆë‹¤. ë‹¤ìŒ ê¸°íšŒì—ëŠ” `argparse`ì— ëŒ€í•´ ì•Œì•„ë³´ê³ , scriptë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ê³ ì í•œë‹¤.\n\n## ì°¸ê³  ìë£Œ\n1. KishStats blog, https://kishstats.com/python/2018/03/07/python-config-parser.html\n2. Python docs, https://docs.python.org/ko/3/library/configparser.html#interpolation-of-values","excerpt":"ë“¤ì–´ê°€ë©° ë¨¸ì‹  ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•  ë•Œ ê¸€ë¡œë²Œ ìƒìˆ˜(constants)ë¥¼ ì •ì˜í•´ì•¼ í•  ì¼ì´ ìƒê¸´ë‹¤. ì˜ˆë¥¼ ë“¤ë©´ ì‹œí€€ìŠ¤ ë°ì´í„°ì˜ ê²½ìš° ìµœëŒ€ ê¸¸ì´ ë¥¼ ì„¤ì •í•˜ê³  ë°ì´í„°ë¥¼ ì¡°ê±´ì— ë”°ë¼ ì„¤ì •í•´ë‘” ìµœëŒ€ ê¸¸ì´ë¡œ ìë¥¸ë‹¤(truncate)ë˜ì§€ vocabulary â€¦","fields":{"slug":"/parser_1/"},"frontmatter":{"date":"Apr 11, 2022","title":"configparser","tags":["Python","Machine Learning"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n### ë¬¸ì œ ë§í¬ â™Ÿ\n> [LeetCode, 51. N-Queens I](https://leetcode.com/problems/n-queens/)\n\n> [LeetCode, 52. N-Queens II](https://leetcode.com/problems/n-queens-ii/)\n\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n\nì²´ìŠ¤ ë³´ë“œëŠ” `8 x 8` í¬ê¸°ì´ë¯€ë¡œ ë³¸ë˜ëŠ” 8-Queen ë¬¸ì œì˜€ìœ¼ë‚˜, ì´ ë¬¸ì œë“¤ì€ `8`ì„ `n`ìœ¼ë¡œ ë°”ê¾¸ì–´ ë¬¸ì œë¥¼ í•œë‹¨ê³„ ë” ì¶”ìƒí™”í–ˆë‹¤.\n\n51ë²ˆì€ `n x n` ë³´ë“œì— `n`ê°œì˜ ì²´ìŠ¤ í€¸ì„ ìœ„ì¹˜í•˜ëŠ” ëª¨ë“  ë°©ë²•ì„ ì¶œë ¥í•˜ëŠ” ë¬¸ì œì´ê³ , 52ë²ˆì€ ê°™ì€ ì„¤ì •ì—ì„œ í€¸ì„ ìœ„ì¹˜í•˜ëŠ” ë°©ë²•ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ëŠ” ë¬¸ì œì´ë‹¤. ì¦‰, 51ë²ˆì—ì„œ í–‰ë ¬ì„ ì§ì ‘ ì¶œë ¥í•´ì•¼ í•œë‹¤ëŠ” ì ì„ ë¹¼ë©´ ì™„ì „íˆ ê°™ì€ ë¬¸ì œì´ë‹¤.\n\nì´ ê¸€ì—ì„œëŠ” **backtracking**ìœ¼ë¡œ n-í€¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•˜ê³ ì í•œë‹¤. \n\n ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” í€¸ë“¤ì´ ìœ„ì¹˜í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ì§€ì ì„ íƒìƒ‰í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ ì²´ìŠ¤ ë³´ë“œ ìœ„ì— í–‰ì´ë‚˜ ì—´ì„ ì„ íƒí•´ì„œ ì²«ë²ˆì§¸ í–‰ì´ë‚˜ ì—´ë¶€í„° í€¸ì„ ìœ„ì¹˜ì‹œí‚¤ê³  (ê°™ì€ í–‰ì´ë‚˜ ì—´ì— í€¸ì´ ìœ„ì¹˜í•´ì„œëŠ” ì•ˆë˜ë¯€ë¡œ) ë‹¤ìŒ í–‰ì´ë‚˜ ì—´ì— `0`ë¶€í„° `n-1` ìœ„ì¹˜ ê¹Œì§€ í•˜ë‚˜ì”© í€¸ì„ ìœ„ì¹˜ ì‹œí‚¬ ìˆ˜ ìˆëŠ”ì§€ íƒìƒ‰í•œë‹¤. ë§Œì•½ íŠ¹ì • ìœ„ì¹˜ì— í€¸ì´ ìœ„ì¹˜ í•  ìˆ˜ ì—†ë‹¤ë©´ ì´ì „ í–‰ì´ë‚˜ ì—´ë¡œ ëŒì•„ê°€ ê·¸ ë‹¤ìŒ ìœ„ì¹˜ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆë‹¤. ì´ê²ƒì´ ë°± íŠ¸ë˜í‚¹ìœ¼ë¡œ, ë°± íŠ¸ë˜í‚¹ì´ë€ í•´ë¥¼ íƒìƒ‰í•˜ë‹¤ê°€ íŠ¹ì • ê²½ìš°ì—ì„œ í•´ê°€ ì•„ë‹Œ ê²ƒì„ í™•ì¸í•  ê²½ìš° ì´ì „ì˜ ìƒíƒœë¡œ ëŒì•„ê°€ëŠ” ë°©ë²•ì„ ë§í•œë‹¤. ì¦‰ ì™„ì „ íƒìƒ‰ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, í•´ê°€ ì•„ë‹Œ ê²ƒì„ í™•ì¸í•  ê²½ìš° ë°”ë¡œ íƒìƒ‰ì„ ì¢…ë£Œí•˜ê³  ë‹¤ìŒ ê²½ìš°ì˜ ìˆ˜ë¡œ ë„˜ì–´ê°€ëŠ” ë°©ë²•ì´ë‹¤.\n\nì¬ê·€í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ë©´ `0`ë¶€í„° `n-1`ê¹Œì§€ ê²½ìš°ë¥¼ íƒìƒ‰í•´ ì¬ê·€ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œ í›„ í•´ê°€ ì•„ë‹Œ ê²½ìš° í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•˜ê¸°ë§Œ í•˜ë©´ ë°± íŠ¸ë˜í‚¹ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤. ë§Œì•½ í€¸ì´ íŠ¹ì • ìœ„ì¹˜ì— ìˆì„ ìˆ˜ ìˆë‹¤ë©´ ë‹¤ìŒ í–‰ì´ë‚˜ ì—´ ìœ„ì¹˜ì— ëŒ€í•´ì„œ ì¬ê·€ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë©´ ëœë‹¤. ì´ ë°©ë²•ìœ¼ë¡œëŠ” ì²«ë²ˆì§¸ í–‰ ë˜ëŠ” ì—´ì— ëŒ€í•´ ë°± íŠ¸ë˜í‚¹ì„ ì‹¤í–‰í•˜ëŠ” ê²ƒìœ¼ë¡œ `n`ë²ˆì§¸ í–‰ ë˜ëŠ” ì—´ê¹Œì§€ í€¸ì„ ë†“ëŠ” ê²½ìš°ë¥¼ ëª¨ë‘ íƒìƒ‰í•  ìˆ˜ ìˆë‹¤. \n\n`path`ëŠ” ì´ˆê¸°í™”ëœ `n` ê¸¸ì´ì˜ ë°°ì—´ë¡œ í€¸ì˜ ìœ„ì¹˜ë¥¼ ì €ì¥í•˜ëŠ” ë°°ì—´ì´ë‹¤. í€¸ì€ ê°™ì€ í–‰ì´ë‚˜ ì—´ì— ìœ„ì¹˜í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ `path[x] = y`ë¼ê³  í•  ë•Œ ì²´ìŠ¤ ë³´ë“œ ìœ„ì˜ (x, y)ì§€ì ì— í€¸ì´ ìˆë‹¤ëŠ” ê²ƒì„ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ì´ë•Œ `path` ë‚´ì˜ ëª¨ë“  xì™€ yëŠ” ì¤‘ë³µë˜ì§€ ì•Šì„ ê²ƒì´ë‹¤.\n\nê³¼ì •ì„ ìš”ì•½í•˜ë©´:\n- `path` ë°°ì—´ì„ ì´ˆê¸°í™” í•œë‹¤. `path`ëŠ” ë°°ì—´ ì¸ë±ìŠ¤ `i`ë¥¼ í–‰ìœ¼ë¡œ í•˜ëŠ” í€¸ì˜ ì—´ ìœ„ì¹˜ë¥¼ ì›ì†Œê°’ìœ¼ë¡œ í•œë‹¤.\n- backtrackì„ êµ¬í˜„í•œë‹¤.\n    - ë°°ì—´ `path`ì™€ `nx`ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ë³´ë“œì˜ `(nx, ny)` ìœ„ì¹˜ì— í€¸ì„ ìœ„ì¹˜ì‹œì¼œë„ ë ì§€ë¥¼ íƒìƒ‰í•´ì„œ, ë§Œì•½ ê°€ëŠ¥í•˜ë‹¤ë©´:\n    - ë³´ë“œê°€ `n`ê°œ í€¸ìœ¼ë¡œ ì±„ì›Œì¡Œìœ¼ë©´ ì¹´ìš´íŠ¸ë¥¼ ì¦ê°€ì‹œí‚¤ê±°ë‚˜ ë°°ì—´ì„ ê²°ê³¼ê°’ì— ì¶”ê°€í•˜ê³ ,\n    - ì•„ì§ ë³´ë“œê°€ ì±„ì›Œì§€ì§€ ì•Šì•˜ìœ¼ë©´ `path[nx]`ì— `ny`ê°’ì„ ì €ì¥í•˜ê³  `nx+1` ê°’ì— ëŒ€í•´ backtrackì„ ì¬ê·€ë¡œ êµ¬í˜„í•œë‹¤.\n* tip: `path`ê°€ ì£¼ì–´ì¡Œì„ ë•Œ í–‰ë ¬ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì„œ backtrackì—ì„œ ë¶€ë¥´ë©´ í¸ë¦¬í•˜ë‹¤.\n\n\n## íŒŒì´ì¬ êµ¬í˜„ ì½”ë“œ\n### 51.\n```python\nclass Solution:\n    def solveNQueens(self, n: int) -> List[List[str]]:\n        \n        # implement backtrack\n        def backtrack(path, nx):\n            # search for (nx, ny) positions to place Queen\n            for ny in range(n):\n                if valid(path, nx, ny):\n                    path[nx] = ny\n                    # if the board is completed,\n                    # use path to return a matrix\n                    if nx == n-1:\n                        ret.append(return_val(path))\n                    else:\n                        backtrack(path, nx+1)\n        \n        # return True if placing queen at board[nx][ny] is valid\n        def valid(path, nx, ny):\n            for i in range(nx):\n                x, y = i, path[i]\n                # if \n                if y == ny or abs(x - nx) == abs(y - ny):\n                    return False\n            return True\n        \n        # given path, return the board in matrix form\n        def return_val(path):\n            board = [['.'] * n for _ in range(n)]\n            for y in range(n):\n                board[path[y]][y] = 'Q'\n            board = [''.join(l) for l in board]\n            return board\n        \n        ret = []\n        path = [-1] * n  # a queen is on board[x][path[x]]\n        backtrack(path, 0)\n        \n        return ret\n```\n\n### 52.\n```python\nclass Solution:\n    def totalNQueens(self, n: int) -> int:\n        \n        # implement backtrack\n        def backtrack(path, nx):\n            # search for (nx, ny) positions to place Queen\n            for ny in range(n):\n                if valid(path, nx, ny):\n                    path[nx] = ny\n                    # if the board is completed,\n                    # increase count by 1\n                    if nx == n-1: \n                        self.cnt += 1\n                    else:\n                        backtrack(path, nx+1)\n\n        # return True if placing queen at board[nx][ny] is valid\n        def valid(path, nx, ny):\n            for i in range(nx):\n                x, y = i, path[i]\n                # if another queen is at the same line or diagonal, \n                # return False\n                if y == ny or abs(x - nx) == abs(y - ny):\n                    return False\n            return True\n        \n        self.cnt = 0\n        path = [-1] * n  # a queen is on board[x][path[x]]\n        backtrack(path, 0)\n        \n        return self.cnt\n```","excerpt":"ë¬¸ì œ ë§í¬ â™Ÿ LeetCode, 51. N-Queens I LeetCode, 52. N-Queens II ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ì²´ìŠ¤ ë³´ë“œëŠ”  í¬ê¸°ì´ë¯€ë¡œ ë³¸ë˜ëŠ” 8-Queen ë¬¸ì œì˜€ìœ¼ë‚˜, ì´ ë¬¸ì œë“¤ì€ ì„ ìœ¼ë¡œ ë°”ê¾¸ì–´ ë¬¸ì œë¥¼ í•œë‹¨ê³„ ë” ì¶”ìƒí™”í–ˆë‹¤. 51ë²ˆâ€¦","fields":{"slug":"/leetcode_n-queen/"},"frontmatter":{"date":"Apr 07, 2022","title":"LeetCode(51, 52). N-Queens I, II","tags":["Algorithms","LeetCode","Implementation"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n### ë¬¸ì œ ë§í¬\n> [LeetCode, 54. Spiral Matrix I](https://leetcode.com/problems/spiral-matrix/)\n\n> [LeetCode, 59. Spiral Matrix II](https://leetcode.com/problems/spiral-matrix-ii/)\n\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n\nì´ ë¬¸ì œëŠ” ë‹¬íŒ½ì´ ë¬¸ì œë¼ê³ ë„ í•˜ë©°, ì•Œê³ ë¦¬ì¦˜ì„ ë°°ìš°ê¸° ì‹œì‘í•  ë•Œ ëª‡ ë²ˆ ë§ˆì£¼ì³¤ë˜ êµ¬í˜„ ë¬¸ì œë‹¤. ê¼­ ë‹¬íŒ½ì´ë¥¼ ì‹œê³„ë°©í–¥ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë”ë¼ë„ ë°˜ì‹œê³„ ë°©í–¥ìœ¼ë¡œ íƒìƒ‰í•˜ê±°ë‚˜ ë§Œë‹¤ë¼ ëª¨ì–‘ ë“±ìœ¼ë¡œ íƒìƒ‰í•˜ë„ë¡ ë¬¸ì œë¥¼ ë³€í˜•í•  ìˆ˜ ìˆë‹¤.\n\nì´ ê¸€ì—ì„œ ì†Œê°œí•˜ëŠ” ë‘ ë¬¸ì œëŠ” ê±°ì˜ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤. 54ë²ˆ ë¬¸ì œëŠ” í–‰ë ¬ì„ ì½ì–´ë“¤ì´ëŠ” ë¬¸ì œê³ , 59ë²ˆ ë¬¸ì œëŠ” ì£¼ì–´ì§„ ì¡°ê±´ì— ë§ëŠ” í–‰ë ¬ì„ ë§Œë“¤ì–´ì„œ ì¶œë ¥í•˜ëŠ” ë¬¸ì œë‹¤. í–‰ë ¬ì„ ì½ëŠ”ì§€ ì“°ëŠ”ì§€ì— ê´€ê³„ì—†ì´ í–‰ë ¬ì˜ ì›ì†Œì— ê°™ì€ ìˆœì„œë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒìœ¼ë¡œ ì½”ë“œì˜ ë§ì€ ë¶€ë¶„ì„ ì¬ì‚¬ìš© í•  ìˆ˜ ìˆë‹¤.\n\níŠ¹ì • ê·œì¹™ì— ë”°ë¼ ë°©í–¥ì„ ë°”ê¾¸ê¸° ìœ„í•´ **ë°©í–¥ ë²¡í„°** `dv`ë¥¼ ì„¤ì •í•´ ë¬¸ì œì— ì ‘ê·¼í–ˆë‹¤. ë°©í–¥ ë²¡í„°ì—ëŠ” ë°©í–¥ì„ í‹€ ë•Œ **ì—…ë°ì´íŠ¸ í•  ì¸ë±ìŠ¤ ë³€í™”ê°’**ì„ ì €ì¥í•œë‹¤. ì—¬ê¸°ì„œëŠ” í–‰ë ¬ì˜ ëì— ë‹¤ë‹¤ë¥´ê±°ë‚˜ ì´ë¯¸ ì½ê±°ë‚˜ ì“´ ê°’ì— ì ‘ê·¼í•  ê²½ìš° í–‰ë ¬ì˜ ì¸ë±ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•´ì„œ (ì‹œê³„ ë°©í–¥ìœ¼ë¡œ ëŒ ìˆ˜ ìˆë„ë¡)**ì˜¤ë¥¸ìª½ ë°©í–¥ìœ¼ë¡œ 90ë„ íšŒì „**í–ˆë‹¤.\n\nìš”ì•½í•˜ë©´:\n- í–‰ë ¬ì˜ ëì— ë‹¤ë‹¤ë¥´ì§€ ì•Šê³ , ì´ë¯¸ ì½ê±°ë‚˜ ì“´ ê°’ì´ ì•„ë‹Œê²½ìš°ì— í•œí•´ ë‹¤ìŒì„ ë°˜ë³µí•œë‹¤.\n- ì§€ê¸ˆ ì¸ë±ìŠ¤ì˜ í–‰ë ¬ê°’ì„ ì½ê±°ë‚˜ ì“´ë‹¤.\n- ì¸ë±ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ì½ê±°ë‚˜ ì“´ í‘œì‹œë¥¼ ë‚¨ê¸´ë‹¤. ì´ë•Œ, ì—…ë°ì´íŠ¸ í•  ì¸ë±ìŠ¤ ê°’ì´ ë²”ìœ„ë¥¼ ë„˜ì—ˆê±°ë‚˜ ì´ë¯¸ ì½ê±°ë‚˜ ì“´ ê°’ì„ ê°€ë¦¬í‚¤ëŠ” ê²½ìš° ë°©í–¥ì„ íŠ¼ ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.\n\n\n## íŒŒì´ì¬ êµ¬í˜„ ì½”ë“œ\n\nLeetCodeì—ì„œëŠ” Pythonìœ¼ë¡œ ë¬¸ì œ ë‹µì•ˆì„ Solution class í˜•íƒœë¡œ ì œì¶œí•´ì•¼ í•œë‹¤. LeetCodeì˜ ì¢‹ì€ ì ì€ ì œí•œ ì‹œê°„ì´ ëª…ì‹œë˜ì–´ ìˆê³  ë‹µì•ˆ ì œì¶œ ì‹œì—ë„ running timeê³¼ memory usageë¥¼ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì‚¬ëŒì˜ ë‹µì— ë¹„í•´ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê±°ë‚˜ ëŠë¦°ì§€ ì•Œë ¤ì¤€ë‹¤ëŠ” ì ì´ë‹¤. \n\n### 54.\n```python\nclass Solution:\n    def spiralOrder(self, matrix: List[List[int]]) -> List[int]:\n        \n        ret = []\n        INF = 1e9\n        \n        x, y, k = 0, 0, 0\n        m, n = len(matrix), len(matrix[0])\n        dv = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n        \n        while -1 < x < m and -1 < y < n and matrix[x][y] != INF:\n            \n            # read the element value\n            ret.append(matrix[x][y])\n\n            # update values\n            matrix[x][y] = INF\n            nx = x + dv[k][0]\n            ny = y + dv[k][1]\n            \n            # if nx or ny is out of boundary, update k\n            if nx in [-1, m] or ny in [-1, n] or matrix[nx][ny] == INF:\n                k = (k+1) % 4\n                x = x + dv[k][0]\n                y = y + dv[k][1]\n            else:\n                x, y = nx, ny\n            \n        return ret\n```\n\n### 59.\n```python\nclass Solution:\n    def generateMatrix(self, n: int) -> List[List[int]]:\n        \n        # initiate a matrix grid\n        grid = [[0 for _ in range(n)] for _ in range(n)]\n        \n        num = 1\n        x, y, k = 0, 0, 0\n        dv = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n        \n        while -1 < x < n and -1 < y < n and grid[x][y] == 0:\n            \n            # write number on the grid\n            grid[x][y] = num\n            \n            # update values\n            num += 1\n            nx = x + dv[k][0]\n            ny = y + dv[k][1]\n            \n            # if nx or ny is out of boundary, update k\n            if nx in [-1, n] or ny in [-1, n] or grid[nx][ny] != 0:\n                k = (k+1) % 4\n                x = x + dv[k][0]\n                y = y + dv[k][1]\n            else:\n                x, y = nx, ny\n                \n        return grid\n            \n```","excerpt":"ë¬¸ì œ ë§í¬ LeetCode, 54. Spiral Matrix I LeetCode, 59. Spiral Matrix II ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ì´ ë¬¸ì œëŠ” ë‹¬íŒ½ì´ ë¬¸ì œë¼ê³ ë„ í•˜ë©°, ì•Œê³ ë¦¬ì¦˜ì„ ë°°ìš°ê¸° ì‹œì‘í•  ë•Œ ëª‡ ë²ˆ ë§ˆì£¼ì³¤ë˜ êµ¬í˜„ ë¬¸ì œë‹¤. ê¼­ ë‹¬íŒ½ì´ë¥¼ ì‹œâ€¦","fields":{"slug":"/leetcode_spiral_matrix/"},"frontmatter":{"date":"Apr 07, 2022","title":"LeetCode(54, 59). Spiral Matrix I, II","tags":["Algorithms","LeetCode","Implementation"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\nì› ë…¼ë¬¸:\n> Vaswani et al., 2017, \"Attention is all you need\" ([Link to arxiv](https://arxiv.org/abs/1706.03762))\n\n## 0. Transformer\n\n![](transformers.jpeg)\n<center>\nThe Transformer (TV Series), from Wikipedia\n</center>\n\n</br>\n\n íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” Seq2Seq ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ë¥¼ ê°–ê³  ìˆì§€ë§Œ, ë³´ë‹¤ ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë‹¤ë£°ìˆ˜ ìˆëŠ” ëª¨ë¸ë¡œ í™˜ì˜ë°›ì•˜ë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìƒˆë¡œìš´ ì–´í…ì…˜ì„ ë„ì…í–ˆë‹¤. 2014ë…„ì— ë“±ì¥í•œ ì–´í…ì…˜(Bahdanau et al., 2014)ì´ RNN ë„¤íŠ¸ì›Œí¬ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í™œìš©ëœ ê²ƒê³¼ ë‹¬ë¦¬, 2017ë…„ì˜ ì–´í…ì…˜ì€ ì‹ ê²½ë§ì„ ì´ìš©í•˜ì§€ ì•Šê³  í–‰ë ¬ ê³±ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë°©ì‹ì„ ì œì•ˆí•˜ë©´ì„œ ìì—°ì–´ ì²˜ë¦¬ì— ìˆì–´ íšê¸°ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ ë¶ˆëŸ¬ì™”ë‹¤. \n\n![](transformer.png)\n<center>\níŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ êµ¬ì¡°, Vaswani et al., 2017\n</center>\n\n</br>\n\níŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ í¬ê²Œ ë´ì„œ ì™¼ìª½ì˜ ì¸ì½”ë”ì™€ ì˜¤ë¥¸ìª½ì˜ ë””ì½”ë”ë¥¼ ê°€ì§€ëŠ” êµ¬ì¡°ì´ë‹¤. RNN ëª¨ë¸ì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì¸ì½”ë”ì˜ ê²°ê³¼ê°’ì„ ë””ì½”ë”ì˜ ì…ë ¥ê°’ê³¼ ê²°í•©í•´ì„œ ì—°ì‚°ì„ ê±°ì³ ê²°ê³¼ê°’ì„ ë„ì¶œí•œë‹¤. ë‹¤ë§Œ RNNê³¼ì˜ ì°¨ì´ì ì€ ì‹œí€€ìŠ¤ë¥¼ **ë™ì‹œì—** ì²˜ë¦¬í•œë‹¤ëŠ” ì ì´ë‹¤. ì¦‰ ì‹œí€€ìŠ¤ ëª¨ë¸ì²˜ëŸ¼ ì‹œí€€ìŠ¤ ë°ì´í„°ì— ìˆœì„œëŒ€ë¡œ ì ‘ê·¼í•´ì„œ í•˜ë‚˜ì”© ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì—°ì‚°í•œë‹¤. ë”°ë¼ì„œ ë¶„ì‚° ì—°ì‚°ì´ ìš©ì´í•˜ë©° RNN ëª¨ë¸ì—ì„œ ë°œìƒí•˜ëŠ” vanishing gradient í˜„ìƒì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²˜í•´ì„œ ë³´ë‹¤ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ë‹¤ë£° ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.\n\níŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬ì— ì‚¬ìš©ë˜ëŠ” ì–´í…ì…˜ì€ í–‰ë ¬ê³±ì„ ì´ìš©í•œ ìˆœì°¨ì ì´ì§€ ì•Šì€ (ë”°ë¼ì„œ ë³‘ë ¬ ì—°ì‚°ì´ ê°€ëŠ¥í•œ) ì–´í…ì…˜ì´ë©°, ì´ ì–´í…ì…˜ì„ Scaled-Dot product ì–´í…ì…˜ì´ë¼ê³  í•œë‹¤.  \n\n### ğŸ”” Scaled-Dot prooduct Attention\n\nScaled-Dot prooduct ì–´í…ì…˜ì—ëŠ” ì„¸ê°œì˜ í–‰ë ¬ $Q$, $K$, $V$ ì…ë ¥ì´ í•„ìš”í•˜ë‹¤:\n\n- $Q$, Queries : ë¹„êµí•˜ê³ ì í•˜ëŠ” ì‹œí€€ìŠ¤ë¡œ, í‚¤ Kì™€ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•œë‹¤.\n- $K$, Keys : ë¹„êµ ëŒ€ìƒì´ ë˜ëŠ” ì‹œí€€ìŠ¤ë¡œ, ì¿¼ë¦¬ Qì™€ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•œë‹¤.\n- $V$, Values : $QK$ì˜ ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§€ëŠ” í–‰ë ¬ì´ë‹¤.\n\nì–´í…ì…˜ì´ë€ í–‰ë ¬ $Q$ì™€ $K$-$V$ ìŒì„ ê²°ê³¼ê°’ì— ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ë¡œ, ê²°ê³¼ê°’ì€ $V$ì˜ ê°€ì¤‘ì¹˜ í•©ìœ¼ë¡œ ê³„ì‚°ë˜ê³ , ê°ê°ì˜ ê°’ $v$ì— í• ë‹¹ëœ ê°€ì¤‘ì¹˜ëŠ” $q$ì™€ ê·¸ì— ëŒ€ì‘í•˜ëŠ” $k$ë¡œë¶€í„° ê³„ì‚°ëœë‹¤. ì´ ì–´í…ì…˜ì´ ì´ë¦„ ë¶™ì€ ì´ìœ ëŠ” ì–´í…ì…˜ì„ ì—°ì‚°í•˜ëŠ” ë°©ë²•ì— ìˆë‹¤.\n\n$$\nAttention(Q, K, V) = softmax(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}) \\cdot V\n$$\n\nì²« ë²ˆì§¸ í–‰ë ¬ ê³±(dot product)ì€ ì¿¼ë¦¬ Qì™€ í‚¤ Kì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ê³ , ë‘ë²ˆì§¸ ê³±ì€ softmax í•¨ìˆ˜ê°’ìœ¼ë¡œ ì–»ì–´ì§„ ê°€ì¤‘ì¹˜ë¥¼ ë°œë¥˜ $V$ì— í• ë‹¹í•œë‹¤. $Q$ì™€ $K$ì˜ ê³±ì€ $K$ì˜ ì°¨ì› $d_k$ì˜ ë£¨íŠ¸ë¡œ ì¡°ì •(scaled) í•˜ëŠ”ë°, ì´ ìŠ¤ì¼€ì¼ë§ì€ reguralizationíš¨ê³¼ë¥¼ ê°€ì§„ë‹¤. ê·¸ ë‹¤ìŒ softmax í•¨ìˆ˜ë¥¼ ê±°ì³ $Q$ì™€ $K$ì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜í•´ ë§ˆì§€ë§‰ìœ¼ë¡œ ê·¸ ê°’ì„ í–‰ë ¬ $V$ì— ë°˜ì˜í•´ ëª¨ë“  ì¿¼ë¦¬ì˜ ì–´í…ì…˜ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. \n\n![](attention.png)\n<center>\nì–´í…ì…˜, Badnau et al., 2015\n</center>\n\n</br>\n\nì–´í…ì…˜ì€ ì¿¼ë¦¬ì™€ í‚¤ì˜ heatmapì„ ìƒì„±í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤. ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ë‹¨ì–´ ìŒ ë‹¨ìœ„ $(q, k)$ë¡œ ì‚´í´ë³´ê¸° ë•Œë¬¸ì—, ë‹¨ì–´ê°€ ë¬¸ì¥ì—ì„œ ë“±ì¥í•˜ëŠ” ìˆœì„œì— ê´€ê³„ì—†ì´ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤. ìœ„ì˜ ì˜ˆì²˜ëŸ¼ ì–´ìˆœì´ ë‹¤ë¥¸ ì˜ì–´ì™€ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ì—ì„œë„ ë‹¨ì–´ì˜ ëŒ€ì‘ ê´€ê³„ë¥¼ ì œëŒ€ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.\n\n### ğŸ”” Multi-Head Attention\n\n![](multi-head-attention.png)\n<center>\nMulti-Head Attention, from deeplearning.ai\n</center>\n\n</br>\n\níŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì–´í…ì…˜ì˜ ë˜ë‹¤ë¥¸ íŠ¹ì§•ì€ ì–´í…ì…˜ì´ ë¨¸ë¦¬(heads)ë¥¼ ì—¬ëŸ¬ê°œ ê°€ì§„ë‹¤ëŠ” ê²ƒì´ë‹¤. ì…ë ¥ê°’ì— ëŒ€í•´ ì–´í…ì…˜ì„ ì—¬ëŸ¬ë²ˆ ìˆ˜í–‰í•œ í›„ ê²°ê³¼ë¥¼ ê²°í•©(concatenate)í•´ì„œ ìµœì¢…ì ìœ¼ë¡œ í•˜ë‚˜ì˜ í–‰ë ¬ì„ ë§Œë“œëŠ” ê²ƒì„ ëœ»í•œë‹¤. $d_{model}$ ì°¨ì›ì˜ $Q$, $K$, $V$ì— ëŒ€í•´ ì¼íšŒ ì–´í…ì…˜ì„ ì ìš©í•˜ëŠ” ëŒ€ì‹  $Q$, $K$, $V$ë¥¼ `n_heads`ë²ˆ ì„ í˜• íˆ¬ì‚¬(linear projection)í•´ì„œ ì„œë¡œë‹¤ë¥¸ í•™ìŠµëœ ì„ í˜• íˆ¬ì‚¬ë“¤ì— ëŒ€í•´ ì–´í…ì…˜ì„ ì ìš©í•œë‹¤. ê° ì„ í˜• íˆ¬ì‚¬ë¥¼ $Q$ì— ëŒ€í•´ $W^Q$, $K$ì— ëŒ€í•´ $W^K$, $V$ì— ëŒ€í•´ $W^V$ë¼ê³  í•˜ë©° ê°ê° $(n_{seq}, d_k)$, $(n_{seq}, d_k)$, $(n_{seq}, d_v)$ ì°¨ì›ì„ ê°€ì§„ë‹¤. ì–´í…ì…˜ì„ ì ìš©í•˜ë©´ í•œê°œì˜ ê²°ê³¼ê°’ì— ëŒ€í•´ $(n_{seq}, d_v)$ ì°¨ì›ì„ ê°€ì§€ë¯€ë¡œ `n_heads`ê°œì˜ ê²°ê³¼ê°’ì„ ê²°í•©í•œ í–‰ë ¬ ë‹¤ì‹œ ì„ í˜• íˆ¬ì‚¬í•´ì„œ ì–´í…ì…˜ ê²°ê³¼ê°’ì„ ì–»ëŠ”ë‹¤. ë§¤ë²ˆ í•™ìŠµí•  ë•Œë§ˆë‹¤ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ë¯€ë¡œ ì—¬ëŸ¬ë²ˆ ì–´í…ì…˜ì„ ì ìš©í•¨ìœ¼ë¡œì„œ ì‹œí€€ìŠ¤ ë°ì´í„° ì‚¬ì´ì˜ ë‹¤ì–‘í•œ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. ì´ë•Œ ì—¬ëŸ¬ë²ˆì˜ ì–´í…ì…˜ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì•¼ í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ë³‘ë ¬ ì—°ì‚°ì„ í•˜ê¸° ìš©ì´í•œ êµ¬ì¡°ë‹¤. \n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax `SplitIntoHeads`ì™€ `MergeHeads` ë©”ì„œë“œë¡œ, Multi-Head ì–´í…ì…˜ì˜ ì¼ë¶€ë¶„ì„ êµ¬í˜„í•œë‹¤. \n\n```python\ndef SplitIntoHeads(n_heads, merged_batch_and_head=True):\n  \"\"\"Returns a layer that reshapes an array for multi-head computation.\"\"\"\n  def f(x):\n    batch_size, seq_len, d_feature = x.shape\n    if d_feature % n_heads != 0:\n      raise ValueError(\n          f'Feature embedding dimensionality ({d_feature}) is not a multiple'\n          f' of the requested number of attention heads ({n_heads}).')\n\n    d_head = d_feature // n_heads\n\n    # (b_size, seq_len, d_feature) --> (b_size*n_heads, seq_len, d_head)\n    x = x.reshape((batch_size, seq_len, n_heads, d_head))\n    x = x.transpose((0, 2, 1, 3))\n    if merged_batch_and_head:\n      x = x.reshape((batch_size * n_heads, seq_len, d_head))\n    return x\n  return Fn('SplitIntoHeads', f)\n```\n\n`SplitIntoHeads`ëŠ” `d_feature`(ê·¸ë¦¼ì—ì„œëŠ” `d_model`)ê°€ Headì˜ ê°œìˆ˜ `n_heads`ì˜ ì •ìˆ˜ë°°ì¼ ê²ƒì„ ê°•ì œí•œë‹¤. ìœ„ì˜ ê·¸ë¦¼ì²˜ëŸ¼ `(batch, seq_len, d_feature)`ì„ ì…ë ¥ë°›ì•„ `(b_size*n_heads, seq_len, d_head)`ì°¨ì›ì„ ì¶œë ¥í•˜ê³  ìˆë‹¤. ê·¸ ë‹¤ìŒ `PureAttention`ì²˜ëŸ¼ 1ê°œ Headì— ëŒ€í•œ ì–´í…ì…˜ì„ `n_heads`ë§Œí¼ ìˆ˜í–‰í•œ í›„, ì—¬ëŸ¬ Headë¥¼ `MergeHeads`ë¡œ ê²°í•©í•œë‹¤.\n\n```python\ndef MergeHeads(n_heads, merged_batch_and_head=True):\n  \"\"\"Returns a layer that rejoins heads, after multi-head computation.\"\"\"\n  def f(x):\n    if merged_batch_and_head:\n      dim_0, seq_len, d_head = x.shape\n      if dim_0 % n_heads != 0:\n        raise ValueError(\n            f\"Array's leading dimension ({dim_0}) is not a multiple of the\"\n            f\" number of attention heads ({n_heads}).\")\n\n      batch_size = dim_0 // n_heads\n      x = x.reshape((batch_size, n_heads, seq_len, d_head))\n    else:\n      batch_size, _, seq_len, d_head = x.shape\n\n    # (b_size, n_heads, seq_len, d_head) --> (b_size, seq_len, d_feature)\n    x = x.transpose((0, 2, 1, 3))\n    x = x.reshape((batch_size, seq_len, n_heads * d_head))\n    return x\n  return Fn('MergeHeads', f)\n```\n\ní•¨ìˆ˜ `f`ëŠ” `(batch_size, n_heads, seq_len, d_head)` ì°¨ì›ì˜ ì…ë ¥ê°’ì„ ì–´í…ì…˜ ë¸”ëŸ­ì˜ ì…ë ¥ê°’ ì°¨ì› `(b_size, seq_len, d_feature)`ë¡œ ë³€í˜•í•´ì„œ ë°˜í™˜í•œë‹¤. \n\n\n## 1. Encoder\n\në„ë¦¬ ì“°ì´ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì‚¬ì „í›ˆë ¨ ëª¨ë¸ì¸ BERTì˜ ê²½ìš° ì¸ì½”ë”ë§Œ (`bert-large`ì˜  ê²½ìš°) 24ê°œ ìŒ“ì€ ë„¤íŠ¸ì›Œí¬ë‹¤. LSTMì„ ìƒê°í•´ ë³´ë©´ ì¸ì½”ë”ì˜ êµ¬ì¡°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‹¨ìˆœí•´ ë³´ì´ì§€ë§Œ, ì¸ì½”ë”ë§Œìœ¼ë¡œë„ ë§ì€ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.\n\n![](transformer_encoder.png)\n<center>\nì¸ì½”ë” êµ¬ì¡°, from deeplearning.ai\n</center>\n\n</br>\n\nì¸ì½”ë”ëŠ” í¬ê²Œ **ë‘ê°œì˜ ë ˆì´ì–´**ë¡œ êµ¬ì„±ëœë‹¤. Multi-Head Attentionê³¼ FeedForwardì´ë‹¤. FeedForwardëŠ” ì¼ë ¨ì˜ í›ˆë ¨ ê°€ëŠ¥í•œ ì‹ ê²½ë§ìœ¼ë¡œ êµ¬ì„±ëœ ë¸”ëŸ­ì´ë‹¤. 0ï¸âƒ£ ì…ë ¥ê°’ì„ Embeddingí•˜ê³  Positional Encodingì„ ì ìš©í•œ í›„ì—, í•œ ê°œì˜ **ì¸ì½”ë” ë¸”ëŸ­**ì€ 1ï¸âƒ£ Residualì„ ì ìš©í•œ Multi-Head Attentionì„ ì‹¤í–‰í•˜ê³  2ï¸âƒ£ ë‹¤ì‹œ Residualì„ ì ìš©í•œ FeedForward ë ˆì´ì–´ë¥¼ ì‹¤í–‰í•œë‹¤. ëª¨ë¸ì„ ê¹Šê²Œ ë§Œë“¤ê¸° ìœ„í•´ ì´ ì¸ì½”ë” ë¸”ëŸ­ì„ ì—¬ëŸ¬ë²ˆ ì‹¤í–‰í•œë‹¤.\n\nResidual ë ˆì´ì–´ëŠ” í•¨ìˆ˜ $Fn(x_1, x_2, ...)$ì— ëŒ€í•´ ë‹¤ìŒì„ ëœ»í•œë‹¤.\n\n$$\nResidual(Fn)(x_1, x_2, ...) = Fn(x_1, x_2, ...) + x_1\n$$\n\nì¦‰ ì…ë ¥ê°’ì˜ ì²«ë²ˆì§¸ ê°’ì„ í•¨ìˆ˜ì˜ ê²°ê³¼ê°’ì— ë”í•˜ëŠ” ê¸°ëŠ¥ì„ í•œë‹¤. Residual ë ˆì´ì–´ë¥¼ ì ìš©í•˜ëŠ” ì´ìœ ëŠ” shortcut ì—°ê²° ê¸°ëŠ¥ì„ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. íŠ¹íˆ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµí•  ë•Œ Residualì´ íš¨ê³¼ì ì„ì´ ê²€ì¦ë˜ì—ˆë‹¤.\n\n> Further study - Residual ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ  : [He et al., 2015](https://arxiv.org/pdf/1512.03385.pdf)\n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `TransformerEncoder` ëª¨ë¸ì´ë‹¤.\n\n```python\ndef TransformerEncoder(vocab_size,\n                       n_classes=10,\n                       d_model=D_MODEL,\n                       d_ff=D_FF,\n                       n_layers=N_LAYERS,\n                       n_heads=N_HEADS,\n                       max_len=MAX_SEQUENCE_LENGTH,\n                       dropout=DROPOUT_RATE,\n                       dropout_shared_axes=DROPOUT_SHARED_AXES,\n                       mode=MODE,\n                       ff_activation=FF_ACTIVATION_TYPE):\n    \n  def _Dropout():\n    return tl.Dropout(rate=dropout, shared_axes=dropout_shared_axes, mode=mode)\n\n  def _EncBlock():\n    return _EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,\n                         mode, ff_activation)\n\n  return tl.Serial(\n      tl.Branch([], tl.PaddingMask()),  # Creates masks from copy of the tokens.\n      tl.Embedding(vocab_size, d_model),\n      _Dropout(),\n      tl.PositionalEncoding(max_len=max_len),\n      [_EncBlock() for _ in range(n_layers)],\n      tl.Select([0], n_in=2),  # Drops the masks.\n      tl.LayerNorm(),\n      tl.Mean(axis=1),\n      tl.Dense(n_classes),\n  )\n```\n\n`TransformerEncoder`ëŠ” í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ `n_classes`ê°œë¡œ ë¶„ë¥˜í•œë‹¤. í•¨ìˆ˜ ë°˜í™˜ê°’ì˜ ì²«ì¤„ì— ë“±ì¥í•˜ëŠ” `tl.Branch`ëŠ” ì…ë ¥ê°’ì„ ë°›ì•„ì„œ ê°ê°ì˜ í•¨ìˆ˜ë¥¼ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰í•œë‹¤. ì¦‰ ì…ë ¥ê°’ì„ ë¦¬ìŠ¤íŠ¸`[]`ë¡œ ë§Œë“  ê°’ê³¼ íŒ¨ë”©ë§ˆìŠ¤í¬ `tl.PaddingMask()` ê°’ ë‘ê°œë¥¼ ë°˜í™˜í•  ê²ƒì´ë‹¤. ë‘ ê°’ ëª¨ë‘ ì„ë² ë”©ê³¼ positional encodingì„ ê±°ì³ ì¸ì½”ë” ë¸”ëŸ­ì— ì…ë ¥ëœë‹¤. ì¸ì½”ë” ë¸”ëŸ­ì˜ ì½”ë“œì—ì„œ ë°ì´í„°ì™€ ë§ˆìŠ¤í¬ ìŒ `(activations, mask)`ì„ ì…ë ¥ë°›ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n```python\ndef _EncoderBlock(d_model,\n                  d_ff,\n                  n_heads,\n                  dropout,\n                  dropout_shared_axes,\n                  mode,\n                  ff_activation):\n  \"\"\"Returns a list of layers that implements a Transformer encoder block.\n  The input to the block is a pair (activations, mask) where the mask was\n  created from the original source tokens to prevent attending to the padding\n  part of the input. The block's outputs are the same type/shape as its inputs,\n  so that multiple blocks can be chained together.\n  \"\"\"\n  def _Attention():\n    return tl.Attention(d_model, n_heads=n_heads, dropout=dropout, mode=mode)\n\n  # ...\n\n  return [\n      tl.Residual(\n          tl.LayerNorm(),\n          _Attention(),\n          _Dropout(),\n      ),\n      tl.Residual(\n          tl.LayerNorm(),\n          _FFBlock(),\n          _Dropout(),\n      ),\n  ]\n```\n\nì—¬ê¸°ì„œ `tl.Attention`ì€ `n_heads`ê°œì˜ ë¨¸ë¦¬ë¥¼ ê°€ì§€ëŠ” multi-head ì…€í”„-ì–´í…ì…˜ì´ë©°, Attention ë ˆì´ì–´ì™€ FeedForward ë¸”ëŸ­ì´ Residualì„ ê±°ì¹˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì–´í…ì…˜ ë¸”ëŸ­ì„ ì§€ë‚œ í›„ì—ëŠ” ë§ˆìŠ¤í¬ê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ `tl.Select()`ë¡œ `(activations, mask)`ìŒì—ì„œ ì•ì˜ ê°’ë§Œ ì·¨í•˜ê³  `tl.LayerNorm()`ê³¼ ê°™ì€ ì¿¼ë¦¬ì— í•´ë‹¹í•˜ëŠ” ì—´ì— ëŒ€í•œ ë§ì…ˆ `tl.Mean(axis=1)`, ê·¸ë¦¬ê³  `n_classes`ê°œì˜ `tl.Dense()` ì¸µì„ ê±°ì³ ë§ˆë¬´ë¦¬í•œë‹¤.\n\n### ğŸ”† Dimensionality Setting\n\nResidual ë ˆì´ì–´ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì–´í…ì…˜ì˜ ì…ë ¥ê°’ê³¼ ê²°ê³¼ê°’ì˜ ì°¨ì›ì´ ê°™ì•„ì•¼í•œë‹¤. ì•ì˜ Multi-Head Attention ê·¸ë¦¼ì„ ì°¸ê³ í•˜ì—¬ ë°°ì¹˜ í¬ê¸°ë¥¼ `batch`, ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ `length`, ê·¸ë¦¬ê³  ì–´í…ì…˜ì˜ ì°¨ì›ì„ `d_model`ë¡œ ì„¤ì •í•˜ì. Q, K, Vê°€ $(batch, length, d_{model})$ ì°¨ì›ì„ ê°€ì§€ë©°, $W^Q$, $W^K$, $W^V$ëŠ” ê°ê° $(batch, length, d_k)$, $(batch, length, d_k)$, $(batch, length, d_v)$ ì°¨ì›ì´ë¼ê³  í•˜ì. ìœ„ì˜ ì„¤ì •ì—ì„œ $d_k = d_v$ë¡œ ë‘ë©°, ê·¸ë¦¼ì—ì„œëŠ” ì´ ê°’ì´ $d_{head}$ë¡œ ë‚˜íƒ€ë‚˜ ìˆë‹¤. ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ê³  ë‚œ í›„ ië²ˆ ì§¸ ì–´í…ì…˜ì€ $Z_i \\in (batch, length, d_v)$ ì°¨ì›ì´ ë˜ëŠ”ë°, $n_{heads}$ê°œì˜ ì–´í…ì…˜ì„ ê²°í•©í•˜ê³  ë‚œ í›„ ì²˜ìŒ ì…ë ¥ê°’ê³¼ ê°™ì€ ì°¨ì›ì„ ì–»ê¸° ìœ„í•´ $ n_{heads} = d_{model} / d_v$ë¡œ ì„¤ì •í•œë‹¤. ìš”ì•½í•˜ë©´:\n\n$$\nd_k = d_v = d_{model} / n_{heads}\n$$\n\n\n### ğŸ”† Positional Encoding\n\nì¸ì½”ë”©ì— ì•ì„œ, ë‹¨ìˆœíˆ ë‹¨ì–´ ì„ë² ë”©ì„ í†µí•´ $QK^T$ 2ì°¨ì› í–‰ë ¬ì„ ê³„ì‚°í•˜ë©´ ì‹œí€€ìŠ¤ ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë‹¨ì–´ì˜ ë¬¸ì¥ ë‚´ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°˜ì˜í•  ìˆ˜ ì—†ë‹¤. ê·¸ëŸ¬ë‚˜ ì–´ìˆœì€ ë§¥ë½ì„ íŒŒì•…í•˜ëŠ”ë°ì— ì¤‘ìš”í•œ ë‹¨ì„œê°€ ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë¬¸ì¥ ë‚´ì—ì„œ ê°™ì€ ë‹¨ì–´ê°€ ë“±ì¥í•´ë„ ê° ë‹¨ì–´ëŠ” ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°€ë¦¬í‚¬ ìˆ˜ ìˆê³ , ì–¸ì–´ë§ˆë‹¤ ë¬¸ë²• êµ¬ì¡°ì— ë”°ë¼ ì–´ìˆœì´ ë‹¤ë¥´ë©°, ê°™ì€ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•´ë„ ì–´ìˆœì— ë”°ë¼ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ë‚´í¬í•  ìˆ˜ ìˆë‹¤.\n\në”°ë¼ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ìœ„ì¹˜ì— ë”°ë¥¸ ì„ì˜ì˜ ê°’ì„ ì„¤ì •í•´ Q, Kì™€ Vì˜ ì„ë² ë”©ì— **ë”í•˜ëŠ”**ë°, ì´ ê²ƒì„ positional encodingì´ë¼ê³  í•œë‹¤. Traxì—ì„œëŠ” ì—¬ëŸ¬ê°€ì§€ positional encoding ë°©ë²•ì„ ì§€ì›í•˜ê³  ìˆëŠ”ë° ([link](https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=positional%20encoding#module-trax.layers.research.position_encodings)), ì› ë…¼ë¬¸ì—ì„œëŠ” ì°¨ì› `i`ì™€ ìœ„ì¹˜ `pos`ì— ëŒ€í•œ sine ê³¡ì„ ìœ¼ë¡œ í‘œí˜„í–ˆë‹¤.\n\n$$\n\\begin{aligned}\nPE_{(pos,2i)} &= sin(pos/10000^{2i/d_{model}}) \\\\\nPE_{(pos,2i+1)} &= cos(pos/10000^{2i/d_{model}})\n\\end{aligned}\n$$\n\nì¦‰ positional encodingì˜ ê° ì°¨ì›ì€ ì‚¬ì¸ ê³¡ì„ ì— ëŒ€ì‘í•œë‹¤. PEëŠ” $2\\pi$ì—ì„œ ë¶€í„° $10000 \\cdot 2\\pi$ê¹Œì§€ì˜ ê¸°í•˜í•™ì  í˜•íƒœë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì„œ ìƒìˆ˜ $k$ì— ëŒ€í•´ ìƒëŒ€ì ì¸ ìœ„ì¹˜ì¸ $PE(pos+k)$ë¥¼ $PE(pos)$ì˜ ì„ í˜• í•¨ìˆ˜ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. trax.layers.Attentionì—ì„œ ì •ì˜í•˜ê³  ìˆëŠ” `PositionalEncoding` ë„ ê°™ì€ ë°©ë²•ì„ ì ìš©í–ˆë‹¤.\n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `PositionalEncoding` ë ˆì´ì–´ë‹¤.\n\n```python\nclass PositionalEncoding(base.Layer):\n  \n  # ...\n\n  def forward(self, inputs):\n    \"\"\"Returns the input activations, with added positional information.\"\"\"\n    weights = self.weights\n\n    # ...\n\n    emb = fastmath.dynamic_slice_in_dim(\n        weights, self.state, inputs.shape[1], axis=1)\n    self.state += inputs.shape[1]\n    return inputs + emb\n\n  def init_weights_and_state(self, input_signature):\n    \"\"\"Randomly initializes the positional encoding vectors.\n    \"\"\"\n    d_feature = input_signature.shape[-1]\n    if self._d_feature is not None:\n      d_feature = self._d_feature\n    pe = np.zeros((self._max_len, d_feature), dtype=np.float32)\n    position = np.arange(0, self._max_len)[:, np.newaxis]\n    div_term = np.exp(\n        np.arange(0, d_feature, 2) * -(np.log(10000.0) / d_feature))\n    pe[:, 0::2] = np.sin(position * div_term)\n    pe[:, 1::2] = np.cos(position * div_term)  # [self._max_len, d_feature]\n    if self._use_bfloat16:\n      pe = pe.astype(jnp.bfloat16)\n    w = jnp.array(pe)  # Trainable parameters, initialized above.\n    # ...\n```\n\n`init_weights_and_state` í•¨ìˆ˜ëŠ” `ShapeDtype` ê°ì²´ë¥¼ ì…ë ¥ë°›ì•„ì„œ ì„ë² ë”© í¬ê¸° `(max_len, d_feature)` í¬ê¸°ì˜ ë²¡í„° `pe`ë¥¼ ì´ˆê¸°í™” í•œë‹¤. `pe` ë²¡í„°ì˜ ì§ìˆ˜ í–‰ì—ëŠ” `positon * div_term`ì˜ sine ê°’ì„ í• ë‹¹í•˜ê³  í™€ìˆ˜ í–‰ì—ëŠ” cosine ê°’ì„ í• ë‹¹í•œë‹¤. ì´ ê°’ì„ `weights`ë¡œ ì „ë‹¬í•´ í•¨ìˆ˜`forward`ì—ì„œ `emb` ê°’ìœ¼ë¡œ ì…ë ¥ê°’ì— ë”í•´ ì „ë‹¬í•˜ê³  ìˆë‹¤. ì¦‰ ì‚¬ì¸ê³¼ ì½”ì‚¬ì¸ ê°’ìœ¼ë¡œ ìœ„ì¹˜ì •ë³´ë¥¼ ì¸ì½”ë”©í•´ ì…ë ¥ê°’ì— ë”í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ positional encodingì„ ìˆ˜í–‰í•œë‹¤.\n\n### ğŸ“£ Encoder Self-Attention \n\nì¸ì½”ë”ëŠ” ì…€í”„-ì–´í…ì…˜ ë ˆì´ì–´ë¥¼ í™œìš©í•œë‹¤. ì…€í”„-ì–´í…ì…˜ì€ ì£¼ì–´ì§„ ë°ì´í„°ì˜ ë¶€ë¶„ê°’ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ë°©ë²•ì´ë‹¤. ì¦‰ ë¬¸ì¥ ë°ì´í„°ì—ì„œ ì…€í”„-ì–´í…ì…˜ì€ ë¬¸ì¥ ë‚´ì˜ ë‹¨ì–´ ë¬¸ë§¥ì„ íŒŒì•…í•œë‹¤. ì•ì„œ $Q$, $K$, $V$ì˜ ê°’ì€ ì–´í…ì…˜ì— ë”°ë¼ ë‹¤ë¥´ë‹¤ê³  í–ˆëŠ”ë°, ì…€í”„-ì–´í…ì…˜ ë ˆì´ì–´ì—ì„œëŠ” ëª¨ë“  $Q$, $K$, $V$ê°€ ê°™ì€ ì‹œí€€ìŠ¤, ì¦‰ ì¸ì½”ë”ì˜ ì´ì „ ë ˆì´ì–´ì˜ ê²°ê³¼ê°’ì—ì„œ ì˜¨ë‹¤. ì£¼ì–´ì§„ ë¬¸ì¥ì´ ìˆì„ ë•Œ, ì„ì˜ì˜ ë‹¨ì–´ $w$ì— ëŒ€ì‘í•˜ëŠ” ì„ë² ë”©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. ì„ë² ë”©ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•´ ì–»ì€ ì¿¼ë¦¬ $q$ì— ëŒ€í•´ ëª¨ë“  $k \\in K$ì™€ dot productë¡œ ë¹„êµí•´ì„œ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ê·¸ ë‹¤ìŒ softmax í•¨ìˆ˜ë¥¼ í†µí•´ ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ë”í•´ì„œ 1ì´ ë˜ëŠ” ì–‘ìˆ˜ê°’ìœ¼ë¡œ ë³€í™˜í•œë‹¤. ê·¸ í›„ ë‘ë²ˆì§¸ dot productë¡œ ë‹¨ì–´ $w$ì— ëŒ€ì‘í•˜ëŠ” ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì˜ $v$ê°’ë“¤ì„ êµ¬í•´ ë‹¤ì‹œ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ê³±í•¨ìœ¼ë¡œì„œ ëª¨ë“  ê°€ì¤‘ì¹˜ í•©ì„ êµ¬í•œë‹¤. ì´ê²ƒì´ ë‹¨ì–´ $w$ì— ëŒ€í•œ ì–´í…ì…˜ì´ë‹¤.\n\n![](attention2.png)\n<center>\nì…€í”„-ì–´í…ì…˜, Vaswani et al., 2017\n</center>\n\n</br>\n\nìœ„ ê·¸ë¦¼ì€ _\"making\"_ ë‹¨ì–´ì— ëŒ€í•œ ì–´í…ì…˜ì„ í‘œí˜„í•˜ê³  ìˆë‹¤. ìœ„ ì–´í…ì…˜ì˜ $Q$, $K$, $V$ëŠ” ëª¨ë‘ í•œ ë¬¸ì¥ _\"It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult. <EOS> <pad> ...\"_ì—ì„œ ì–»ì–´ì§„ë‹¤. ë‹¤ë¥¸ ìƒ‰ê¹”ì€ ë‹¤ë¥¸ headë¥¼ ë‚˜íƒ€ë‚´ë©° ìƒ‰ì´ ì„ ëª…í• ìˆ˜ë¡ ê´€ê³„ë„ê°€ ë†’ë‹¤. _\"making\"_ê³¼ ì—°ê´€ëœ headëŠ” _\"making ... more difficult\"_ êµ¬ë¬¸ì„ ì™„ì„±í•œë‹¤.\n\në¬¼ë¡  íš¨ìœ¨ì„ ìœ„í•´ ìš°ë¦¬ëŠ” í–‰ë ¬ ë‹¨ìœ„ë¡œ ì–´í…ì…˜ì„ ì—°ì‚°í•œë‹¤. ì£¼ì–´ì§„ ë¬¸ì¥ì˜ ë‹¨ì–´ ì„ë² ë”©ì´ ì„ë² ë”© ì°¨ì› embì— ëŒ€í•´ $(n_{seq}, emb)$ ì°¨ì›ì´ë¼ê³  í•˜ì. ìš°ë¦¬ëŠ” $(emb, d_{model})$ì°¨ì›ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^Q$, $W^K$, ê·¸ë¦¬ê³  $W^V$ì„ í•™ìŠµí•œë‹¤. ë‹¨ì–´ì— ëŒ€í•´ í–ˆë˜ ê²ƒê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì„ë² ë”© í–‰ë ¬ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ê³±í•´ì„œ ê°ê° $(n_{seq}, d_{model})$ ì°¨ì›ì˜ í–‰ë ¬ $Q$, $K$, ê·¸ë¦¬ê³  $V$ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë‹¤. ì´í›„ì˜ ì–´í…ì…˜ ì—°ì‚°ì€ scaled-dot product ì–´í…ì…˜ì—ì„œ ì‚´í´ë³¸ ê²ƒê³¼ ê°™ë‹¤. Multi-head ì…€í”„-ì–´í…ì…˜ì„ ì‹¤í–‰í•œë‹¤ë©´, $i \\in n_{heads}$ì— ëŒ€í•´ $W^Q_i$, $W^K_i$, $W^V_i$ë¥¼ í›ˆë ¨í•˜ê³  $Q_i$, $K_i$, $V_i$ë¡œ ì–´í…ì…˜ì„ ì—°ì‚°í•œ í›„, ì–´í…ì…˜ ê²°ê³¼ê°’ $Z_i$ë¥¼ ê²°í•©í•œ $Z$ì— í•™ìŠµí•œ $(n_{seq}, d_v)$ ì°¨ì›ì˜ ê°€ì¤‘ì¹˜ $W^O$ í–‰ë ¬ì„ ê³±í•´ ìµœì¢…ì ìœ¼ë¡œ multi-head ì–´í…ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.\n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `Attention` ëª¨ë¸ë¡œ, Multi-Head ì…€í”„-ì–´í…ì…˜ì„ ìˆ˜í–‰í•œë‹¤.\n\n```python\ndef Attention(d_feature, n_heads=1, dropout=0.0, mode='train'):\n  \"\"\"Returns a layer that maps `(vectors, mask)` to `(new_vectors, mask)`.\n  This layer type represents one pass of multi-head self-attention, from vector\n  set to vector set, using masks to represent out-of-bound (e.g., padding)\n  positions. ...\n  \"\"\"\n  return cb.Serial(\n      cb.Select([0, 0, 0]),\n      AttentionQKV(d_feature, n_heads=n_heads, dropout=dropout, mode=mode),\n  )\n```\n\në””ì½”ë”ì—ì„œ ì‚´í´ë³´ê² ì§€ë§Œ, `AttentionQKV`ëŠ” $Q$, $K$, $V$ë¥¼ ë‹¤ë¥¸ ì…ë ¥ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì…€í”„-ì–´í…ì…˜ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ `Attention`ì€ `Select`ë¡œ ì²«ë²ˆì§¸ ì…ë ¥ê°’ì„ 3ê°œë¡œ ë³µì œí•œ ê°’ì„ `AttentionQKV`ì— ì „ë‹¬í•œë‹¤.\n\në˜ ì¸ì½”ë”ì˜ ì…€í”„-ì–´í…ì…˜ì€ **Padding Mask**ë¥¼ í™œìš©í•œë‹¤. \n\n```python\ndef PaddingMask(pad=0):\n  \"\"\"Returns a layer that maps integer sequences to padding masks.\n  The layer expects as input a batch of integer sequences. The layer output is\n  an N-D array that marks for each sequence position whether the integer (e.g.,\n  a token ID) in that position represents padding -- value ``pad`` -- versus\n  text/content -- all other values. The padding mask shape is\n  (batch_size, 1, 1, encoder_sequence_length), such that axis 1 will broadcast\n  to cover any number of attention heads and axis 2 will broadcast to cover\n  decoder sequence positions. ...\n  \"\"\"\n  def f(x):\n    if len(x.shape) != 2:\n      raise ValueError(\n          f'Input to PaddingMask must be a 2-D array with shape '\n          f'(batch_size, sequence_length); instead got shape {x.shape}.')\n    batch_size = x.shape[0]\n    sequence_length = x.shape[1]\n    content_positions = (x != pad)\n    return content_positions.reshape((batch_size, 1, 1, sequence_length))\n  return Fn(f'PaddingMask({pad})', f)\n```\n\nì¦‰ íŒ¨ë”© í† í° `pad`ë¡œ ì„¤ì •ëœ ê°’ê³¼ ê°™ì€ ë¶€ë¶„ì„ $0$ìœ¼ë¡œ ë°”ê¾¼ë‹¤. ì¶œë ¥ ì°¨ì›ì€ `(batch_size, 1, 1, sequence_length)`ìœ¼ë¡œ, ì–´í…ì…˜ê³¼ ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ 1ë²ˆê³¼ 2ë²ˆ ì¶•ì„ ì¶”ê°€í•œë‹¤.\n\n\n## 2. Decoder\n\níŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë”ëŠ” ë‘ ê°€ì§€ ì–´í…ì…˜ì„ ê±°ì¹œë‹¤. ì²« ë²ˆì§¸ ì–´í…ì…˜ì€ ì¸ì½”ë”ì—ì„œì™€ ê°™ì€ ì…€í”„-ì–´í…ì…˜ì´ê³ , ë‘ë²ˆì§¸ëŠ” ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ì´ë‹¤. ì¸ì½”ë”ë§Œ ì‚¬ìš©í•´ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆì—ˆë˜ ê²ƒì²˜ëŸ¼, ë””ì½”ë”ë§Œ ì‚¬ìš©í•´ì„œ ëª¨ë¸ì„ í˜•ì„±í•  ìˆ˜ë„ ìˆë‹¤. ë””ì½”ë”ë§Œ ì‚¬ìš©í•  ë•Œì—ëŠ” Multi-Head ì…€í”„-ì–´í…ì…˜ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n\n![](transformer_decoder.png)\n<center>\në””ì½”ë” êµ¬ì¡°, from deeplearning.ai\n</center>\n\n</br>\n\nì¸ì½”ë”ì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë””ì½”ë”ì—ì„œë„ ì…ë ¥ê°’ $Q$, $K$, $V$ë¥¼ ì„ë² ë“œí•˜ê³  Positional Encoding ì²˜ë¦¬ë¥¼ í•œ í›„ì— Residualì„ í¬í•¨í•œ 1ï¸âƒ£ Multi-Head Attentionê³¼ 2ï¸âƒ£ FeedForward ë ˆì´ì–´ë¥¼ ê±°ì¹œë‹¤. ë””ì½”ë” ë¸”ëŸ­ì„ ì—¬ëŸ¬ë²ˆ ê±°ì¹œ í›„ì— í›ˆë ¨ ê°€ëŠ¥í•œ Linear ë ˆì´ì–´ì™€ Softmax í•¨ìˆ˜ë¥¼ ê±°ì¹˜ëŠ”ë°, ì´ ë¶€ë¶„ì€ ìˆ˜í–‰í•˜ê³ ì í•˜ëŠ” ê³¼ì œì— ë”°ë¼ ë³€ê²½í•  ìˆ˜ ìˆë‹¤.\n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `TransformerLM`ë¡œ, ë””ì½”ë”ë§Œ êµ¬í˜„ëœ í•¨ìˆ˜ì´ë‹¤.\n\n```python\ndef TransformerLM(vocab_size,\n                  d_model=D_MODEL,\n                  d_ff=D_FF,\n                  n_layers=N_LAYERS,\n                  n_heads=N_HEADS,\n                  max_len=MAX_SEQUENCE_LENGTH,\n                  dropout=DROPOUT_RATE,\n                  dropout_shared_axes=DROPOUT_SHARED_AXES,\n                  mode=MODE,\n                  ff_activation=FF_ACTIVATION_TYPE):\n\n  # ...\n\n  def _DecBlock():\n    return _DecoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,\n                         mode, ff_activation)\n\n  return tl.Serial(\n      tl.ShiftRight(mode=mode),  # Teacher Forcing\n      tl.Embedding(vocab_size, d_model),\n      _Dropout(),\n      tl.PositionalEncoding(max_len=max_len, mode=mode),\n      [_DecBlock() for _ in range(n_layers)],\n      tl.LayerNorm(),\n      tl.Dense(vocab_size),\n  )\n```\n\n`_DecoderBlock`ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n```python\ndef _DecoderBlock(d_model,\n                  d_ff,\n                  n_heads,\n                  dropout,\n                  dropout_shared_axes,\n                  mode,\n                  ff_activation):\n  # ...\n\n  return [\n      tl.Residual(\n          tl.LayerNorm(),\n          _CausalAttention(),\n          _Dropout(),\n      ),\n      tl.Residual(\n          tl.LayerNorm(),\n          _FFBlock(),\n          _Dropout(),\n      ),\n  ]\n```\n\n`TransformerLM` í•¨ìˆ˜ëŠ” Teacher Forcingì„ ê±°ì³ ì„ë² ë”©, positional encoding ì²˜ë¦¬ í›„ `n_layers`ë§Œí¼ì˜ ë””ì½”ë” ë¸”ëŸ­ì„ ê±°ì³ `tl.LayerNorm()`ê³¼ `vocab_size`ë§Œí¼ì˜ `tl.Dense()` ë ˆì´ì–´ì„ í†µê³¼í•˜ëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì‚¬ì „ì— ì£¼ì–´ì§„ ë‹¨ì–´ë“¤ì„ í†µí•´ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ vocabulary ë‚´ì˜ í† í°ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ ëª¨ë¸(language model)ì„ ìˆ˜í–‰í•œë‹¤.\n\n\n### ğŸ”† Teacher Forcing\në””ì½”ë” ë¸”ëŸ­ì— ë“¤ì–´ê°€ê¸°ì— ì•ì„œ, Teacher Forcing ê¸°ë²•ì„ í™œìš©í•´ ëª¨ë¸ì˜ í›ˆë ¨ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤. RNN ëª¨ë¸ì¸ Seq2Seq ëª¨ë¸ì€ ë°”ë¡œ ì „ ë ˆì´ì–´ì˜ ì˜ˆì¸¡ ê°’ì„ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ë•Œë¬¸ì— ëª¨ë¸ í›ˆë ¨ ì´ˆê¸°ì˜ (ëœ í›ˆë ¨ëœ) ë‚˜ìœ ì˜ˆì¸¡ ê°’ì´ ê³„ì†í•´ì„œ ëª¨ë¸ í›ˆë ¨ì— ì˜í–¥ì„ ì¤„ ê°€ëŠ¥ì„±ì´ í¬ë‹¤. ì´ëŸ° ë¬¸ì œë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ì´ì „ ë ˆì´ì–´ì˜ ì˜ˆì¸¡ê°’ì´ ì•„ë‹Œ ì‹¤ì œ íƒ€ì¼“ ê°’ì„ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ Teacher Forcingì´ë¼ê³  í•œë‹¤. ë§ˆì¹˜ ì„ ìƒë‹˜ì´ ì§ì ‘ ì´ë ‡ê²Œ í•˜ë¼ê³  ì§€ë„í•´ì£¼ëŠ” ê²ƒê³¼ ê°™ë‹¤. í›ˆë ¨ ì´ˆê¸°ì— íƒ€ê²Ÿ ê°’ì— ìˆ˜ë ´í•˜ëŠ” ê²ƒì„ ë•ê¸° ë•Œë¬¸ì—, ì´ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\nìœ„ì˜ ì½”ë“œì—ì„œ ë‚˜íƒ€ë‚œ `ShiftRight` ë ˆì´ì–´ê°€ teacher forcing ì—­í• ì„ í•œë‹¤. ì¦‰ (í•œ ì‹œì  ë¯¸ë˜ ê°’ì¸) ë°”ë¡œ ì˜¤ë¥¸ ìª½ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ê²ƒìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ëª¨ë¸ì„ êµì •í•  ìˆ˜ ìˆë‹¤. ìœ„ì˜ ì½”ë“œì—ì„œ `mode`ê°€ ì¸ìë¡œ ë“¤ì–´ê°„ ì´ìœ ë„, í•™ìŠµ ì™¸ì— ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ë•ŒëŠ” teacher forcingì„ ì ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤.\n\nê·¸ë ‡ì§€ë§Œ Teacher Forcingì€ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ê³¼ì •ì—ì„œ ì‹¤ì œ íƒ€ê²Ÿê°’ì„ ë…¸ì¶œí•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ì˜ ì•ˆì •ì„±, ì¦‰ ë³´ë‹¤ ì¼ë°˜ì ì¸ ì˜ˆì— ëŒ€í•œ ì˜ˆì¸¡ ëŠ¥ë ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ í›ˆë ¨ ì¤‘ì— Labelì— ë…¸ì¶œë˜ëŠ” ê²½ìš°ë¥¼ **Exposure Bias**ê°€ ìˆë‹¤ê³  í•œë‹¤. ì´ ë•Œë¬¸ì— curriculum learning ë°©ë²•ì—ì„œëŠ” FeedForwardì˜ í•™ìŠµ ì´ˆê¸°ì—ë§Œ ì´ì „ ë ˆì´ì–´ì˜ ì˜ˆì¸¡ê°’ì„ íƒ€ê²Ÿ ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê³  í•™ìŠµ í›„ê¸°ì—ëŠ” ëŒ€ì²´ í•˜ì§€ ì•ŠëŠ”ë‹¤.\n\n### ğŸ“£ Causal Self-Attention\n\në””ì½”ë”ì˜ ì…ë ¥ê°’ì— ëŒ€í•œ ì–´í…ì…˜ì„ ì‹¤í–‰í•  ë•Œë„ ì–´í…ì…˜ì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë¬¸ë§¥ì„ ìœ„í•´ ì…€í”„-ì–´í…ì…˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ë‹¨, ë””ì½”ë”ì˜ ì…€í”„-ì–´í…ì…˜ì€ **Causal Mask**ê°€ í•„ìš”í•˜ë‹¤. ì•ì—ì„œì™€ ê°™ì´ ê¸°ê³„ ë²ˆì—­ ê³¼ì œë¥¼ ê³ ë ¤í•´ë³´ì. RNNì€ ë””ì½”ë”ì˜ ì…ë ¥ê°’ì— ìˆœì°¨ì ìœ¼ë¡œ ì ‘ê·¼í•´ ë§¤ë²ˆ ì¸ì½”ë”ì˜ ê²°ê³¼ê°’ê³¼ í•´ë‹¹ ì‹œì ì˜ ë””ì½”ë” ì…ë ¥ê°’ì„ ë¹„êµí•  ê²ƒì´ë‹¤. ê·¸ë ‡ì§€ë§Œ ì–´í…ì…˜ì€ ëª¨ë“  ì‹œì ì˜ ë°ì´í„°ë¥¼ í•œë²ˆì— ë³¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íŠ¹ì • ì‹œì ì—ì„œ ëª¨ë¸ì˜ íƒ€ê¹ƒì¸ ì˜¤ë¥¸ìª½ ê°’ì— ëŒ€í•œ ì ‘ê·¼(attend)ì„ ë°©ì§€í•´ì•¼ í•œë‹¤.\n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Traxì˜ `_causal_mask`ë¡œ, ì¸ìë¡œ ë°›ì€ `length` ê¸¸ì´ ì •ë°© í–‰ë ¬ì˜ lower triangular í–‰ë ¬ì„ ë°˜í™˜í•œë‹¤.  \n\n```python\ndef _causal_mask(length):\n  # Not all backends define jnp.tril. However, using np.tril is inefficient\n  # in that it creates a large global constant. TODO(kitaev): try to find an\n  # alternative that works across all backends.\n  if fastmath.is_backend(fastmath.Backend.JAX):\n    return jnp.tril(jnp.ones((1, length, length), dtype=np.bool_), k=0)\n  else:\n    return np.tril(np.ones((1, length, length), dtype=np.bool_), k=0)\n```\n\n`DotProductCausalAttention` ì–´í…ì…˜ì€ 1ê°œ Head ì–´í…ì…˜ì„ êµ¬í˜„í•˜ëŠ” í•¨ìˆ˜ë¡œ `CausalAttention`ìœ¼ë¡œ êµ¬í˜„ë  ìˆ˜ ìˆë‹¤. ì£¼ëª©í•´ì„œ ë³¼ ì ì€ ëª¨ë¸ì´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì§€ ì•Šì„ ë•Œë§Œ Causal Maskë¥¼ í™œìš©í•˜ëŠ” ì ì´ë‹¤.\n\n```python\nclass DotProductCausalAttention(base.Layer):\n  \"\"\"Layer that computes attention strengths by masking out the \"future\".\n  Causal attention uses masking to prevent a given sequence position from\n  attending to positions greater than / following it. This is used, for\n  example, when training autoregressive sequence models, or when decoding a\n  sequence symbol by symbol.\n  This layer performs the core per-head attention calculation. The layer\n  assumes that any splitting into attention heads precedes it, and that any\n  merging of attention heads will follow it.\n  \"\"\"\n  # ...\n\n  def forward(self, inputs):\n    \"\"\"Returns attention-computed activations.\n    Args:\n      inputs: A (queries, keys, values) tuple.\n    \"\"\"\n    q, k, v = inputs\n\n    # ...\n\n    if self._mode == 'predict':\n      self.state, mask = _fast_inference_update_state(\n          inputs, self.state,\n          mask_for_predict=mask_for_predict)\n      # ...\n    else:\n      sequence_length = q.shape[-2]\n      mask = _causal_mask(sequence_length)\n\n    activations, attn_strengths = _per_head_attention(\n        q, k, v, mask, dropout=self._dropout, mode=self._mode, rng=self.rng)\n    #...\n    return activations\n\n    # ...\n```\n\n\n### ğŸ“£ Encoder-Decoder Attention\n\nì´ì œ ë””ì½”ë”ì˜ ì…ë ¥ê°’ê³¼ ì¸ì½”ë”ì˜ ì…ë ¥ê°’ì„ ë¶„ì„í•˜ëŠ” ê³¼ì œê°€ ë‚¨ì•˜ë‹¤. ì¸ì½”ë”-ë””ì½”ë” ë¸”ëŸ­ì˜ ì…ë ¥ê°’ì€ `(vec_d, mask, vec_e)`ë¡œ íŒ¨ë”© ë§ˆìŠ¤í¬ `mask`ë¥¼ ì´ìš©í•´ íŒ¨ë”©ëœ ê°’ì— ëŒ€í•´ì„œëŠ” ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤. \n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `AttentionQKV` í•¨ìˆ˜ë¡œ, `Attention`ì´ ì…€í”„-ì–´í…ì…˜ë§Œ ìˆ˜í–‰í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬ $Q$ì™€ $K-V$ë¥¼ ë‹¤ë¥¸ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì„ í—ˆìš©í•œë‹¤. \n\n```python\ndef AttentionQKV(d_feature, n_heads=1, dropout=0.0, mode='train',\n                 cache_KV_in_predict=False, q_sparsity=None,\n                 result_sparsity=None):\n  # ...\n\n  return cb.Serial(\n      cb.Parallel(_SparsifiableDense(q_sparsity),\n                  _CacheableDense(),\n                  _CacheableDense()),\n      _PureAttention(),\n      _SparsifiableDense(result_sparsity),\n  )\n```\n\n`cb.Parallel`ì€ $Q$ì— í•´ë‹¹í•˜ëŠ” ì…ë ¥ì„ ë°€ë„ `q_sparsity`ë¥¼ ê°€ì§€ëŠ” í–‰ë ¬ë¡œ, ê·¸ë¦¬ê³  $K$ì™€ $V$ì— í•´ë‹¹í•˜ëŠ” ì…ë ¥ì„ `d_feature`ë§Œí¼ì˜ `Dense` ë ˆì´ì–´ë¡œ ë‘ê³ , `_PureAttention`ê³¼ ì¼ì¢…ì˜ í›ˆë ¨ê°€ëŠ¥í•œ `Dense` ë ˆì´ì–´ë¥¼ í†µê³¼í•œë‹¤.\n\nìµœì¢…ì ìœ¼ë¡œ Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `_EncoderDecoderBlock` í•¨ìˆ˜ë¥¼ ë³´ì.\n\n```python\ndef _EncoderDecoderBlock(d_model,\n                         d_ff,\n                         n_heads,\n                         dropout,\n                         dropout_shared_axes,\n                         mode,\n                         ff_activation):\n\n  def _Dropout():\n    return tl.Dropout(rate=dropout, shared_axes=dropout_shared_axes, mode=mode)\n\n  def _AttentionQKV():\n    return tl.AttentionQKV(d_model, n_heads=n_heads, dropout=dropout,\n                           mode=mode, cache_KV_in_predict=True)\n\n  def _CausalAttention():\n    return tl.CausalAttention(d_model, n_heads=n_heads, mode=mode)\n\n  def _FFBlock():\n    return _FeedForwardBlock(d_model, d_ff, dropout, dropout_shared_axes, mode,\n                             ff_activation)\n\n  return [                             # vec_d masks vec_e\n      tl.Residual(\n          tl.LayerNorm(),\n          _CausalAttention(),\n          _Dropout(),\n      ),\n      tl.Residual(\n          tl.LayerNorm(),\n          tl.Select([0, 2, 2, 1, 2]),  # vec_d vec_e vec_e masks vec_e\n          _AttentionQKV(),             # vec_d masks vec_e\n          _Dropout(),\n      ),\n      tl.Residual(\n          tl.LayerNorm(),\n          _FFBlock(),\n          _Dropout(),\n      ),\n  ]\n```\n\n`_EncoderDecoderBlock`ì€ ë””ì½”ë” ë²¡í„°, ë§ˆìŠ¤í¬, ì¸ì½”ë” ë²¡í„° ìŒì¸ `(vec_d, masks, vec_e)`ë¥¼ ì…ë ¥ë°›ëŠ”ë‹¤. ì—¬ê¸°ì„œ ë””ì½”ë”ì˜ ë‘ê°€ì§€ ì–´í…ì…˜ì„ ëª¨ë‘ ì‹¤í–‰í•˜ê³  ìˆìŒì— ìœ ì˜í•œë‹¤. ì²«ì§¸ë¡œ `_CausalAttention`ì„ ì ìš©í•œ í›„ `(vec_d, vec_e, vec_e, masks, vec_e)`ë¡œ ë°ì´í„°ë¥¼ ì •ë ¬í•œë‹¤. ì•ì—ì„œ ë¶€í„° ì„¸ ê°œ ì…ë ¥ì´ `_AttentionQKV()`ë ˆì´ì–´ë¥¼ ê±°ì³ì„œ ì…ë ¥ê°’ê³¼ ê°™ì€ ì°¨ì›ì¸ `(vec_d, masks, vec_e)`ë¥¼ ì–»ì–´ FeedForward ë¸”ëŸ­ì„ ê±°ì¹œë‹¤. ì¦‰ ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ì—ì„œëŠ” ë””ì½”ë” ë²¡í„°ë¥¼ $Q$ë¡œ, ì¸ì½”ë” ë²¡í„°ë¥¼ $K$ì™€ $V$ë¡œ ì…ë ¥ë°›ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n\n## 4. Overall\n\në‹¤ìŒì€ ì¸ì½”ë”©ê³¼ ë””ì½”ë”©ì„ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ”ê·¸ë¦¼ìœ¼ë¡œ, ì˜ì–´ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­í•˜ëŠ” ì˜ˆì‹œë¥¼ ë³´ì´ê³ ìˆë‹¤.\n\n![](https://3.bp.blogspot.com/-aZ3zvPiCoXM/WaiKQO7KRnI/AAAAAAAAB_8/7a1CYjp40nUg4lKpW7covGZJQAySxlg8QCLcBGAs/s1600/transform20fps.gif) \n*Cool gif from [Google AI blog](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)*\n\nTransformer ëª¨ë¸ì€ ì¸ì½”ë”ë‚˜ ë””ì½”ë”ë§Œìœ¼ë¡œë„ ì“°ì„ì´ ìˆì§€ë§Œ, ê¸°ê³„ ë²ˆì—­ê³¼ ê°™ì€ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤ ê³¼ì œì—ëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ëª¨ë‘ í™œìš©í•´ì•¼ í•œë‹¤. ì•„ë˜ì˜ `Transformer` ëª¨ë¸ì€ ì•ì„œ ì‚´í´ ë³¸ ì¸ì½”ë”ì™€ ë””ì½”ë” ë¸”ëŸ­ì„ í™œìš©í•´ ì „ì²´ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ë°˜í™˜í•œë‹¤.\n\nğŸ“‚ ë‹¤ìŒ ì½”ë“œëŠ” Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `Transformer` ëª¨ë¸ì´ë‹¤.\n\n```python\ndef Transformer(input_vocab_size,\n                output_vocab_size=None,\n                d_model=D_MODEL,\n                d_ff=D_FF,\n                n_encoder_layers=N_LAYERS,\n                n_decoder_layers=N_LAYERS,\n                n_heads=N_HEADS,\n                max_len=MAX_SEQUENCE_LENGTH,\n                dropout=DROPOUT_RATE,\n                dropout_shared_axes=DROPOUT_SHARED_AXES,\n                mode=MODE,\n                ff_activation=FF_ACTIVATION_TYPE):\n  \"\"\"Returns a full Transformer model.\n  This model is an encoder-decoder that performs tokenized string-to-string\n  (\"source\"-to-\"target\") transduction:\n  \"\"\"\n\n  # ...\n\n  def _Dropout():\n    return tl.Dropout(rate=dropout, shared_axes=dropout_shared_axes, mode=mode)\n\n  def _EncBlock():\n    return _EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,\n                         mode, ff_activation)\n\n  def _Encoder():\n    encoder = tl.Serial(\n        in_embedder,\n        _Dropout(),\n        tl.PositionalEncoding(max_len=max_len, mode=encoder_mode),\n        [_EncBlock() for _ in range(n_encoder_layers)],\n        tl.LayerNorm(),\n    )\n    return tl.Cache(encoder) if mode == 'predict' else encoder\n\n  def _EncDecBlock():\n    return _EncoderDecoderBlock(d_model, d_ff, n_heads, dropout,\n                                dropout_shared_axes, mode, ff_activation)\n\n  # Input to model is encoder-side tokens and decoder-side tokens: tok_d, tok_e\n  # Model output is decoder-side vectors and decoder-side tokens: vec_d  tok_d\n  return tl.Serial(\n      tl.Select([0, 1, 1]),  # Copies decoder tokens for use in loss.\n\n      # Encode.\n      tl.Branch([], tl.PaddingMask()),  # tok_e masks tok_d tok_d\n      _Encoder(),\n\n      # Decode.\n      tl.Select([2, 1, 0]),  # Re-orders inputs: tok_d masks vec_e .....\n      tl.ShiftRight(mode=mode),\n      out_embedder,\n      _Dropout(),\n      tl.PositionalEncoding(max_len=max_len, mode=mode),\n      tl.Branch([], tl.EncoderDecoderMask()),  # vec_d masks ..... .....\n      [_EncDecBlock() for _ in range(n_decoder_layers)],\n      tl.LayerNorm(),\n      tl.Select([0], n_in=3),  # Drops masks and encoding vectors.\n\n      # Map vectors to match output vocab size.\n      tl.Dense(output_vocab_size),\n  )\n```\n\n`Transformer` ëŠ” ì¸ì½”ë”ì— ì…ë ¥ë˜ëŠ” í† í°ê³¼ ë””ì½”ë”ì— ì…ë ¥ë˜ëŠ” í† í° ìŒ `(tok_d, tok_e)`ë¥¼ ì…ë ¥ë°›ì•„ ë””ì½”ë” ë²¡í„°ì™€ ë””ì½”ë” í† í° ìŒ `(vec_d, tok_d)`ë¥¼ ë°˜í™˜í•œë‹¤. `tl.Branch`ë¡œ ì…ë ¥ê°’ê³¼ íŒ¨ë”©ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•œ í›„ `_Encoder()`ë¡œ ì¸ì½”ë”©ì„ ì‹¤í–‰í•œë‹¤. `_Encoder`ëŠ” `n_encoder_layers`ê°œì˜ ì¸ì½”ë” ë¸”ëŸ­ `_EncoderDecoderBlock`ì„ í¬í•¨í•˜ë„ë¡ ì •ì˜ë˜ì–´ ìˆë‹¤. ì¸ì½”ë”©ì„ ê±°ì¹˜ë©´ ë°ì´í„°ëŠ” `(vec_e, masks, tok_d)`ê°€ ë˜ë©° `tl.Select`ë¡œ ìˆœì„œë¥¼ ë’¤ì§‘ì–´ teacher forcingê³¼ positional encodingì„ ì‹¤í–‰í•œë‹¤. ë‘ë²ˆì§¸ `tl.Branch`ë¡œ `(tok_d, masks)`ë¥¼ ì¸ì½”ë”-ë””ì½”ë” ë¸”ëŸ­ì— ì…ë ¥í•˜ë©°, ì´ ì™¸ì˜ ê°’ë“¤ì€ ì´í›„ `tl.Select`ë¡œ ì œì™¸ì‹œí‚¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. `_EncoderDecoderBlock`ì€ ì•ì—ì„œ ì‚´í´ë³¸ ëŒ€ë¡œë‹¤. ì´ë¡œì¨ `Transformer`í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒë§Œìœ¼ë¡œ  íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n\n\n## ë‚˜ê°€ë©°\n\nì—¬ëŸ¬ ë‚´ìš©ì„ ë‹¤ë£¨ë‹¤ë³´ë‹ˆ ê¸€ì´ ê¸¸ì–´ì¡Œë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ ê¸´ ì‹œí€€ìŠ¤ì—ì„œ ë§¥ë½ì„ ì¶”ì¶œí•˜ëŠ”ë°ì— ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë¡œ ë„ë¦¬ ì“°ì´ê³  ìˆì§€ë§Œ, ì§§ì€ ì‹œí€€ìŠ¤ë¥¼ ë¶„ì„í•˜ê±°ë‚˜ ë§¥ë½ì„ êµ¬í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œì— ëŒ€í•´ì„œëŠ” ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. í•œí¸ìœ¼ë¡œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ì´ë¯¸ì§€ì— ì ìš©í•œ ì‚¬ë¡€ë‚˜ ë‹¤ì–‘í•œ ê³¼ì œë¥¼ í•œë²ˆì— ìˆ˜í–‰í•˜ëŠ” T5, ë” ê¸´ ì‹œí€€ìŠ¤ì— ëŒ€í•´ íš¨ìœ¨ì ($O(NlogN)$)ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë¦¬í¬ë¨¸ ëª¨ë¸ ë“± ë‹¤ì–‘í•œ ë²„ì „ì´ ë“±ì¥í•˜ê³  ìˆìœ¼ë¯€ë¡œ, íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê¸°ë³¸ì ì¸ êµ¬ì¡°ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•  ê²ƒì´ë‹¤. \n\nê¸€ë¡œ ì •ë¦¬í•˜ë©´ì„œ ë‚˜ì˜ ë§¹ì ì— ëŒ€í•´ ì•Œ ìˆ˜ ìˆì—ˆë‹¤. Residualì´ ì™œ í•„ìš”í•œì§€, ì¸ì½”ë”ë‚˜ ë””ì½”ë” ë¸”ëŸ­ì„ ì™œ ì—¬ëŸ¬ë²ˆ ì‹¤í–‰í•˜ëŠ”ì§€, ì–´í…ì…˜ì—ì„œ í•™ìŠµí•˜ëŠ” íŒŒë¼ë¯¸í„°ëŠ” ì–´ëŠ ë¶€ë¶„ì¸ì§€ ìƒê°í•˜ì§€ ì•Šê³  ë„˜ê¸°ë‹¤ê°€ ë…¼ë¬¸ì„ ì½ìœ¼ë©´ì„œ ì €ìì˜ ì˜ë„ì™€ historyë¥¼ ì¡°ê¸ˆ ë” ì´í•´í•  ìˆ˜ ìˆì—ˆë‹¤. ë˜ ê¸€ì„ ì“°ë©´ì„œ Trax ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì½”ë“œë¥¼ ë¶€ë¶„ì ìœ¼ë¡œ ë“¤ì—¬ë‹¤ë´¤ë‹¤. `Select()`ë‚˜ `Residual()`, `Branch()`ë¡œ ë ˆì´ì–´ë¥¼ ìŒ“ëŠ” ë¶€ë¶„ì€ ê·¸ë¦¼ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë– ì˜¤ë¥´ëŠ” ê°œë…ì„ ì½”ë“œë¡œ í‘œí˜„í•´ ì§ê´€ì ì´ë¼ëŠ” ëŠë‚Œì´ ë“¤ì—ˆê³ , ì¸ì½”ë”ë‚˜ ë””ì½”ë”ì˜ ì¼ë¶€ë¶„ì„ ë”°ë¡œ ë–¼ì–´ì„œ ì‚¬ìš©í•˜ëŠ” ê°ê°ì˜ í•¨ìˆ˜ê°€ ìˆì–´ ì‚¬ìš© í¸ì˜ë¥¼ ê³ ë ¤í•œ ì ì´ ëŠê»´ì¡Œë‹¤. í° í”„ë¡œê·¸ë¨(ë¼ì´ë¸ŒëŸ¬ë¦¬)ì˜ ì½”ë“œì´ë‹¤ë³´ë‹ˆ ì¬ì‚¬ìš©ë˜ëŠ” ë¶€ë¶„ê³¼ ì¡°ê¸ˆì”© ì°¨ì´ë‚˜ëŠ” ë¶€ë¶„, íŠ¹íˆ ë©”ì„œë“œì˜ ì˜ì¡´ë„ë¥¼ ë¯¸ë¦¬ ë””ìì¸í•´ì„œ í° ê·¸ë¦¼ì„ ì—¼ë‘ì— ë‘ê³  í”„ë¡œê·¸ë¨ì„ ì‘ì„±í–ˆë‹¤ëŠ” ì ì´ ëŠê»´ì¡Œë‹¤. ê²°êµ­ ì´ë¡ ê³¼ êµ¬í˜„ì´ ëª¨ë‘ ì¤‘ìš”í•˜ê³  ë‚˜ë¦„ì˜ ê¹Šì´ê°€ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.\n\n\n## ì°¸ê³  ìë£Œ\n1. Natural Language Processing with Attention Models, deeplearning.ai, Coursera, https://www.coursera.org/specializations/natural-language-processing\n2. Trax Library for Machine Learning, Github, https://github.com/google/trax\n3. Transformers, Google AI blog, https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n4. Vaswani et al, 2017, https://arxiv.org/abs/1706.03762\n5. Jay Alammar on Github page, https://jalammar.github.io/illustrated-transformer/\n","excerpt":"ì› ë…¼ë¬¸: Vaswani et al., 2017, \"Attention is all you need\" (Link to arxiv) 0. Transformer   íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” Seq2Seq ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ë¥¼ ê°–ê³  ìˆì§€ë§Œ, ë³´ë‹¤ ê¸´ ì‹œí€€â€¦","fields":{"slug":"/transformer/"},"frontmatter":{"date":"Mar 31, 2022","title":"Transformer (2017)","tags":["NLP","Attention","Transformer"],"update":"Apr 14, 2022"}}},{"node":{"rawMarkdownBody":"\n\nì´ ê¸€ì€ deeplearning.aiì˜ NLP Specializationë¥¼ ì°¸ê³ í•˜ì—¬ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì„ í…ìŠ¤íŠ¸ ì •ì„œ ë¶„ì„ì— ì´ˆì ì„ ë§ì¶° ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤.\n\n> [Githubì—ì„œ Naive Bayes ì½”ë“œ ë³´ê¸°](https://github.com/snowith/nlp_model_practices/blob/main/naive_bayes/naive_bayes_sentiment.ipynb)\n\n\n## 0. ëª¨ë¸ ê°œëµ\në‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì€ ë¶„ë¥˜ ê³¼ì œë¥¼ ìœ„í•œ í™•ë¥  ëª¨ë¸ì´ë‹¤. í›ˆë ¨ ë°ì´í„°ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ë‹¨ì–´ì˜ ë¹ˆë„ë¥¼ ì„¸ì–´ì„œ ê° ë°ì´í„°ì— ëŒ€í•œ ì¡°ê±´ë¶€ í™•ë¥ ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•˜ë¯€ë¡œ ë¶„ë¥˜ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ëŠ”ë° ì í•©í•˜ë‹¤.\n\n### ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì€\n- í›ˆë ¨ê³¼ ì˜ˆì¸¡ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ baseline ëª¨ë¸ë¡œ ì í•©í•˜ë‹¤.\n- ë¬¸ì¥ì— ìˆëŠ” ê° ë‹¨ì–´ë“¤ì´ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•˜ê¸° ë•Œë¬¸ì—, ë¬¸ì¥ ë‚´ ë‹¨ì–´ë“¤ì˜ ê´€ê³„ë¥¼ ì¸¡ì •í•˜ê±°ë‚˜ ë¬¸ì¥ ë‚´ì˜ ë¹ˆì¹¸ì„ ì±„ìš°ëŠ” ë“±ì˜ ê³¼ì œì—ëŠ” ì í•©í•˜ì§€ ì•Šë‹¤.\n- í›ˆë ¨ ë°ì´í„° ë‚´ ë‹¨ì–´ë“¤ì´ ë“±ì¥í•˜ëŠ” ë¹ˆë„ì— ê¸°ë°˜í•˜ê¸° ë•Œë¬¸ì—, í›ˆë ¨ ë°ì´í„°ì— í¬í•¨ë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ë‹¨ì–´ì— ëŒ€í•œ ì˜ˆì¸¡ì´ë‚˜ ë‹¨ì–´ì˜ ìˆœì„œë¥¼ íŒë‹¨í•˜ëŠ” ê³¼ì œì—ëŠ” ì í•©í•˜ì§€ ì•Šë‹¤.\n- ê°ì • ë¶„ì„, ì €ì ë¶„ë¥˜, ìŠ¤íŒ¸ í•„í„°ë§, ë¬¸ì„œ ìš”ì•½, ë™ìŒì´ì˜ì–´ êµ¬ë¶„ ë“±ì˜ ê³¼ì œì— í™œìš©í•  ìˆ˜ ìˆë‹¤.\n\nì´ ê¸€ì—ì„œëŠ” ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ë¡œ ì´ì§„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ìƒí™©ì„ ê°€ì •í•˜ê² ë‹¤. íŠ¹íˆ ì–´ë–¤ ë¬¸ì¥ì„ ì…ë ¥ ë°›ì•„ì„œ ë¬¸ì¥ì´ ê¸ì •ì ì¸ ì •ì„œë¥¼ ë‚´í¬í•˜ê³  ìˆìœ¼ë©´ `1`ì„, ë¶€ì •ì ì¸ ì •ì„œë¥¼ ë‚´í¬í•˜ê³  ìˆìœ¼ë©´ `0`ì„ ë°˜í™˜í•˜ëŠ” ê°ì • ë¶„ì„(sentiment analysis) ê³¼ì œë¥¼ ìˆ˜í–‰í•œë‹¤.\n\n```python\ninput_s = 'This is my best day ever.'\nmodel(input_s) # 1, ê¸ì •\n\ninput_s = 'the class was in a terrible mood...'\nmodel(input_s) # 0, ë¶€ì •\n```\n_ìœ„ì™€ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ `model`ì„ ì–»ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤._\n\n\n\n## 1. ì¡°ê±´ë¶€ í™•ë¥ ê³¼ ë² ì´ì¦ˆ ë£°\nëª¨ë¸ì„ ì‚´í´ë³´ê¸°ì— ì•ì„œ ì¡°ê±´ë¶€ í™•ë¥ ê³¼ ë² ì´ì¦ˆ ë£°ì— ëŒ€í•´ ì•Œì•„ë³´ì.\n\n### ğŸ² ì¡°ê±´ë¶€ í™•ë¥ (Conditional Probability) ì´ë€?\nëª¨ìˆ˜ì—ì„œ ì¡°ê±´ Aê°€ ë§Œì¡±ë  í™•ë¥ ì„ $P(A)$, ì¡°ê±´ Bê°€ ë§Œì¡±ë  í™•ë¥ ì„ $P(B)$ë¼ê³  í•˜ì. ì´ë•Œ Bì— ëŒ€í•œ Aì˜ ì¡°ê±´ë¶€ í™•ë¥  $P(A|B)$ ëŠ” ì¡°ê±´ Bë¥¼ ë§Œì¡±í•˜ëŠ” í‘œë³¸ì—ì„œ ì¡°ê±´ Aë¥¼ ë§Œì¡±í•˜ëŠ” í‘œë³¸ì„ ì„ íƒí•  í™•ë¥ ì„ ì˜ë¯¸í•œë‹¤. ì¦‰ $P(A|B)$ëŠ” ì¡°ê±´ Aì™€ Bë¥¼ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” í‘œë³¸ì„ ì„ íƒí•  í™•ë¥ ì¸ $P(A \\cap B)$ì— ëª¨ìˆ˜ì—ì„œ ì¡°ê±´ Bë¥¼ ë§Œì¡±í•˜ëŠ” í‘œë³¸ì„ ì„ íƒí•  í™•ë¥  $P(B)$ë¥¼ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ ì •ì˜ëœë‹¤.\n\n$$\nP(A|B) =\\frac{P(A \\cap B)}{P(B)}\n$$\n\nì¡°ê±´ë¶€ í™•ë¥ ì€ ë½‘ì„ ìƒ˜í”Œì˜ ë²”ìœ„ë¥¼ í‘œë³¸ ëŒ€ì‹  ì¡°ê±´ìœ¼ë¡œ ì œí•œí•˜ëŠ” íš¨ê³¼ê°€ ìˆë‹¤. \n\n### ğŸ² ë² ì´ì¦ˆ ì •ë¦¬ë€\nìœ„ì˜ ì •ì˜ë¡œ ë¶€í„° ë‘ê°œì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ í‘œí˜„ í•  ìˆ˜ ìˆë‹¤.\n\n$$\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} \\\\\nP(B|A) = \\frac{P(A \\cap B)}{P(A)} \n$$\n\nì˜ˆë¥¼ ë“¤ì–´ ì¡°ê±´ `A`ê°€ `20ëŒ€`ì´ê³  ì¡°ê±´ `B`ê°€ `ì‹¬ì¥ë³‘`ì´ë¼ê³  í•˜ì. ëª‡ ê°œì˜ ë³‘ì›ì—ì„œ í‘œë³¸ ì§‘ë‹¨ì„ ëª¨ì•„ì„œ **ì‹¬ì¥ë³‘ì— ê±¸ë¦° ì‚¬ëŒì´ 20ëŒ€ì¼ í™•ë¥ **ì„ ì¡°ì‚¬í•˜ê³ ì í•œë‹¤. ìš°ë¦¬ëŠ” í‘œë³¸ ì§‘ë‹¨ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë¶€í„° **ì‹¬ì¥ë³‘ì´ ê±¸ë¦° ì‚¬ëŒì˜ ë¹„ìœ¨**ê³¼ **20ëŒ€ì˜ ë¹„ìœ¨**ì„ ì•Œê³ ìˆìœ¼ë©°, ë‚˜ì•„ê°€ **20ëŒ€ ì¤‘ì—ì„œ ì‹¬ì¥ë³‘ì— ê±¸ë¦° ì‚¬ëŒì˜ ë¹„ìœ¨**ì„ ì•Œ ìˆ˜ ìˆë‹¤. ë² ì´ì¦ˆ ì •ë¦¬ëŠ” ì„¸ê°€ì§€ ì •ë³´ë¡œë¶€í„° ì‹¬ì¥ë³‘ì— ê±¸ë¦° ì‚¬ëŒì´ 20ëŒ€ì¼ í™•ë¥ ì„ ë„ì¶œí•œë‹¤. ëŒ€ìˆ˜ ì—°ì‚°ì„ í†µí•´ $P(A|B)$ë¥¼ $P(B|A)$ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.\n\n$$\nP(A|B) = \\frac{P(A)}{P(B)} \\times P(B|A) ...... (*)\n$$\n\në‘ ì¡°ê±´ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìˆ˜ì‹ (*)ì„ **ë² ì´ì¦ˆ ì •ë¦¬**ë¼ê³  í•œë‹¤. ì´ë•Œ $P(A)$ë¥¼ **ì‚¬ì „í™•ë¥ (prior)**, $P(A|B)$ë¥¼ **ì‚¬í›„í™•ë¥ (posterior)**, ê·¸ë¦¬ê³  $P(B|A)$ë¥¼ **ìš°ë„(likelihood)**ë¼ê³  ë¶€ë¥¸ë‹¤.\n\n\n## 3. ì¡°ê±´ë¶€ ë¹ˆë„ ì„¸ê¸°\ní…ìŠ¤íŠ¸ê°€ ë‚´í¬í•˜ëŠ” ê°ì •ì„ ì´ì§„ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ë¶„ë¥˜ í´ë˜ìŠ¤ë¥¼ $class \\in \\{positive, negative\\}$ë¡œ ì •ì˜í•˜ì. $m$ê°œì˜ ë‹¨ì–´ë¥¼ í¬í•¨í•˜ëŠ” corpusì— ì†í•˜ëŠ” ë‹¨ì–´ $w_i \\in corpus$ì— ëŒ€í•´ ìš°ë¦¬ê°€ êµ¬í•˜ê³ ì í•˜ëŠ” ê°’ì€ $P(class|w_i)$, ì¦‰ ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ë‹¨ì–´ê°€ íŠ¹ì • classì— ì†í•  í™•ë¥ ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤. ë² ì´ì¦ˆ ì •ë¦¬ë¥¼ ë– ì˜¬ë ¤ ë³´ë©´:\n\n$$\nP(class|w_i) = \\frac{P(class) \\cdot P(w_i|class)}{P(w_i)}\n$$\n\nì´ë©° $P(w_i)$ëŠ” $w_i$ì— ëŒ€í•œ ìƒìˆ˜ê°’ì´ë¯€ë¡œ í™•ë¥ ì„ ê³„ì‚°í•  ë•Œ ë¬´ì‹œí•  ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ë¬¸ì¥ì„ ì…ë ¥ë°›ì•„ ê° ë‹¨ì–´ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ ê³„ì‚°í•´ì„œ ë‚˜ì´ë¸Œ ê°€ì •ì— ë”°ë¼ í•œ ë¬¸ì¥ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ ë°˜í™˜í•˜ê³ ì í•œë‹¤. ë”°ë¼ì„œ **ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ** ëª¨ë¸ì˜ ì•„ì´ë””ì–´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥ $sentence$ì— ì†í•œ ëª¨ë“  ë‹¨ì–´ $w_i \\in sentence$ ($i=1, .., n$)ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤: \n\n$$\n\\hat{y} = argmax_{class} P(class) \\prod_{i=1}^{n}P(w_i|class)\n$$\n\nìœ„ ì‹ì€ ìµœëŒ€ ìš°ë„ ì¶”ì •(Maximum Likelihood Estimation, MLE)ì˜ ì•„ì´ë””ì–´ì´ê¸°ë„ í•˜ë‹¤. ìš°ì„ ì€ corpusì— ëŒ€í•œ ì¡°ê±´ë¶€ ë¹ˆë„ì¸ $P(w_i|class)$ë¥¼ ê³„ì‚°í•´ì•¼ í•œë‹¤.\n\në‹¤ì‹œ ë² ì´ì¦ˆ ì •ë¦¬ì— ì˜í•´, í´ë˜ìŠ¤ì— ëŒ€í•œ ì¡°ê±´ë¶€ í™•ë¥ ì„ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.\n\n$$\n\\begin{aligned}\nP(w | class) &= \\frac{P(w \\cap class)}{P(class)} \\\\\n&= \\frac{freq(w, class)}{N_{class}}\n\\end{aligned}\n$$\n\nìœ„ ì‹ì—ì„œ $freq(w, class)$ëŠ” $class$ì—ì„œ $w$ê°€ ë‚˜íƒ€ë‚˜ëŠ” íšŸìˆ˜ë¡œ, $P(w \\cap class)$ì™€ ê°™ë‹¤. $N_{class}$ëŠ” í´ë˜ìŠ¤ì— í¬í•¨ë˜ëŠ” ëª¨ë“  ë‹¨ì–´ì˜ ë¹ˆë„ì´ë‹¤.\n\n### ğŸ² Laplacian Smoothing\nLaplacian Smoothingì€ ì¡°ê±´ë¶€ í™•ë¥ ì´ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ì´ë‹¤. ìœ„ì—ì„œ ë³¸ ìµœëŒ€ ìš°ë„ ì¶”ì •ì— ë”°ë¥´ë©´ ëª¨ë“  íŠ¹ì„±ì— ëŒ€í•´ likelihoodë¥¼ ê³±í•˜ê²Œ ë˜ëŠ”ë°, ë§Œì•½ corpusì— ì—†ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ì˜¤ë©´ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì— ê´€ê³„ì—†ì´ ì˜ˆì¸¡ê°’ì´ 0ì´ ë  ê²ƒì´ë‹¤. ë¶„ìê°’ì— biasë¥¼ 1 ë”í•˜ë©´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. \n\n$$\nP(w|class) = \\frac{freq(w, class) + 1}{N_{class} + V_{class}}\n$$\n\n$V_{class}$ëŠ” í´ë˜ìŠ¤ì— ë“±ì¥í•˜ëŠ” **ìœ ì¼í•œ** ë‹¨ì–´ì˜ ê°œìˆ˜ì´ë‹¤. ë¶„ëª¨ì—ëŠ” $V_{class}$ë¥¼ ë”í•¨ìœ¼ë¡œì„œ ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•œ likelihoodê°€ 1ì´ ë„˜ì§€ ì•Šë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆë‹¤:\n\n$$\n\\sum_{w}P(w|class) = \\frac{\\sum_w freq(w,class) + V_{class}}{N_{class} + V_{class}}\n$$\n\n\n\n## 3. Likelihood ê³„ì‚°í•˜ê¸°\nì•ì—ì„œ í‘œí˜„í•œ ìµœëŒ€ ìš°ë„ ì¶”ì • ë°©ì‹ì„ ì¡°ê¸ˆ ë³€í˜•í•´, ì´ ê¸€ì—ì„œëŠ” **Likelihood-ratio** ë°©ë²•ì„ í†µí•´ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ ì í•œë‹¤. \n\nìš°ì„  ratioë€ ë¶„ë¥˜ $class$ì— ëŒ€í•œ ì¡°ê±´ë¶€ í™•ë¥ ì˜ ë¹„ìœ¨ì´ë‹¤. ì„ì˜ì˜ ë‹¨ì–´ $w_i$ì— ëŒ€í•´ $ratio(w_i)$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆë‹¤.\n\n$$\nratio(w_i) = \\frac{P(w_i|Pos)}{P(w_i|Neg)}\n$$\n\nLikelihoodë€ í‘œë³¸ì„ ê²°í•© í™•ë¥ ë¡œ ë‚˜íƒ€ë‚¸ í•¨ìˆ˜ì´ë©°, ì—¬ê¸°ì„œëŠ” ì…ë ¥ ë¬¸ì¥$s$ê°€ ì„ì˜ì˜ $class$ì¼ í™•ë¥ ì„ ì˜ë¯¸í•œë‹¤. ì—¬ê¸°ì„œëŠ” Likelihoodë¥¼ ratioì— ëŒ€í•´ ì •ì˜í•˜ì. ì¦‰ ëª¨ë“  ì…ë ¥ê°’ $w_i \\in s$ì— ëŒ€í•´ ratioë¥¼ ê³±í•œ ê°’ìœ¼ë¡œ í‘œí˜„í•œë‹¤.\n\n$$\nlikelihood(s) = \\prod^{m}_{i=1}\\frac{P(w_i|Pos)}{P(w_i|Neg)}\n$$\n\në§Œì•½ ì…ë ¥ê°’ì˜ ëª¨ë“  ë‹¨ì–´ $w_i$ê°€ corpusì˜ ê¸ì •ì ì¸ ë¼ë²¨ê³¼ ë¶€ì •ì ì¸ ë¼ë²¨ì—ì„œ ê°™ì€ ë¹ˆë„ë¡œ ë‚˜íƒ€ë‚¬ë‹¤ë©´ likelihood ê°’ì€ `1`ë¡œ ë‚˜íƒ€ë‚  ê²ƒì´ë‹¤. ì´ ê²°ê³¼ë¥¼ ê¸ì •ì ì´ì§€ë„ ë¶€ì •ì ì´ì§€ë„ ì•Šì€ **ì¤‘ë¦½ ê°’**ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ë°˜ë©´ ë¶„ëª¨ ë¶„ìëŠ” ë¹ˆë„ ìˆ˜ì´ë¯€ë¡œ likelihoodëŠ” ìŒì˜ ê°’ì„ ê°€ì§ˆ ìˆ˜ ì—†ê³ , ë¶„ëª¨ $P(w_i|Neg)$ê°€ ë¶„ì $P(w_i|Pos)$ ë³´ë‹¤ ì»¤ì§ˆ ìˆ˜ë¡ 0ì— ê°€ê¹Œì›Œì§€ê³  ë°˜ëŒ€ì˜ ê²½ìš° ì–‘ì˜ ë¬´í•œëŒ€ ê°’ì— ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆë‹¤.\n\n### ğŸ² Naive ë€?\në² ì´ì¦ˆ ëª¨ë¸ì´ **naive**(ìˆœì§„í•˜ë‹¤)ëŠ” ë§ì€ ëª¨ìˆ˜ì˜ ëª¨ë“  í‘œë³¸ì´ ìƒí˜¸ ë…ë¦½ì ì´ê³  ì™„ì „í•˜ë‹¤ê³  ê°€ì •í•˜ëŠ” ê²ƒì„ ëœ»í•œë‹¤. ì¦‰ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì—ì„œëŠ” ë°ì´í„°ì˜ ëª¨ë“  íŠ¹ì„±ë“¤(features)ì„ ì•Œ ìˆ˜ ìˆê³ , ë‚˜ì•„ê°€ íŠ¹ì„±ë“¤ì´ ì„œë¡œ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•˜ëŠ” ê²ƒì„ ëœ»í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í•œ ë¬¸ì¥ì„ ë°ì´í„° í•œê°œë¼ê³  í•˜ë©´, ë¬¸ì¥ì— ì†í•œ ë‹¨ì–´ë¥¼ ë°ì´í„°ì˜ íŠ¹ì„±ë“¤ë¡œ ë³¼ ìˆ˜ ìˆê³  ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì€ ì´ ë‹¨ì–´ë“¤ì´ ìƒí˜¸ ì—°ê´€(covariate) ë˜ì–´ìˆì§€ ì•Šë‹¤ê³  ê°€ì •í•œë‹¤. \n\në‹¨ì–´ $w_i (i= 1, ..., n)$ì„ í¬í•¨í•˜ëŠ” ë¬¸ì¥ì´ classì— ì†í•  í™•ë¥ ì€ ê²°í•© í™•ë¥  $P(class, w_1, ..., w_n)$ì¸ë°, ì—°ì‡„ ë²•ì¹™ì— ë”°ë¥´ë©´:\n\n$$\n\\begin{aligned}\nP(class, w_1, ..., w_n) \n&= P(class) \\cdot P(w_1, ..., w_n) \\\\\n&= P(class) \\cdot P(w_1|class) \\cdot P(w_2, ..., w_n) \\\\\n&= P(class) \\cdot P(w_1|class) \\cdot P(w_2|class, w_1) \\cdot P(w_3, ..., w_n) \\\\\n&= ...\n\\end{aligned} \n$$\n\nì´ë ‡ê²Œ ë¬¸ì¥ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ ì•ì— ë“±ì¥í•œ ë‹¨ì–´ë“¤ê³¼ classì— ëŒ€í•œ ì¡°ê±´ë¶€ í™•ë¥  ê³±ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ ë‚˜ì´ë¸Œ ê°€ì •ì€ íŠ¹ì„±ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•˜ë¯€ë¡œ ì„ì˜ì˜ ìŒ $i \\neq j$ì— ëŒ€í•´ $P(w_i|class) = P(w_i|class, w_j)$ë¥¼ ë§Œì¡±í•œë‹¤. ë”°ë¼ì„œ ë¬¸ì¥ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.\n\n$$\n\\begin{aligned}\nP(class, w_1, ..., w_n) \n&= P(class) \\cdot P(w_1|class) \\cdot ... \\cdot P(w_n|class) \\\\\n&= P(class) \\cdot \\prod_{i=1}^{n} P(w_i|class)\n\\end{aligned} \n$$\n\ní˜„ì‹¤ ì„¸ê³„ì˜ ë§ì€ í˜„ìƒì´ ìƒí˜¸ ì˜ì¡´ì ì„ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì€ ì˜¤ë«ë™ì•ˆ íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ì¸ ëª¨ë¸ë¡œ í™œìš©ë˜ì–´ì™”ë‹¤.\n\n> [ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì˜ íš¨ê³¼ ë¶„ì„ ìë£Œ ë³´ê¸°](https://web.archive.org/web/20171210133853/http://www.research.ibm.com/people/r/rish/papers/RC22230.pdf)\n\n### ğŸ² ë¡œê·¸ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ê¸°\ní™•ë¥ ì€ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ì´ë¯€ë¡œ, í™•ë¥ ì„ ì—¬ëŸ¬ë²ˆ ê³±í•˜ë©´ ì „ì‚°ì ìœ¼ë¡œ ì–¸ë”í”Œë¡œìš°ì˜ ìœ„í—˜ì´ ì»¤ì§„ë‹¤. ë„ˆë¬´ í° ê°’ì´ë‚˜ ë„ˆë¬´ ì‘ì€ ê°’ì„ ë‹¤ë£¨ëŠ” ì „í˜•ì ì¸ ë°©ë²•ì€ ë¡œê·¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ë¡œê·¸ë¥¼ ì·¨í•œ log likelihoodëŠ” log ratioì˜ í•©ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆë‹¤.\n\n$$\n\\begin{aligned}\nlog\\_ ratio(w_i) &= log \\frac{P(w_i|Pos)}{P(w_i|Neg)} \\\\\nlog\\_ likelihood &= \\sum^{m}_{i=1} log \\frac{P(w_i|Pos)}{P(w_i|Neg)}\n\\end{aligned}\n$$\n\ní•œê°€ì§€ ê°œë…ì„ ì¶”ê°€í•˜ìë©´, log ratioì˜ ê°’ì„ lambda í•¨ìˆ˜ë¡œ í‘œí˜„í•˜ê¸°ë„ í•œë‹¤. ì¦‰ $\\lambda(w)$ë¥¼ log ratioë¡œ í‘œí˜„í•˜ë©´ likelihoodë¥¼ ë” ê°„ë‹¨í•˜ê²Œ ì“¸ìˆ˜ ìˆë‹¤.\n\n$$\n\\begin{aligned}\n\\lambda(w_i) &= log\\frac{P(w_i|Pos)}{P(w_i|Neg)} \\\\\nlog\\_ likelihood(s) &= \\sum^{n}_{i=1} \\lambda(w_i)\n\\end{aligned}\n$$\n\në¡œê·¸ë¥¼ ì·¨í•˜ê²Œ ë˜ë©´ likelihoodì˜ ì¤‘ë¦½ ê°’ì€ $1$ì—ì„œ $log 1 = 0$ìœ¼ë¡œ ë³€í•˜ê²Œ ëœë‹¤. $0$ì—ì„œ ì–‘ì˜ ë¬´í•œëŒ€ì— ëŒ€í•œ ë¡œê·¸ê°’ì€ ìŒì˜ ë¬´í•œëŒ€ì—ì„œ ì–‘ì˜ ë¬´í•œëŒ€ì´ë¯€ë¡œ log likelihoodì˜ ê°’ì˜ ë²”ìœ„ë„ $0$ì„ ì¤‘ë¦½ ê°’ìœ¼ë¡œí•˜ëŠ” ìŒì˜ ë¬´í•œëŒ€ì—ì„œ ì–‘ì˜ ë¬´í•œëŒ€ ê°’ì„ ë°˜í™˜í•  ê²ƒì´ë‹¤.\n\n### ğŸ² ì‚¬ì „í™•ë¥ \nì˜ˆë¥¼ ë“¤ì–´ ì½”ë¡œë‚˜ íŒ¬ë°ë¯¹ì— ëŒ€í•œ íŠ¸ìœ—ì„ ëª¨ì•„ì„œ ì •ì„œ ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤ë©´, ë¶€ì •ì ì¸ íŠ¸ìœ—ì´ ê¸ì •ì ì¸ íŠ¸ìœ—ë³´ë‹¤ ë§ì„ ê²ƒì´ë‹¤. í˜„ì‹¤ ë°ì´í„° corpusì—ì„œ ë¶„ë¥˜ í´ë˜ìŠ¤ê°€ ê· ë“±í•˜ê²Œ ë‚˜ëˆ ì§€ëŠ” ê²½ìš°ëŠ” ë“œë¬¼ê¸° ë•Œë¬¸ì—, ë°ì´í„°ì˜ ë¶ˆê· í˜•ì„ ë³´ì •í•˜ê¸° ìœ„í•œ ì ˆì°¨ê°€ í•„ìš”í•˜ë‹¤. \n\në‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì—ì„œëŠ” ì‚¬ì „í™•ë¥ ì´ ì´ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. Likelihoodì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì‚¬ì „í™•ë¥ ì„ classì˜ ë¹„ìœ¨ë¡œ ì •ì˜í•˜ê³  ë¡œê·¸ê°’ì„ ì·¨í•  ìˆ˜ ìˆë‹¤. \n\n$$\nlog\\_prior = log \\frac{P(Pos)}{P(Neg)}\n$$\n\nì–´ë–¤ ì…ë ¥ê°’ì— ëŒ€í•´ log likelihoodê°€ 0ì´ë¼ê³  í•˜ë©´, ì˜ˆì¸¡ê°’ì€ log priorì™€ ê±°ì˜ ê°™ì„ ê²ƒì´ë‹¤. \n\n## 4. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸\në‹¤ì‹œ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ì—°ì‚°ì„ ë³´ë©´, ì…ë ¥ ë¬¸ì¥ $s$ì— ëŒ€í•´:\n\n$$\nNB = log\\frac{P(Pos)}{P(Neg)} + \\sum^{n}_{i=1} \\lambda(w_i)\n$$\n\nìœ„ì˜ ì‹ìœ¼ë¡œ ê³„ì‚°ë˜ë©°, \n\n$$\nNB = log\\_prior + log\\_likelihood\n$$\n\në¡œ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì˜ ì—°ì‚°ì˜ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤. \n\n0. í›ˆë ¨ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ í•œë‹¤.\n1. í† í°í™” ëœ ë‹¨ì–´ì˜ ë¹ˆë„ $freq(w, class)$ë¥¼ ê³„ì‚°í•œë‹¤.\n2. ëª¨ë“  í›ˆë ¨ ë°ì´í„°ì˜ ë‹¨ì–´ì— ëŒ€í•´ í›ˆë ¨í•´ log priorì™€ log likelihood ê°’ì„ êµ¬í•œë‹¤.\n    - ëª¨ë“  í›ˆë ¨ ë°ì´í„°ì˜ ë‹¨ì–´ì— ëŒ€í•´ $P(w|Pos)$ì™€ $P(w|Neg)$ ê°’ì„ êµ¬í•œë‹¤.\n    - ëª¨ë“  í›ˆë ¨ ë°ì´í„°ì˜ ë‹¨ì–´ì— ëŒ€í•´ $P(Pos)$ì™€ $P(Neg)$ ê°’ì„ êµ¬í•œë‹¤.\n3. í›ˆë ¨í•œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¡œ ì •ì„œë¥¼ ë¶„ë¥˜í•œë‹¤.\n\n\n### ğŸ“‚ êµ¬í˜„í•˜ê¸°\n\n#### 1. í† í°í™” ëœ ë‹¨ì–´ì˜ ë¹ˆë„ $freq(w, class)$ë¥¼ ê³„ì‚°í•œë‹¤.\n```python\ndef get_freq(dd, train_x, train_y):\n    '''\n    Get frequency dictionary from the training data.\n    input:\n        dd : a defaultdict of integer.\n        train_x : list of tokened sentences of training data.\n        train_y : list of 0 or 1 corresponding to the train_x. \n    return:\n        result : dictionary of (key, value) = (word label pair, frequency).\n    '''\n    for label, sentence in zip(train_y, train_x):\n        for word in process(sentence):\n            dd[(word, label)] += 1\n\n    return dd\n\n# count frequency dictionary from train_x and train_y.\nfreqs = get_freq(defaultdict(int), train_x, train_y)\n```\n\n#### 2. ëª¨ë“  í›ˆë ¨ ë°ì´í„°ì˜ ë‹¨ì–´ì— ëŒ€í•´ í›ˆë ¨í•´ log priorì™€ log likelihood ê°’ì„ êµ¬í•œë‹¤.\n```python\ndef train_naive_bayes(freqs, train_x, train_y):\n    '''\n    Train Naive Bayes model, that is, get prior and likelihood from the training data.\n    return:\n        log_prior : an integer. P(Pos) / P(Neg) value.\n        log_likelihood : a dictionary of (key, value) = (word, log likelihood)\n    '''\n    # log_likelihood relies on words\n    log_likelihood = {}\n    # log prior value relies on the corpus\n    log_prior = 0\n\n    # get unique words from the frequency dict\n    vocab = list(set(freq.keys()))\n    V = len(vocab)\n\n    # get N_pos and N_neg\n    N_pos = N_neg = 0\n    for pair in freqs.keys():\n        # if label is 1(> 0), the word is positive.\n        if pair[1] > 0:\n            N_pos += freqs[pair]\n        # if label is 0, the word is negative.\n        else:\n            N_neg += freqs[pair]\n\n    # get log likelihood\n    for w in vocab:\n        # get positive and negative frequency of word w.\n        freq_pos = freqs.get((w, 1), 0)\n        freq_neg = freqs.get((w, 0), 0)\n\n        # get P(w|Pos) and P(w|Neg).\n        p_w_pos = (freq_pos + 1) / (N_pos + V)\n        p_w_neg = (freq_neg + 1) / (N_neg + V)\n\n        log_likelihood[w] = np.log(p_w_pos) - np.log(p_w_neg)\n\n    # to compute log_prior,\n    # get the number of positive and negative labels\n    num_label = len(train_y)\n    num_pos = len(train_y[train_y == 1])\n    num_neg = len(train_y[train_y == 0])\n\n    # log prior = log(P(Pos)) - log(P(Neg))\n    log_prior = np.log(num_pos / num_label) - np.log(num_neg / num_label)\n\n    return log_prior, log_likelihood\n\n# get log prior and log likelihood from the training data\n# so that we can train on test data.\nlog_prior, log_likelihood = train_naive_bayes(freqs, train_x, train_y)\n```\n\n#### 3. í›ˆë ¨í•œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¡œ ì •ì„œë¥¼ ë¶„ë¥˜í•œë‹¤.\n```python\ndef predict_naive_bayes(s, log_prior, log_likelihood):\n    '''\n    input:\n        s : a list. Input sentence.\n        log_prior : log prior from trained naive bayes.\n        log_likelihood : log likelihood from trained naive bayes.\n    return:\n        log_prob : float between 0 and 1. probability that s is positive.\n    '''    \n    \n    words = proprocess(s)\n\n    log_prob = 0\n\n    for w in words:\n        if w in log_likelihood:\n            log_prob += log_likelihood[w]\n\n    log_prob += log_prior\n\n    return log_prob\n\n# print probability of test data.\ntest_data = 'hope you get well soon. it hurts to see you ill ğŸ˜¢'\nprint('prediction:', predict_naive_bayes(test_data, log_prior, log_likelihood))\n\n# output: 3.5905424260671044 -- ê¸ì • ì •ì„œë¡œ ì˜ˆì¸¡í–ˆë‹¤.\n```\n\n\n## ì°¸ê³  ìë£Œ\n1. Coursera, deeplearning.ai, Natural Language Processing with Classification and Vector Spaces, week 2 \n2. Wikipedia, Naive Bayes Classification, https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n3. Wikipedia, Additive Smooothing, https://en.wikipedia.org/wiki/Additive_smoothing\n4. Wikipedia, Likelihood-ratio test, https://en.wikipedia.org/wiki/Likelihood-ratio_test","excerpt":"ì´ ê¸€ì€ deeplearning.aiì˜ NLP Specializationë¥¼ ì°¸ê³ í•˜ì—¬ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì„ í…ìŠ¤íŠ¸ ì •ì„œ ë¶„ì„ì— ì´ˆì ì„ ë§ì¶° ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. Githubì—ì„œ Naive Bayes ì½”ë“œ ë³´ê¸° 0. ëª¨ë¸ ê°œëµ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ì€ ë¶„ë¥˜ ê³¼â€¦","fields":{"slug":"/naive_bayes/"},"frontmatter":{"date":"Mar 28, 2022","title":"ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜","tags":["NLP","Classification","Sentiment Analysis"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n## ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜\n\nê·¸ë˜í”„ëŠ” ê°„ì„ ì— ê°€ì¤‘ì¹˜ ì •ë³´ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤. ì´ëŸ° ê·¸ë˜í”„ë¥¼ ê°€ì¤‘ ê·¸ë˜í”„(weighted graph) ë¼ê³  í•˜ë©°, ìì—°ìŠ¤ëŸ½ê²Œ ì¶œë°œ ë…¸ë“œì—ì„œ íŠ¹ì • ë…¸ë“œë¡œ ê°€ëŠ” ê²½ë¡œì˜ ê°€ì¤‘ì¹˜ í•©ì´ ìµœì†Œê°€ ë˜ëŠ” ê²½ë¡œë¥¼ ì°¾ëŠ” ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ê¹Šì´ ìš°ì„  íƒìƒ‰(DFS)ì—ì„œ ì´ë™í•˜ëŠ” `ê²½ë¡œì˜ ê°œìˆ˜ë¥¼ ìµœì†Œí™”`í•˜ëŠ” ê²ƒì´ ëª©ì ì´ì—ˆë‹¤ë©´ ì´ ë¬¸ì œì—ì„œëŠ” ê°€ì¤‘ ê·¸ë˜í”„ì—ì„œ `ê²½ë¡œ ê°€ì¤‘ì¹˜ì˜ í•©ì„ ìµœì†Œí™”` í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë©°, ì´ ë¬¸ì œë¥¼ `ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜`ì´ë¼ê³  ë¶€ë¥¸ë‹¤.\n\nì´ ê¸€ì—ì„œëŠ” ë‘ê°œì˜ ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤.\n\n1. Dijkstra ì•Œê³ ë¦¬ì¦˜\n2. Floyd-Warshall ì•Œê³ ë¦¬ì¦˜\n\n## 1. Dijkstra ì•Œê³ ë¦¬ì¦˜\nDijkstra ì•Œê³ ë¦¬ì¦˜ì€ ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ì‹œì‘ ë…¸ë“œì—ì„œ ëª¨ë“  ë…¸ë“œê¹Œì§€ì˜ ìµœë‹¨ ê²½ë¡œë¥¼ ê³„ì‚°í•œë‹¤. Dijkstra ì•Œê³ ë¦¬ì¦˜ì€ ë§¤ ì‹œì ì—ì„œ ê°€ì¥ ë¹„ìš©ì´ ì ì€ ë…¸ë“œë¥¼ ì„ íƒí•˜ëŠ” **ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜**ì´ë©°, ì´ ë•Œë¬¸ì— ê°€ì¤‘ì¹˜ê°€ ëª¨ë‘ ì–‘ìˆ˜(positive number)ì¸ ìœ í–¥(directed) ê·¸ë˜í”„ì— ëŒ€í•´ì„œë§Œ ì‘ë™í•œë‹¤.\n\n### ğŸ“‚ ìš°ì„  ìˆœìœ„ íë¥¼ í™œìš©í•œ Dijkstra ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„\n_ìµœë‹¨ ê±°ë¦¬ë¥¼ ì •ë ¬í•˜ê¸° ìœ„í•´ ìš°ì„  ìˆœìœ„ íë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, íë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ ì„œë„ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤._\n\nDijkstra ì•Œê³ ë¦¬ì¦˜ì€ ìš°ì„  ìˆœìœ„ íë¥¼ í™œìš©í•œ ì¬ê·€ í•¨ìˆ˜ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤. \n1. ì €ì¥ëœ ìµœë‹¨ ê±°ë¦¬ê°€ ì…ë ¥ ë°›ì€ ê±°ë¦¬ë³´ë‹¤ ì§§ì€ ê²½ìš°, í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•œë‹¤.\n2. 1ë²ˆì—ì„œ ëë‚˜ì§€ ì•Šì€ ê²½ìš°, í˜„ì¬ ë…¸ë“œì—ì„œ ëª¨ë“  ì—°ê²°ëœ ë…¸ë“œë¡œ ê°€ëŠ” ê²½ë¡œë¥¼ ê³ ë ¤í•´, ì´ë¯¸ ì €ì¥ëœ ê²½ë¡œì™€ ê±°ë¦¬ë¥¼ ë¹„êµí•œë‹¤. ì €ì¥ëœ ìµœë‹¨ ê±°ë¦¬ê°€ ê³„ì‚°í•œ ê±°ë¦¬ë³´ë‹¤ ê¸´ ê²½ìš°, ë” ì§§ì€ ê±°ë¦¬ë¡œ `dist` ë°°ì—´ì˜ í•´ë‹¹ ê°’ì„ ë³€ê²½í•œë‹¤.\n3. ìš°ì„  ìˆœìœ„ íê°€ ë¹Œ ë•Œ ê¹Œì§€ ìœ„ ê³¼ì •ì„ ë°˜ë³µí•œë‹¤.\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom heapq import heappush, heappop\nfrom collections import defaultdict\n\n# ë…¸ë“œ ê°œìˆ˜ nê³¼ ê°„ì„  ê°œìˆ˜ mì„ ì…ë ¥ë°›ëŠ”ë‹¤.\nn, m = map(int, input().split())\n\n# ì‹œì‘ ë…¸ë“œë¥¼ ì…ë ¥ ë°›ëŠ”ë‹¤.\nstart = int(input())\n\n# 1ì°¨ì› ë°°ì—´ graphë¥¼ ì´ˆê¸°í™”í•œë‹¤.\ngraph = defaultdict(list)\n\n# graph[i]ëŠ” (node_number, weight)ë¥¼ ì›ì†Œë¡œ í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë‹¤.\nfor _ in range(m):\n    i, j, w = map(int, input().split())\n    graph[i].append(j, w)\n\n# graphì™€ ë…¸ë“œ ê°œìˆ˜ nì„ ì…ë ¥ë°›ì•„\n# `ì‹œì‘ ë…¸ë“œ`ì—ì„œ `ëª¨ë“  ë…¸ë“œ`ê¹Œì§€ì˜ ìµœë‹¨ ê±°ë¦¬ë¥¼ ë°˜í™˜í•œë‹¤. \ndef shortest_path(graph, n, start):\n\n    # distance[i] : ì‹œì‘ ë…¸ë“œì—ì„œ ë…¸ë“œ i ê¹Œì§€ì˜ ìµœë‹¨ ê±°ë¦¬\n    # í° ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•œë‹¤.\n    INF = int(1e9)\n    distance = [INF] * (n + 1)\n\n    def dijkstra(start):\n        # qì˜ ì›ì†Œ: (shortest_distance, node_number)\n        # ì‹œì‘ë…¸ë“œì—ì„œ ì‹œì‘ë…¸ë“œê¹Œì§€ì˜ ê±°ë¦¬ëŠ” 0ì´ë‹¤.\n        hq = []\n        heappush(hq, (0, start))\n        distance[start] = 0\n\n        # qê°€ ì¡´ì¬í•˜ëŠ” í•œ ê³„ì†í•œë‹¤.\n        while hq:\n            dist, now = heappop(q)\n            # ì €ì¥ëœ ìµœë‹¨ ê±°ë¦¬ê°€ ê³„ì‚°í•œ ê±°ë¦¬ë³´ë‹¤ ì§§ì€ ê²½ìš°, \n            # ë³€ê²½í•˜ì§€ ì•ŠëŠ”ë‹¤.\n            if distance[now] < dist:\n                continue\n            # ì—°ê²°ëœ ë…¸ë“œì— ëŒ€í•´ ìƒˆë¡œìš´ ê²½ë¡œì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•œë‹¤.\n            for n, d in graph[now]:\n                w_dist = dist + d\n                # ì €ì¥ëœ ìµœë‹¨ ê±°ë¦¬ê°€ ê³„ì‚°í•œ ê±°ë¦¬ë³´ë‹¤ ê¸´ ê²½ìš°, \n                # ë” ì§§ì€ ê±°ë¦¬ë¡œ dist ê°’ì„ ë³€ê²½í•œë‹¤.\n                if w_dist < distance[n]:\n                    distance[n] = w_dist\n                    heappush(hq, (w_dist, n))\n\n    # ì‹œì‘ë…¸ë“œì— ëŒ€í•´ dijkstraë¥¼ êµ¬í˜„í•œë‹¤.\n    dijkstra(start)\n    return distance\n\nshortest = shortest_path(graph, n, start))\nfor i in range(n):\n    print(f\"Shortest Path from node {start} to node {i}: {shortest[i+1]}\")\n```\nì‹œê°„ ë³µì¡ë„ëŠ” ìš°ì„  ìˆœìœ„ íì˜ ì •ë ¬ì— ì˜í•´ ë…¸ë“œ ê°œìˆ˜ $N$ê³¼ ê°€ì¤‘ì¹˜ ê°œìˆ˜ $M$ì— ëŒ€í•´ $O(MlogN)$ì´ë‹¤.\n\n## 2. Floyd-Warshall ì•Œê³ ë¦¬ì¦˜\n\nFloyd-Warshall ì•Œê³ ë¦¬ì¦˜ì€ ëª¨ë“  ë…¸ë“œì—ì„œ ëª¨ë“  ë…¸ë“œê¹Œì§€ì˜ ìµœë‹¨ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ëŠ” **ë‹¤ì´ë‚´ë¯¹ í”„ë¡œê·¸ë˜ë°** ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ë”°ë¼ì„œ ì í™”ì‹ì„ ì•Œê¸°ë§Œ í•˜ë©´ êµ¬í˜„ì´ ë¹„êµì  ê°„ë‹¨í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.\n\n`ë…¸ë“œ i`ì—ì„œ `ë…¸ë“œ j`ë¡œ ê°€ëŠ” ì„ì˜ì˜ ê²½ë¡œê°€ ìˆë‹¤ê³  í•˜ì. ë§Œì•½ iì—ì„œ jë¡œ ê°€ëŠ” ë‹¤ë¥¸ ê²½ë¡œê°€ ìˆë‹¤ë©´ ì´ ê²½ë¡œëŠ” ì„ì˜ì˜ ê²½ë¡œê°€ ì§€ë‚˜ì§€ ì•ŠëŠ” ë‹¤ë¥¸ ë…¸ë“œë¥¼ ê±°ì³ê°ˆ ê²ƒì´ë‹¤. ë‹¤ë¥¸ ë…¸ë“œë¥¼ ì„ì˜ë¡œ `ë…¸ë“œ k`ë¼ê³  í• ë•Œ, `ë…¸ë“œ i`ì—ì„œ `ë…¸ë“œ k`ë¡œ ë‹¤ì‹œ `ë…¸ë“œ k`ì—ì„œ `ë…¸ë“œ j`ë¡œ ê°€ëŠ” ê²½ë¡œì™€ ê·¸ë ‡ì§€ ì•Šì€ ê²½ë¡œë¥¼ ë¹„êµí•  ìˆ˜ ìˆë‹¤. $dist[i][j]$ë¥¼ ë…¸ë“œ iì—ì„œ jë¡œ ê°€ëŠ” ìµœë‹¨ ê²½ë¡œë¼ê³  ì •ì˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì í™”ì‹ì„ ì“¸ ìˆ˜ ìˆë‹¤.\n$$\ndist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])\n$$\në”°ë¼ì„œ ë…¸ë“œ ê°œìˆ˜ Nì— ëŒ€í•´ $(N, N)$í¬ê¸°ì˜ 2ì°¨ì› ë°°ì—´ì— ì„ì˜ì˜ `ë…¸ë“œ i`ì—ì„œ ì„ì˜ì˜ `ë…¸ë“œ j`ë¡œ ê°€ëŠ” ìµœë‹¨ ê²½ë¡œë¥¼ ì €ì¥í•œë‹¤. \n\n### ğŸ“‚ Floyd-Warshall ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„\n1. ë…¸ë“œ ê°œìˆ˜ $N$ì— ëŒ€í•´ $(N, N)$ í¬ê¸°ì˜ 2ì°¨ì› ë°°ì—´ì„ ì´ˆê¸°í™”í•œë‹¤.\n2. ìœ„ì˜ ì í™”ì‹ì„ ì´ìš©í•´ ëª¨ë“  kì— ëŒ€í•´ 2ì°¨ì› ë°°ì—´ì„ ìˆœíšŒí•œë‹¤.\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\n# ë…¸ë“œ ê°œìˆ˜ nê³¼ ê°„ì„  ê°œìˆ˜ mì„ ì…ë ¥ë°›ëŠ”ë‹¤.\nn, m = map(int, input().split())\n\n# 2ì°¨ì› dist ë°°ì—´ì„ í° ê°’ìœ¼ë¡œ ì´ˆê¸°í™” í•œë‹¤.\n# dist[i][j] : ë…¸ë“œ iì—ì„œ ë…¸ë“œ jë¡œ ê°€ëŠ” ìµœë‹¨ ê²½ë¡œ\nINF = 1e9\ndist = [INF for _ in range(n)] for _ in range(n)\n\n# ê°„ì„  ê°œìˆ˜ë§Œí¼ ê°„ì„  ì •ë³´ë¥¼ 2ì°¨ì› ë°°ì—´ì— ì…ë ¥ë°›ëŠ”ë‹¤.\nfor _ in range(m):\n    i, j, w = map(int, input().split())\n    dist[i][j] = w\n\n# distì™€ ë…¸ë“œ ê°œìˆ˜ nì„ ì…ë ¥ë°›ì•„\n# `ëª¨ë“  ë…¸ë“œ`ì—ì„œ `ëª¨ë“  ë…¸ë“œ`ê¹Œì§€ì˜ ìµœë‹¨ ê±°ë¦¬ë¥¼ ì €ì¥í•œ 2ì°¨ì› ë°°ì—´ì„ ë°˜í™˜í•œë‹¤. \nfor k in range(n+1):\n    for i in range(n+1):\n        for j in range(n+1):\n            # ì €ì¥ë˜ì–´ ìˆëŠ” ìµœë‹¨ ê²½ë¡œ dist[i][j]ì™€\n            # ë…¸ë“œ kë¥¼ ê±°ì¹˜ëŠ” ê²½ë¡œ dist[i][k] + dist[k][j]ë¥¼ ë¹„êµí•œë‹¤.\n            dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])\n\nfor i in range(n):\n    for j in range(n):\n        print(f\"Shortest Path from node {i} to node {j}: {dist[i+1][j+1]}\")\n```\n\nFloyd-Warshall ì•Œê³ ë¦¬ì¦˜ì€ ì‚¼ì¤‘ forë¬¸ì— ì˜í•´ ì‹œê°„ ë³µì¡ë„ê°€ $O(N^3)$ì´ë¯€ë¡œ ë…¸ë“œ ê°œìˆ˜ê°€ ë§ì€ ê·¸ë˜í”„ëŠ” ìˆ˜í–‰ì‹œê°„ì— ìœ ì˜í•´ì•¼ í•œë‹¤. \n\n---\n\n## ì°¸ê³ ìë£Œ\n1. Youtube, (ì´ì½”í…Œ 2021 ê°•ì˜ ëª°ì•„ë³´ê¸°) 7. ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜, https://www.youtube.com/watch?v=acqm9mM1P6o","excerpt":"ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜ ê·¸ë˜í”„ëŠ” ê°„ì„ ì— ê°€ì¤‘ì¹˜ ì •ë³´ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤. ì´ëŸ° ê·¸ë˜í”„ë¥¼ ê°€ì¤‘ ê·¸ë˜í”„(weighted graph) ë¼ê³  í•˜ë©°, ìì—°ìŠ¤ëŸ½ê²Œ ì¶œë°œ ë…¸ë“œì—ì„œ íŠ¹ì • ë…¸ë“œë¡œ ê°€ëŠ” ê²½ë¡œì˜ ê°€ì¤‘ì¹˜ í•©ì´ ìµœì†Œê°€ ë˜ëŠ” ê²½ë¡œë¥¼ ì°¾ëŠ” ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ê¹Šì´ ìš°â€¦","fields":{"slug":"/shortest_path/"},"frontmatter":{"date":"Mar 21, 2022","title":"ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜","tags":["Algorithms","Shortest Path","Dijkstra Algorithm","Floyd-Warshall Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ: [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/12978)\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n\nê·¸ë˜í”„ì™€ ê° ê°„ì„ ì˜ ê°€ì¤‘ì¹˜ê°€ ì£¼ì–´ì§ˆ ë•Œ, ì‹œì‘ ë…¸ë“œì—ì„œ ì¶œë°œí•´ ì§€ë‚˜ëŠ” ê°„ì„ ì˜ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë‘ ë”í•´ ë„ì°©í•  ë•Œê¹Œì§€ `ê°€ì¤‘ì¹˜ì˜ í•©`ì´ `K` ì´í•˜ê°€ ë˜ëŠ” ë…¸ë“œë¥¼ ëª¨ë‘ ì°¾ëŠ” ë¬¸ì œë‹¤. ì¦‰ ì‹œì‘ë…¸ë“œì—ì„œ íŠ¹ì • ë…¸ë“œê¹Œì§€ ê°€ì¤‘ì¹˜ í•©ì„ ìµœì†Œë¡œ í•˜ëŠ” ê²½ë¡œë¥¼ ì°¾ì•„ì•¼ í•˜ë©°, ì´ëŸ° ë¬¸ì œë¥¼ `ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜`ì´ë¼ê³  ë¶€ë¥¸ë‹¤.\n\n> [ìµœë‹¨ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜ ì•Œì•„ë³´ê¸°](https://snowith.github.io/shortest_path/)\n\nì´ ë¬¸ì œëŠ” Dijkstra ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆë‹¤. \n1. ì£¼ì–´ì§„ roadì˜ ì •ë³´ë¥¼ í•œìª½ ë…¸ë“œë¥¼ í‚¤ë¡œ í•˜ê³  ë°˜ëŒ€ìª½ ë…¸ë“œì™€ ê°€ì¤‘ì¹˜ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥í•œë‹¤.\n2. ë‹¤ìµìŠ¤íŠ¸ë¼ ì•Œê³ ë¦¬ì¦˜ì„ ì¬ê·€ í•¨ìˆ˜ë¡œ êµ¬í˜„í•œë‹¤.\n    - ì…ë ¥ ë°›ì€ ê²½ë¡œì™€ dist ë°°ì—´ì— ì €ì¥ëœ ê°’ì„ ë¹„êµí•˜ì—¬ ì—…ë°ì´íŠ¸í•œë‹¤.\n    - ì‹œì‘ ë…¸ë“œì˜ ìµœì†Œ ê²½ë¡œì—ì„œ ì—°ê²° ëœ ë…¸ë“œë¥¼ ì—°ê²°í•œ ê²½ë¡œì— ëŒ€í•´ ë‹¤ìµìŠ¤íŠ¸ë¼ ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í–‰í•œë‹¤. \n    \n3. ì‹œì‘ ë…¸ë“œì¸ 1ë²ˆ ë…¸ë“œì™€ ìµœë‹¨ê±°ë¦¬ 0ì— ëŒ€í•´ ë‹¤ìµìŠ¤íŠ¸ë¼ ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í–‰í•œë‹¤.\n4. Kë³´ë‹¤ ì‘ì€ ê°’ë“¤ì„ ì„¸ì–´ ë°˜í™˜í•œë‹¤.\n\n## íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom collections import defaultdict\n\ndef solution(N, road, K):\n    \n    # ì‹œì‘ ë…¸ë“œì—ì„œ ê° ë…¸ë“œê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ í° ê°’ìœ¼ë¡œ ì´ˆê¸°í™” í•œë‹¤.\n    # ì¸ë±ìŠ¤ëŠ” 'ì£¼ì–´ì§„ ë…¸ë“œ - 1'ë¡œ ì„¤ì •í•œë‹¤.\n    INF = 1e9\n    dist = [INF] * (N + 1)\n    dist[0] = 0\n\n    # roadì˜ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥í•œë‹¤.\n    graph = defaultdict(list)\n    for a, b, c in road:\n        graph[a].append([b,c])\n        graph[b].append([a,c])\n    \n    # dijkstraë¥¼ êµ¬í˜„í•œë‹¤.\n    # graph ë”•ì…”ë„ˆë¦¬ì™€ ì‹œì‘ë…¸ë“œ v, ìµœë‹¨ ê²½ë¡œ(ì‹œê°„) timeì´ ì£¼ì–´ì¡Œì„ ë•Œ\n    # í•¨ìˆ˜ ë°–ì˜ dist ë°°ì—´ì— ê²½ë¡œì˜ ìµœì†Œê°’ì„ ì €ì¥í•œë‹¤.\n    def dijkstra(start_node, time):\n        # ìµœë‹¨ ê²½ë¡œë§Œ ì €ì¥í•œë‹¤.\n        if dist[start] > time:\n            dist[start] = time\n        # ì—°ê²°ëœ ë…¸ë“œì— ëŒ€í•´ dijkstraë¥¼ ì‹¤í–‰í•œë‹¤.\n        for next_, t in graph[start]:\n            if t + time < dist[next_]:\n                dijkstra(graph, next_, t + time)\n    \n    # 1ë²ˆ ë…¸ë“œì˜ ìµœë‹¨ ê²½ë¡œê°€ 0ì¸ ê²ƒì—ì„œ ì¶œë°œí•´ì„œ\n    # ëª¨ë“  ë…¸ë“œì˜ ìµœë‹¨ ê²½ë¡œë¥¼ ì°¾ëŠ”ë‹¤.\n    dijkstra(graph, 1, 0)\n\n    # K ë³´ë‹¤ ì‘ì€ distì˜ ê°’ë“¤ì„ ì„¸ì–´ ë°˜í™˜í•œë‹¤.\n    cnt = 0\n    for n in range(N):\n        if dist[n] <= K:\n            cnt += 1\n\n    return cnt\n```\n","excerpt":"ë¬¸ì œ: í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ê·¸ë˜í”„ì™€ ê° ê°„ì„ ì˜ ê°€ì¤‘ì¹˜ê°€ ì£¼ì–´ì§ˆ ë•Œ, ì‹œì‘ ë…¸ë“œì—ì„œ ì¶œë°œí•´ ì§€ë‚˜ëŠ” ê°„ì„ ì˜ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë‘ ë”í•´ ë„ì°©í•  ë•Œê¹Œì§€ ì´  ì´í•˜ê°€ ë˜ëŠ” ë…¸ë“œë¥¼ ëª¨ë‘ ì°¾ëŠ” ë¬¸ì œë‹¤. ì¦‰ ì‹œì‘ë…¸ë“œì—ì„œ íŠ¹ì • ë…¸ë“œê¹Œì§€ ê°€ì¤‘ì¹˜ í•©ì„ ìµœì†Œë¡œ í•˜ëŠ”â€¦","fields":{"slug":"/programmers. ë°°ë‹¬/"},"frontmatter":{"date":"Mar 19, 2022","title":"programmers. ë°°ë‹¬","tags":["Algorithms","Graph","Shortest Path","Dijkstra Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n## Greedy algorithm\n(ì „ì²´ê°€ ì•„ë‹Œ) ë¶€ë¶„ì—ì„œ ìµœì ì˜ í•´ë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ ì „ì²´ ë¬¸ì œì˜ ìµœì  í•´ê°€ ë ë•Œ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, êµ¬í˜„í•˜ê¸°ëŠ” ì–´ë µì§€ ì•Šì§€ë§Œ ì •ë‹¹ì„±ì„ ì¦ëª…í•´ì•¼ ë‹µì„ ë³´ì¥í•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒì˜ ë¬¸ì œë“¤ì—ì„œ ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ ì •ë‹¹ì„± ì¦ëª…ì„ ì—°ìŠµí•  ìˆ˜ ìˆë‹¤.\n\n> ëª¨ë“  ë¬¸ì œì˜ ì¶œì²˜: [ì´ì½”í…Œ ìœ íŠœë¸Œ](https://www.youtube.com/watch?v=m-9pAwq1o3w&list=PLRx0vPvlEmdAghTr5mXQxGpHjWqSz0dgC&index=1)\n\n---\n\n### <ë¬¸ì œ> ê±°ìŠ¤ë¦„ ëˆ\n`n`ì›ì„ `10ì›`, `50ì›`, `100ì›`, `500ì›` ë™ì „ìœ¼ë¡œ ê±°ìŠ¬ëŸ¬ ì£¼ë ¤ê³  í•  ë•Œ, ê±°ìŠ¬ëŸ¬ì£¼ëŠ” ë™ì „ì˜ ê°œìˆ˜ë¥¼ ìµœì†Œí™”í•˜ë ¤ê³  í•œë‹¤. ì´ë•Œ ê±°ìŠ¬ëŸ¬ ì£¼ëŠ” ë™ì „ì˜ ìµœì†Œ ê°œìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ë¬¸ì œì´ë‹¤.\n\n#### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ì „ëµ: ê°€ì¥ í° í™”í ë‹¨ìœ„ë¶€í„° ê±°ìŠ¬ëŸ¬ ì¤€ë‹¤.\n- ì •ë‹¹ì„± ì¦ëª…: ê±°ìŠ¬ëŸ¬ ì¤„ ë™ì „ ì¤‘ í° ë‹¨ìœ„ê°€ í•­ìƒ ì‘ì€ ë‹¨ìœ„ì˜ ë°°ìˆ˜ì´ë¯€ë¡œ, ê°™ì€ ëˆì„ ê±°ìŠ¬ëŸ¬ ì£¼ëŠ” ë°©ë²• ì¤‘ ê°€ì¥ ì ì€ ë™ì „ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ê°€ëŠ¥í•œ í•œ ê°€ì¥ í° ë‹¨ìœ„ì˜ ë™ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.\n- ì¦‰ ë™ì „ì˜ ë‹¨ìœ„ê°€ 500ì›, 400ì›, 100ì›ìœ¼ë¡œ ì£¼ì–´ì§„ ê²½ìš°ì—ëŠ” ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•´ë‹µì„ êµ¬í•  ìˆ˜ ì—†ë‹¤.\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\ncoins = [500, 100, 50, 10]\ncnt = 0\n\nfor coin in coins:\n\tcnt += n // coin\n\tn %= coin\n\nprint(count) \n```\n\n---\n\n### <ë¬¸ì œ> 1ì´ ë  ë•Œê¹Œì§€\n1ì´ ì•„ë‹Œ ìˆ«ì `N`ê³¼ `K`ê°€ ì£¼ì–´ì§„ë‹¤. ì˜¤ì§ ë‘ ê°€ì§€ ì—°ì‚°ë§Œ í•  ìˆ˜ ìˆëŠ”ë°, Nì´ Kë¡œ ë‚˜ëˆ„ì–´ì§€ëŠ” ê²½ìš° `Nì„ Kë¡œ ë‚˜ëˆŒ` ìˆ˜ ìˆê³ , ê·¸ ì™¸ì˜ ê²½ìš°ì—ëŠ” `Nì—ì„œ 1ì„ ëº„` ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ Nì„ 1ë¡œ ë§Œë“œëŠ” ìµœì†Œ ì—°ì‚° íšŸìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë‹¤.  \n\n#### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ì „ëµ : ìˆ«ì Nì´ Kë¡œ ë‚˜ëˆ„ì–´ì§€ëŠ” ê²½ìš°ì˜ ìˆ˜ë¥¼ ìµœëŒ€í•œìœ¼ë¡œ í•˜ë˜, ë§Œì•½ Nì´ Kë¡œ ë‚˜ëˆ„ì–´ì§€ì§€ ì•Šìœ¼ë©´ 1ì„ ëº€ë‹¤.\n- ì •ë‹¹ì„± ì¦ëª…: ë§Œì•½ Nì´ Kë¡œ ë‚˜ëˆ„ì–´ì§€ë©´, Nê³¼ KëŠ” 1ì´ ì•„ë‹ˆë¯€ë¡œ N ë‚˜ëˆ„ê¸° K ëŠ” N - 1ë³´ë‹¤ ì‘ì€ ê°’ì´ ëœë‹¤. ì–¸ì œë‚˜ 1ì„ ë¹¼ëŠ” ê²ƒìœ¼ë¡œ Nì„ 1ë¡œ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë§¤ë²ˆ Nì„ ìµœëŒ€í•œ ì‘ì€ ìˆ˜ë¡œ ë§Œë“œëŠ” ë°©ë²•ìœ¼ë¡œ ì „ì²´ ì—°ì‚° íšŸìˆ˜ë¥¼ ìµœì†Œí™” í•  ìˆ˜ ìˆë‹¤.\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\nn, k = map(int, input().split())\ncnt = 0\n\nwhile n >= k:\n\tif n % k == 0:\n\t\tcnt += 1\n\t\tn //= k\n\telse:\n\t\tcnt += n % k\n\t\tn -= n % k\n\nprint(cnt + n - 1)\n```\n\n---\n\n### <ë¬¸ì œ> ê³±í•˜ê¸° í˜¹ì€ ë”í•˜ê¸°\n0 ë˜ëŠ” ì–‘ìˆ˜ì¸ ì„ì˜ì˜ ìˆ˜ë“¤ `s`ê°€ ì£¼ì–´ì§ˆ ë•Œ, ë‘ ìˆ˜ë¥¼ ë”í•˜ê±°ë‚˜ ê³±í•´ì„œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê°€ì¥ í° ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤.\n\n#### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ì „ëµ : í”¼ì—°ì‚°ì ë‘ê°œ ì¤‘ í•˜ë‚˜ë¼ë„ 0ì´ë‚˜ 1ì´ë©´ ë”í•˜ê³ , ê·¸ ì™¸ì˜ ê²½ìš°ë©´ ê³±í•œë‹¤.\n- ì •ë‹¹ì„± ì¦ëª…: ì—°ì‚°ì˜ ì™¼ìª½ ìˆ«ìë¥¼ ì„ì˜ì˜ ìˆ˜ Nì´ë¼ í•  ë•Œ, ëª¨ë“  ìˆ˜ëŠ” 0 ë˜ëŠ” ì–‘ìˆ˜ì´ë¯€ë¡œ `N * 0 = 0` ë³´ë‹¤ `N + 0 = N` ì´ ê°™ê±°ë‚˜ í¬ê³ , `N * 1 = N` ë³´ë‹¤ `N + 1` ì´ ë” í¬ë‹¤. ë°˜ë©´, 2ì´ìƒ 9ì´í•˜ì˜ ì •ìˆ˜ Xì— ëŒ€í•´ `N * X` ë³´ë‹¤ `N + X` ê°€ ê°™ê±°ë‚˜ ì‘ë‹¤. ê³±ì…ˆê³¼ ë§ì…ˆì€ êµí™˜ë²•ì¹™ì´ ì„±ë¦½í•˜ë¯€ë¡œ í”¼ì—°ì‚°ìì˜ ìˆœì„œì— ê´€ê³„ì—†ì´ ë²•ì¹™ì´ ì„±ë¦½í•œë‹¤.\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\ns = input()\nret = int(s[0])\n\nfor i in range(1, len(s)):\n\tnum = int(s[i])\n\tif num <= 1 or ret <= 1: \n\t\tret += num\n\telse:\n\t\tret *= num\n\nprint(ret)\n```\n\n---\n\n### <ë¬¸ì œ> ëª¨í—˜ê°€ ê¸¸ë“œ\nì–´ë–¤ ë§ˆì„ì— ëª¨í—˜ê°€ë“¤ì´ ìˆë‹¤. ëª¨í—˜ê°€ë“¤ì€ ì œê°ê¸° ê³µí¬ë„ê°€ ìˆëŠ”ë°, ê³µí¬ë„ê°€ `i`ì¸ ì‚¬ëŒì€ `i`ëª… ì´ìƒì´ ì†í•œ ê·¸ë£¹ì— ë“¤ì–´ì•¼ ëª¨í—˜ì„ ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤. ëª¨í—˜ê°€ë“¤ì˜ ê³µí¬ë„ê°€ ì£¼ì–´ì§ˆ ë•Œ, ëª¨í—˜ì„ ë‚˜ê°€ëŠ” ê·¸ë£¹ì˜ ìˆ˜ë¥¼ ìµœëŒ€í™”í•´ì„œ ë°˜í™˜í•˜ëŠ” ë¬¸ì œë‹¤. ë‹¨, ëª¨í—˜ê°€ë“¤ì´ ë§ˆì„ì— ë‚¨ì•„ìˆëŠ” ê²½ìš°ë„ í—ˆìš©ëœë‹¤.\n\n#### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ì „ëµ: ê³µí¬ë„ê°€ ì ì€ ì‚¬ëŒë¶€í„° ìˆœì„œëŒ€ë¡œ ê·¸ë£¹ì„ ê¾¸ë¦¬ë˜, ê·¸ë£¹ì˜ ìµœì†Œ ì •ì›ì´ ë§Œì¡±ë˜ë©´ ë‹¤ìŒ ê·¸ë£¹ìœ¼ë¡œ í¸ì„±í•œë‹¤.\n- ì •ë‹¹ì„± ì¦ëª…: ì£¼ì–´ì§„ ì •ë³´ì— ëŒ€í•´ ê·¸ë£¹ìˆ˜ê°€ ìµœëŒ€ê°€ ë˜ë„ë¡ ê¾¸ë ¤ì§„ ì„ì˜ì˜ í¸ì„±ì´ ìˆë‹¤ê³  í•˜ì. ì´ í¸ì„±ì˜ í•œ ê·¸ë£¹ì— ëŒ€í•´  ê³µí¬ë„ê°€ ì ì€ ì‚¬ëŒë¶€í„° ê·¸ë£¹ì˜ ìµœì†Œ ì •ì›ì„ ë§Œì¡±í•˜ë„ë¡ ê·¸ë£¹ì„ ë§Œë“¤ê³  ì´ì™¸ì˜ ëª¨í—˜ê°€ë“¤ì„ ì œì™¸ì‹œì¼œë„ ì—¬ì „íˆ ê·¸ë£¹ì˜ ìˆ˜ëŠ” ìµœëŒ€ì´ë‹¤. ë”°ë¼ì„œ ìœ„ì˜ ì „ëµì€ ìµœì ì˜ í•´ë¥¼ ë³´ì¥í•œë‹¤.\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\nn = int(input())\nfears = list(map(int, input().split()))\nfears.sort()\n\n# cnt : ê° ê·¸ë£¹ì— í¬í•¨ëœ ì‚¬ëŒì˜ ìˆ˜\n# ret : ì „ì²´ ê·¸ë£¹ì˜ ìˆ˜\ncnt, ret = 0, 0\n\nfor fear in fears:\n\tcnt += 1\n\t# fearê°€ cntë¥¼ ë„˜ìœ¼ë©´,\n\t# ì „ì²´ ê·¸ë£¹ ìˆ˜ë¥¼ 1 ì¦ê°€í•˜ê³  cntë¥¼ ì´ˆê¸°í™” í•œë‹¤. \n\tif cnt >= fear:\n\t\tret += 1\n\t\tcnt = 0\n\t\nprint(ret)\n```\n\n## ì°¸ê³ ìë£Œ\n- Coursera, Algorithmic Toolbox, Greedy Algorithm\n","excerpt":"Greedy algorithm (ì „ì²´ê°€ ì•„ë‹Œ) ë¶€ë¶„ì—ì„œ ìµœì ì˜ í•´ë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ ì „ì²´ ë¬¸ì œì˜ ìµœì  í•´ê°€ ë ë•Œ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, êµ¬í˜„í•˜ê¸°ëŠ” ì–´ë µì§€ ì•Šì§€ë§Œ ì •ë‹¹ì„±ì„ ì¦ëª…í•´ì•¼ ë‹µì„ ë³´ì¥í•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒì˜ ë¬¸ì œë“¤ì—ì„œ ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ ì •ë‹¹ì„± â€¦","fields":{"slug":"/greedy_algorithm/"},"frontmatter":{"date":"Mar 09, 2022","title":"ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ì˜ ì •ë‹¹ì„± ì¦ëª…","tags":["Algorithms","Greedy Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/72412)\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\níš¨ìœ¨ì„± í†µê³¼ê°€ ê¹Œë‹¤ë¡­ë‹¤ê³  ëŠê¼ˆë˜ ë¬¸ì œì¤‘ í•˜ë‚˜ë¡œ, ì ìˆ˜ë¥¼ ì œì™¸í•œ `ê²€ìƒ‰ ì¡°ê±´ì˜ ê°œìˆ˜`ê°€ `4ê°œ`ì— ë¶ˆê³¼í•˜ë‹¤ëŠ” ì ì„ ì´ìš©í•´ì„œ ëª¨ë“  ì¡°ê±´ ì¡°í•©ì„ í•´ì‹œí•œ ë‹¤ìŒ ì´ì§„ ê²€ìƒ‰ì„ í†µí•´ í•´ê²°í•  ìˆ˜ ìˆì—ˆë‹¤.\n\nì½”ë“œëŠ” ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ìˆœì„œëŒ€ë¡œ ì‘ì„±í•˜ë©´ ëœë‹¤. ìš°ì„  `info`ì—ì„œ ì£¼ì–´ì§„ ì •ë³´ë¡œ `ì ìˆ˜ë¥¼ ì œì™¸í•œ ì¡°ê±´`ë“¤ì„ í•´ì‹œì˜ í‚¤ë¡œ, `ì ìˆ˜ ì¡°ê±´`ì„ í•´ì‹œê°’ìœ¼ë¡œ ì €ì¥í•œë‹¤. ì´ë•Œ, ì ìˆ˜ë¥¼ ì œì™¸í•œ ì¡°ê±´ë“¤ì„ ëª¨ë‘ `'-'`ë¡œ ëŒ€ì²´í•˜ëŠ” ê²½ìš°ë„ ê³ ë ¤í•˜ë„ë¡ í•œë‹¤. ì´ë•Œ íŒŒì´ì¬ `combinations`ë¥¼ ì´ìš©í•´ ëª¨ë“  ì¡°í•©ì„ êµ¬í–ˆë‹¤. ê·¸ ë‹¤ìŒ í•´ì‹œê°’ì¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ê³ , `query`ì— ì£¼ì–´ì§„ `ì ìˆ˜ë¥¼ ì œì™¸í•œ ì¡°ê±´`ì„ í•´ì‹œì—ì„œ ì°¸ì¡°í•´ì„œ ì£¼ì–´ì§„ `ì ìˆ˜ ì¡°ê±´`ê³¼ ê°™ê±°ë‚˜ í° ê°’ë“¤ ì¤‘ ìµœì†Œê°’ì„ êµ¬í•œë‹¤. ì „ì²´ ê¸¸ì´ì—ì„œ ìµœì†Œê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë¹¼ì„œ ë°˜í™˜í•˜ë©´ ëœë‹¤.\n\n### ì‹œê°„ ë³µì¡ë„ ê³„ì‚°í•˜ê¸°\në¬¸ì œê°€ ë˜ëŠ” ê²ƒì€ ì‹œê°„ ë³µì¡ë„ì´ë‹¤. ìš°ì„  ì£¼ì–´ì§„ `info`ë°°ì—´ì˜ í¬ê¸°ê°€ ìµœëŒ€ `50,000`ì´ë¯€ë¡œ, ì ìˆ˜ë¥¼ ì œì™¸í•œ ëª¨ë“  ì¡°ê±´ ì¡°í•©ì„ í•´ì‹œí•˜ëŠ” ê²½ìš° í•´ì‹œì˜ í‚¤ê°€ í˜•ì„±ë˜ëŠ” íšŸìˆ˜ë¥¼ ì„¸ì–´ì•¼ í•œë‹¤. ëª¨ë“  ì¡°ê±´ì—ì„œ `'-'`ê°€ ëŒ€ì‹  ë“¤ì–´ê°€ëŠ” ê²½ìš°ë¥¼ ê³ ë ¤í•´ë„ $\\sum^{4}_{i=0} \\binom{4}{i}$ê°œë¡œ, ì´ ê°’ì€ ìƒìˆ˜ì´ë¯€ë¡œ ì„ í˜•ì‹œê°„ì•ˆì— í•´ê²°í•  ìˆ˜ ìˆë‹¤. \ní•´ì‹œê°’ì„ ì •ë ¬ í•˜ëŠ”ë°ì—ëŠ” $O(NlogN)$ ì‹œê°„ì´ ì†Œìš”ëœë‹¤. ë§ˆì§€ë§‰ ê³¼ì •ì¸ `query`ì— ëŒ€í•´ì„œë„ `forë¬¸`ì„ ê±°ì³ì•¼í•˜ê³ , `query`ê°€ ìµœëŒ€ `100,000`ê°œ ì´ë¯€ë¡œ íš¨ìœ¨ì ì¸ íƒìƒ‰ì´ í•„ìš”í•˜ë‹¤. ì´ì§„íƒìƒ‰ì„ í™œìš©í•˜ë©´ $O(NlogN)$ ì‹œê°„ ë³µì¡ë„ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤. \n\nì „ì²´ ê³¼ì •ì˜ ì‹œê°„ ë³µì¡ë„ëŠ” $O(N) + O(NlogN) + O(NlogN) = O(NlogN)$ì´ ëœë‹¤.\n\n\n## íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom itertools import combinations\n\ndef solution(info, query):\n\n    hsh = {}\n    for inf in info:\n        # infoì˜ ê°’ ì¤‘ ì¡°ê±´ ë¶„ë¥˜ì™€ ì ìˆ˜ë¥¼ ë”°ë¡œ ì €ì¥í•œë‹¤. \n        conds = inf.split()[:-1]\n        score = int(inf.split()[-1])\n        \n        # ëª¨ë“  ì¡°ê±´ì˜ ì¡°í•©ì„ í•´ì‹œí•œë‹¤. \n        for i in range(5):\n            combs = list(combinations(range(4), i))\n            for comb in combs:\n                # ìˆœì„œëŒ€ë¡œ '-'ë¥¼ ì‚½ì…í•˜ëŠ” í‚¤ë¥¼ ìƒì„±í•œë‹¤.\n                temp = conds.copy()\n                for j in comb:\n                    temp[j] = '-'\n                new_cond = ' and '.join(temp)\n                \n                # hshì˜ ì¡°ê±´ ì¡°í•© í‚¤ì— ì ìˆ˜ì„ ì¶”ê°€í•œë‹¤.\n                if new_cond not in hsh:\n                    hsh[new_cond] = [score]\n                else:\n                    hsh[new_cond] += [score]\n\n    # ì´ì§„ ê²€ìƒ‰ì„ ìœ„í•´ hshê°’ ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ê°’ë“¤ì„ ì •ë ¬í•œë‹¤.  \n    for values in hsh.values():\n        values.sort()\n    \n    ret = []   \n    for q in query:\n        # queryì˜ ê°’ ì¤‘ ì¡°ê±´ ë¶„ë¥˜ì™€ ì ìˆ˜ë¥¼ ë”°ë¡œ ì €ì¥í•œë‹¤.\n        cond = ' '.join(q.split()[:-1])\n        score = int(q.split()[-1])\n        \n        # hshì— í•´ë‹¹í•˜ëŠ” í‚¤ê°€ ìˆëŠ” ê²½ìš°\n        if cond in hsh:\n            # hshì˜ ê°’ì—ì„œ ì ìˆ˜ê°€ queryì—ì„œ ìš”êµ¬í•˜ëŠ” ì ìˆ˜ \n            # scoreì™€ ê°™ê±°ë‚˜ í° ì ìˆ˜ë¥¼ ì´ì§„ íƒìƒ‰í•œë‹¤.\n            left, right = 0, len(hsh[cond])\n            while left <= right and left != len(hsh[cond]):\n                half = (left + right) // 2\n                if hsh[cond][half] >= score:\n                    right = half - 1\n                else:\n                    left = half + 1\n            # í•´ì‹œê°’ ê¸¸ì´ì—ì„œ leftmost ì¸ë±ìŠ¤ë¥¼ ëº€ ê°’ì„ ì €ì¥í•œë‹¤.\n            ret.append(len(hsh[cond]) - left)\n        # ë§Œì•½ hshì— í•´ë‹¹ í‚¤ê°€ ì—†ëŠ” ê²½ìš°, 0ì„ ì €ì¥í•œë‹¤.\n        else:\n            ret.append(0)\n\n    return ret\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ íš¨ìœ¨ì„± í†µê³¼ê°€ ê¹Œë‹¤ë¡­ë‹¤ê³  ëŠê¼ˆë˜ ë¬¸ì œì¤‘ í•˜ë‚˜ë¡œ, ì ìˆ˜ë¥¼ ì œì™¸í•œ ê°€ ì— ë¶ˆê³¼í•˜ë‹¤ëŠ” ì ì„ ì´ìš©í•´ì„œ ëª¨ë“  ì¡°ê±´ ì¡°í•©ì„ í•´ì‹œí•œ ë‹¤ìŒ ì´ì§„ ê²€ìƒ‰ì„ í†µí•´ í•´ê²°í•  ìˆ˜ ìˆì—ˆë‹¤. ì½”ë“œëŠ” ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ìˆœì„œëŒ€ë¡œ ì‘ì„±í•˜ë©´ ëœâ€¦","fields":{"slug":"/programmers. á„‰á…®á†«á„‹á…± á„€á…¥á†·á„‰á…¢á†¨/"},"frontmatter":{"date":"Mar 05, 2022","title":"programmers. ìˆœìœ„ ê²€ìƒ‰","tags":["Algorithms","programmers","Hashing","Binary Search"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/43163)\n\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n\në‹¨ì–´ê°€ ì•ŒíŒŒë²³ í•˜ë‚˜ ì°¨ì´ë¡œ ë‹¤ë¥¸ ê²½ìš° ë‹¨ì–´ ë…¸ë“œë¥¼ ê°„ì„ ìœ¼ë¡œ ì—°ê²°í•œ í›„ ì‹œì‘ ë‹¨ì–´ì—ì„œ íƒ€ê¹ƒ ë‹¨ì–´ì— ì´ë¥´ê¸° ê¹Œì§€ ê¹Šì´ ìš°ì„  íƒìƒ‰ì„ ì´ìš©í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n\n- ê·¸ë˜í”„ ìƒì„±: ë‹¨ì–´ 2ê°œ ì¡°í•©ì—ì„œ ì•ŒíŒŒë²³ì´ í•˜ë‚˜ ì°¨ì´ë‚˜ëŠ” ë‹¨ì–´ë¥¼ ê·¸ë˜í”„ì— ì €ì¥í•œë‹¤.\n- ìµœì†Œ ë³€í™˜ íšŸìˆ˜ ì°¾ê¸°: ê¹Šì´ ìš°ì„  íƒìƒ‰ì„ ì´ìš©í•´, íƒ€ê²Ÿ ë‹¨ì–´ì— ì´ë¥´ê¸°ê¹Œì§€ ìµœì†Œ ê±°ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©° ì—°ê²°ëœ ë…¸ë“œë¥¼ íƒìƒ‰í•œë‹¤.\n\n\n## íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom collections import defaultdict\nfrom itertools import combinations\n\ndef solution(begin, target, words):\n    \n    graph = defaultdict(list)\n    combs = list(combinations(words + [begin], 2))\n    \n    # 2ê°œ ë‹¨ì–´ ì¡°í•© ì¤‘ì—ì„œ ì•ŒíŒŒë²³ì´ í•˜ë‚˜ ì°¨ì´ë‚˜ë©´ graphì— ì €ì¥\n    for comb in combs:\n        w1, w2 = comb[0], comb[1]\n        sameness = sum([1 if c1 == c2 else 0 for c1, c2 in zip(w1, w2)])\n        if sameness == len(w1) - 1:\n            graph[w1].append(w2)\n            graph[w2].append(w1)\n        \n    # ê¹Šì´ ìš°ì„  íƒìƒ‰ êµ¬í˜„\n    min_d = 100\n    visited = []\n    # stackì— [ë…¸ë“œ, beginì—ì„œì˜ ê±°ë¦¬] í˜•íƒœë¡œ ì €ì¥\n    stack = [[begin, 0]]\n    while stack:\n        v, d = stack.pop()\n        if v == target and min_d > d:\n            min_d = d\n        if v not in visited:\n            visited.append(v)\n            for u in graph[v]:\n                stack.append([u, d + 1])\n    \n    return min_d if min_d != 100 else 0\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ë‹¨ì–´ê°€ ì•ŒíŒŒë²³ í•˜ë‚˜ ì°¨ì´ë¡œ ë‹¤ë¥¸ ê²½ìš° ë‹¨ì–´ ë…¸ë“œë¥¼ ê°„ì„ ìœ¼ë¡œ ì—°ê²°í•œ í›„ ì‹œì‘ ë‹¨ì–´ì—ì„œ íƒ€ê¹ƒ ë‹¨ì–´ì— ì´ë¥´ê¸° ê¹Œì§€ ê¹Šì´ ìš°ì„  íƒìƒ‰ì„ ì´ìš©í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆë‹¤. ê·¸ë˜í”„ ìƒì„±: ë‹¨ì–´ 2ê°œ ì¡°í•©ì—ì„œ ì•ŒíŒŒë²³ì´ í•˜ë‚˜ ì°¨ì´ë‚˜â€¦","fields":{"slug":"/programmers. ë‹¨ì–´ ë³€í™˜/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. ë‹¨ì–´ ë³€í™˜","tags":["Algorithms","programmers","Graph","DFS"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/42627)\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n\n- í•˜ë“œë””ìŠ¤í¬ê°€ ë¹„ì–´ìˆì„ ë•Œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ë°”ë¡œ ì²˜ë¦¬í•œë‹¤.\n- í•˜ë“œë””ìŠ¤í¬ê°€ ì‘ì—… ì¤‘ì¼ ë•Œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì„ ëë‚´ê³ , ì‘ì—… ì†Œìš” ì‹œê°„ì„ ìµœì†Œ í™ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í™ì˜ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•œë‹¤.\n\nì´ë•Œ `start`ì™€ `end`ë¡œ í˜„ì¬ ì‘ì—… ì‹œê°„ì˜ ì–‘ìª½ ëì„ ì„¤ì •í•´ì„œ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•  ìˆ˜ ìˆë‹¤. ë˜ ë£¨í”„ë¥¼ ì‹œì‘í•  ë•Œ ìš”ì²­ì‹œê°„ì´ `end`ì™€ ì‘ê±°ë‚˜ ê°™ì€ ê²ƒìœ¼ë¡œ íƒìƒ‰í•˜ë¯€ë¡œ, ì•„ë¬´ ê²ƒë„ ì²˜ë¦¬í•˜ì§€ ì•ŠëŠ” ë¹ˆ ì‹œê°„ì— ëŒ€í•´ ì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ `jobs`ì˜ ì¸ë±ìŠ¤ `i`ëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  `end`ë¥¼ 1ì”© ì¦ê°€ì‹œí‚¨ë‹¤. \n\n`jobs`ì˜ ê¸¸ì´, ì¦‰ í™ì´ ì •ë ¬í•  ì›ì†Œ ê°œìˆ˜ì˜ ìµœëŒ€ê°’ì€ 500 ì´í•˜ì´ê³ , ì‘ì—… ì†Œìš”ì‹œê°„ì€ 1,000ì´í•˜ì´ì§€ë§Œ ë‹¤ìŒì½”ë“œì—ì„œ í•œë²ˆì— ì²˜ë¦¬(`end += now[0]`)í•˜ë¯€ë¡œ ì‹œê°„ë‚´ì— ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n\n## íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom heapq import heappush, heappop\n\ndef solution(jobs):\n\n    start, end = -1, 0\n    ret, hq = [], []\n\n    i = 0\n    # í™ì—ì„œ í•˜ë‚˜ë¥¼ êº¼ë‚¼ë•Œ ë§ˆë‹¤ startì™€ endë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤\n    while i < len(jobs):\n        # ìš”ì²­ì‹œê°„ì´ ì‘ì—… ë„ì¤‘ì¸ ê²½ìš°, í™ì— ì¶”ê°€í•˜ê¸°\n        for job in jobs:\n            if start < job[0] <= end:\n                heappush(hq, [job[1], job[0]])\n        # í™ì´ ë¹„ì–´ ìˆì§€ ì•Šìœ¼ë©´\n        # í™ì— ìˆëŠ” ì†Œìš” ì‹œê°„ì´ ê°€ì¥ ì‘ì€ ì‘ì—…ì„ ì²˜ë¦¬í•œë‹¤\n        if len(hq) > 0:\n            now = heappop(hq)\n            start = end\n            end += now[0]\n            ret.append(end - now[1])\n            i += 1\n        # í™ì´ ë¹„ì—ˆìœ¼ë©´, ì¦‰ í˜„ì¬ ì‘ì—…ì´ ëë‚  ë•Œê¹Œì§€ ìš”ì²­ì´ ì—†ìœ¼ë©´\n        # ìš”ì²­ì´ ë“¤ì–´ì˜¬ ë•Œê¹Œì§€ endë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤\n        else:\n            end += 1\n\n    # ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ì‘ì—… ì†Œìš”ì‹œê°„ í‰ê· ì„ ë°˜í™˜í•œë‹¤\n    return sum(ret) // len(ret)\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ í•˜ë“œë””ìŠ¤í¬ê°€ ë¹„ì–´ìˆì„ ë•Œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ë°”ë¡œ ì²˜ë¦¬í•œë‹¤. í•˜ë“œë””ìŠ¤í¬ê°€ ì‘ì—… ì¤‘ì¼ ë•Œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì„ ëë‚´ê³ , ì‘ì—… ì†Œìš” ì‹œê°„ì„ ìµœì†Œ í™ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í™ì˜ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•œë‹¤. ì´ë•Œ ì™€ ë¡œ í˜„ì¬â€¦","fields":{"slug":"/programmers. ë””ìŠ¤í¬ ì»¨íŠ¸ë¡¤ëŸ¬/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. ë””ìŠ¤í¬ ì»¨íŠ¸ë¡¤ëŸ¬","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/12927)\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\në¬¸ì œì—ì„œ ì •ì˜í•œ ì•¼ê·¼ í”¼ë¡œë„ëŠ” ì•¼ê·¼ì„ ì‹œì‘í•œ ì‹œì ì—ì„œ ë‚¨ì€ ì¼ì˜ ì‘ì—…ëŸ‰ì„ ëª¨ë‘ ì œê³±í•˜ì—¬ ë”í•œ ê°’ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. ìˆ˜ì‹ìœ¼ë¡œ ì“°ë©´ ë¬¸ì œì˜ ëª©í‘œëŠ”\n$$\nmin(\\sigma_i {work_i}^2) \n$$\nì´ê³  ì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ìµœëŒ€ê°’ì„ ìµœì†Œí™”í•´ì„œ ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆë‹¤. (ë‚¨ì€ ì‘ì—…ëŸ‰ì´ ì£¼ì–´ì§€ê³  ê·¸ ì¤‘ì—ì„œ 1ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆì„ë•Œ, ê°€ì¥ í° ê°’ì„ 1 ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì „ì²´ ì‹ì„ ìµœì†Œí™”í•œë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•  ìˆ˜ ìˆë‹¤.) ë”°ë¼ì„œ ì„ì˜ ì‹œì ì—ì„œ ê°€ì¥ ì‘ì—…ëŸ‰ì´ í° ì¼ì„ 1ë§Œí¼ ì²˜ë¦¬í•´ì•¼ í•˜ë©°, ì‘ì—…ëŸ‰ì„ ìµœëŒ€í™ìœ¼ë¡œ ì •ë ¬í•´ì„œ ê³¼ì œë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nnì€ 1,000,000 ì´í•˜ì˜ ìì—°ìˆ˜ì´ê³  ìµœëŒ€ $2*n$ë²ˆ í™ ì—°ì‚°ì´ ìˆ˜í–‰ë˜ë¯€ë¡œ $O(nlogn)$ ì‹œê°„ ë‚´ì— ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n\n## íŒŒì´ì¬ ì½”ë“œ\n```python\nimport heapq\n\ndef solution(n, works):\n    if sum(works) <= n: return 0\n    \n    yageun = []\n    for work in works:\n        heapq.heappush(yageun, -work)\n        \n    # í•œ ì‹œê°„ ì”© ì‘ì—…í•˜ë˜, ê°€ì¥ ì‘ì—…ëŸ‰ì´ í° ì¼ì„ 1ë§Œí¼ ì²˜ë¦¬í•œë‹¤\n    while n != 0:\n        work = heapq.heappop(yageun)\n        heapq.heappush(yageun, work + 1)\n        n -= 1\n        \n    # í™ì— ë‚¨ì€ ì›ì†Œì— ëŒ€í•´ ì•¼ê·¼ í”¼ë¡œë„ë¥¼ ê³„ì‚°í•œë‹¤\n    return sum(list(map(lambda x: x ** 2, yageun)))\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ë¬¸ì œì—ì„œ ì •ì˜í•œ ì•¼ê·¼ í”¼ë¡œë„ëŠ” ì•¼ê·¼ì„ ì‹œì‘í•œ ì‹œì ì—ì„œ ë‚¨ì€ ì¼ì˜ ì‘ì—…ëŸ‰ì„ ëª¨ë‘ ì œê³±í•˜ì—¬ ë”í•œ ê°’ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. ìˆ˜ì‹ìœ¼ë¡œ ì“°ë©´ ë¬¸ì œì˜ ëª©í‘œëŠ” ì´ê³  ì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ìµœëŒ€ê°’ì„ ìµœì†Œí™”í•´ì„œ ëª©í‘œë¥¼ ë‹¬ì„±í•  â€¦","fields":{"slug":"/programmers. ì•¼ê·¼ ì§€ìˆ˜/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. ì•¼ê·¼ ì§€ìˆ˜","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/42628)\n\n## ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n\nìµœì†Œ í™ê³¼ ìµœëŒ€ í™ì„ ë™ì‹œì— ì´ìš©í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤. ì´ì¤‘ ìš°ì„ ìˆœìœ„ íì— ì ìš©í•˜ëŠ” ì„¸ê°€ì§€ ì—°ì‚°ì„ ê²½ìš° ë³„ë¡œ ë‚˜ëˆ„ì–´ ê³ ë ¤í•œë‹¤.\n\n- ì›ì†Œë¥¼ ì¶”ê°€í•  ê²½ìš°, ìµœì†Œ í™ê³¼ ìµœëŒ€ í™ì— ëª¨ë‘ ì¶”ê°€í•œë‹¤.\n- ìµœì†Œê°’ì„ ì œê±°í•  ê²½ìš°, ìµœì†Œ í™ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ìµœì†Œí™ì˜ ìµœì†Œê°’ì„ ì œê±°í•œë‹¤. ë§Œì•½ ìµœëŒ€í™ì˜ ì¸ë±ìŠ¤ 0ì¸ ê°’ì´ ì§€ìš°ë ¤ëŠ” í•´ë‹¹ ì›ì†Œì´ë©´, ìµœëŒ€í™ì—ì„œ ì´ ì›ì†Œë¥¼ ì œê±°í•œë‹¤.\n- ìµœëŒ€ê°’ì„ ì œê±°í•  ê²½ìš°, ìµœëŒ€ í™ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ìµœëŒ€í™ì˜ ìµœëŒ€ê°’ì„ ì œê±°í•œë‹¤. ë§Œì•½ ìµœì†Œí™ì˜ ì¸ë±ìŠ¤ 0ì¸ ê°’ì´ ì§€ìš°ë ¤ëŠ” í•´ë‹¹ ì›ì†Œì´ë©´, ìµœì†Œí™ì—ì„œ ì´ ì›ì†Œë¥¼ ì œê±°í•œë‹¤.\n- ë‹¤ìŒ ë£¨í”„ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì—, ìµœì†Œ í™ì´ë‚˜ ìµœëŒ€ í™ ì¤‘ í•˜ë‚˜ë¼ë„ ë¹„ì–´ìˆê±°ë‚˜ ìµœì†Œí™ì˜ ìµœì†Œê°’ì´ ìµœëŒ€í™ì˜ ìµœëŒ€ê°’ë³´ë‹¤ í¬ë©´, ë‘ê°œ í™ì„ ëª¨ë‘ ë¹„ìš´ë‹¤.\n\në£¨í”„ê°€ ì¢…ë£Œëœ í›„, ìµœì†Œí™ê³¼ ìµœëŒ€í™ ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë¹„ì–´ìˆìœ¼ë©´ ì´ì¤‘ ìš°ì„ ìˆœìœ„ íê°€ ë¹„ì—ˆë‹¤ëŠ” ëœ»ì´ë¯€ë¡œ [0,0]ì„ ë°˜í™˜í•œë‹¤. ì•„ë‹ê²½ìš°, ìµœëŒ€í™ì—ì„œ ìµœëŒ€ê°’ì„ ìµœì†Œí™ì—ì„œ ìµœì†Œê°’ì„ ë°˜í™˜í•œë‹¤.\n\nì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ operationsì˜ ê¸¸ì´ëŠ” ìµœëŒ€ 1,000,000ì´ì§€ë§Œ, í™ìœ¼ë¡œ ì •ë ¬í•œ ìˆ˜í–‰ì‹œê°„ì€ $O(NlogN)$ìœ¼ë¡œ ì‹œê°„ë‚´ì— í•´ê²° í•  ìˆ˜ ìˆë‹¤.\n\n\n## íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom heapq import heappush, heappop\n\ndef solution(operations):\n    \n    hq1, hq2 = [], []\n    for op in operations:\n        # hq1ì´ ìµœì†Œ í™, hq2ê°€ ìµœëŒ€ í™\n        if op[0] == 'I':\n            heappush(hq1, int(op.split()[-1]))\n            heappush(hq2, -int(op.split()[-1]))\n        \n        # ìµœëŒ€ í™ì—ì„œ ì›ì†Œë¥¼ ì œê±°í•œë‹¤\n        # ìµœì†Œ í™ì´ ë¹„ì§€ ì•Šê³ , ì‚­ì œí•  ê°’ì´ ìµœì†Œ í™ì— ìˆìœ¼ë©´, ìµœì†Œ í™ì—ì„œ ì›ì†Œë¥¼ ì œê±°í•œë‹¤\n        elif op == 'D 1' and hq2 != []:\n            if hq1 and hq1[0] == -hq2[0]:\n                heappop(hq1)\n            heappop(hq2)\n\n        # ìµœì†Œ í™ì—ì„œ ì›ì†Œë¥¼ ì œê±°í•œë‹¤\n        # ìµœëŒ€ í™ì´ ë¹„ì§€ ì•Šê³ , ì‚­ì œí•  ê°’ì´ ìµœëŒ€ í™ì— ìˆìœ¼ë©´, ìµœëŒ€ í™ì—ì„œ ì›ì†Œë¥¼ ì œê±°í•œë‹¤\n        elif op == 'D -1' and hq1 != []:\n            if hq2 and hq1[0] == -hq2[0]:\n                heappop(hq2)\n            heappop(hq1)\n\n        # ìµœì†Œ í™ì´ë‚˜ ìµœëŒ€ í™ ì¤‘ í•˜ë‚˜ë¼ë„ ë¹„ì–´ìˆê±°ë‚˜, ë‘ í™ì˜ ìµœì†Œê°’ì´ ìµœëŒ€ê°’ë³´ë‹¤ í¬ë‹¤ë©´ \n        # í™ì„ ëª¨ë‘ ë¹„ìš´ë‹¤\n        if (not hq1 or not hq2) or (hq1[0] > -hq2[0]): \n            hq1, hq2 = [], []\n            \n    if not hq1 or not hq2: \n        return [0, 0]\n\n    return [-hq2[0], hq1[0]]\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ìµœì†Œ í™ê³¼ ìµœëŒ€ í™ì„ ë™ì‹œì— ì´ìš©í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤. ì´ì¤‘ ìš°ì„ ìˆœìœ„ íì— ì ìš©í•˜ëŠ” ì„¸ê°€ì§€ ì—°ì‚°ì„ ê²½ìš° ë³„ë¡œ ë‚˜ëˆ„ì–´ ê³ ë ¤í•œë‹¤. ì›ì†Œë¥¼ ì¶”ê°€í•  ê²½ìš°, ìµœì†Œ í™ê³¼ ìµœëŒ€ í™ì— ëª¨ë‘ ì¶”ê°€í•œë‹¤. ìµœì†Œê°’ì„ ì œê±°í•  ê²½ìš°, â€¦","fields":{"slug":"/programmers. ì´ì¤‘ ìš°ì„ ìˆœìœ„ í/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. ì´ì¤‘ ìš°ì„ ìˆœìœ„ í","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n`word2vec`ì€ 2013ë…„ êµ¬ê¸€ì—ì„œ ê³ ì•ˆí•œ ìì—°ì–´ ì²˜ë¦¬ ì•„ì´ë””ì–´ë¡œ, ì´ì— ê¸°ë°˜í•œ ëª¨ë¸ì€ `Continuous Bag-of-Words(CBOW)`ì™€ `Skip-gram` ë‘ê°€ì§€ê°€ ìˆë‹¤. ì´ ê¸€ì€ ê·¸ ì¤‘ì—ì„œ `CBOW` ëª¨ë¸ì„ ì› ë…¼ë¬¸ê³¼ deeplearning.ai ìˆ˜ì—…ì„ ì°¸ê³ í•˜ì—¬ ì •ë¦¬í•œ ê¸€ì´ë‹¤. \n\n**ì› ë…¼ë¬¸**:\n- Mikolov et. al., 2013, Efficient Estimation of Word Representations in Vector Space ([arxiv](https://arxiv.org/pdf/1301.3781.pdf))\n- Mikolov et. al., 2013, Distributed Representations of Words and Phrases and their Compositionality ([arxiv](https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf))\n\n\n## 0. CBOWë€\nCBOW(Continuous Bag-of-Words, ì—°ì†ë˜ëŠ” ë‹¨ì–´ ì£¼ë¨¸ë‹ˆ)ëŠ” \n- í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë²¡í„° ê³µê°„ì— í‘œí˜„í•˜ëŠ” `ë‹¨ì–´ ì„ë² ë”©(word embedding)` ëª¨ë¸ì´ì,  \n- `ì–•ì€ ì‹ ê²½ë§(neural network)` ëª¨ë¸ì´ë©°, \n- ìŠ¤ìŠ¤ë¡œ í›ˆë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” `ìê¸° ì§€ë„ í›ˆë ¨(self-supervised learning)` ëª¨ë¸ì´ë‹¤. \n\nCBOW ëª¨ë¸ì´ ì²˜ìŒ ì†Œê°œë  ë•ŒëŠ” 50-100 ì°¨ì›ì˜ ì› í•« ë²¡í„°ë¡œ ëª‡ ë°±ë§Œê°œì˜ ë‹¨ì–´ë¥¼ í›ˆë ¨ì‹œì¼°ë‹¤. \n\n\n### ğŸ“– Skip-gramê³¼ì˜ ì°¨ì´ì \nCBOW ëª¨ë¸ì€ ì—¬ëŸ¬ê°œì˜ ë‹¨ì–´ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ë©´ ê·¸ì— ìƒì‘í•˜ëŠ” í•œê°œì˜ ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ëŠ” `Many to One` (ì—¬ëŸ¬ê°œ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ í•œê°œì˜ ë°ì´í„°ë¥¼ ì¶œë ¥í•˜ëŠ” ëª¨ë¸ êµ¬ì¡°) ëª¨ë¸ì´ë‹¤. ë°˜ë©´ Skip-gramì€ í•œê°œì˜ ë‹¨ì–´ë¥¼ ì…ë ¥í–ˆì„ ë•Œ ê·¸ì— ëŒ€ì‘í•˜ëŠ” ì—¬ëŸ¬ê°œì˜ ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ëŠ” `One to Many` ëª¨ë¸ì´ë‹¤. ì¦‰ ë‘ ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” `ë°˜ì „`ë˜ì–´ìˆê³ , ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì´ ì„œë¡œ ë°˜ëŒ€ëœë‹¤. \n\n## 1. ëª¨ë¸ì˜ êµ¬ì¡°\nCBOWëŠ” ì–•ì€ ì‹ ê²½ë§ ëª¨ë¸ë¡œ, ì´ ê¸€ì—ì„œëŠ” í•œ ê°œì˜ ì€ë‹‰ì¸µ(hidden layer)ë¥¼ ê°€ì§€ëŠ” ì‹ ê²½ë§ ëª¨ë¸ì„ ê³ ë ¤í•œë‹¤.\n\n![](cbow_model_architecture.png)\n*image by DeepLearning.AI*\n\nëª¨ë¸ì˜ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1. í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì› í•« ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤.\n2. ì²«ë²ˆì§¸ ì€ë‹‰ì¸µ(hidden layer)ì„ ê±°ì¹œë‹¤.\n    - í™œì„±í™” í•¨ìˆ˜ : ReLU\n3. ë‘ë²ˆì§¸ ê²°ê³¼ì¸µ(output layer)ì„ ê±°ì¹œë‹¤.\n    - í™œì„±í™” í•¨ìˆ˜ : Softmax\n4. ê²°ê³¼ ë²¡í„°ì˜ ê°’ ì¤‘ ê°€ì¥ í° ê°’ìœ¼ë¡œ ì˜ˆì¸¡í•œë‹¤.\n\nëª¨ë¸ì„ ì´í•´í•˜ê³  ì‹¤ì œë¡œ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„œëŠ” ê° ì¸µì˜ ì°¨ì›ì„ ì •í™•íˆ ì•Œì•„ì•¼ í•œë‹¤.\n### ğŸ“– ë²¡í„°ì˜ ì°¨ì›\në³€ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ë•Œ,\n- $V$ : ë‹¨ì–´ ì‚¬ì „ì˜ í¬ê¸°,  í˜¹ì€ ì›-í•« ë²¡í„°ì˜ í¬ê¸°.\n- $N$ : ì„ë² ë”© í¬ê¸°. ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì´ë‹¤.\n- $m$ : ë°°ì¹˜ í¬ê¸°. í•œë²ˆì— í›ˆë ¨í•  ë°ì´í„°ì˜ ê°œìˆ˜ì´ë‹¤.\n\nì…ë ¥ê°’ $X$ì˜ ì°¨ì›\n$$\nX \\in M(V, m)\n$$\nì— ëŒ€í•´ ê° ì¸µì— ëŒ€í•œ ë²¡í„°ì˜ ì°¨ì›ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.\n<center>\n\n|ì€ë‹‰ì¸µ ë²¡í„°|ì°¨ì›|ê²°ê³¼ì¸µ ë²¡í„°|ì°¨ì›|\n|---|---|---|---|\n|$W_1$|$(N, V)$|$W_2$|$(V, N)$|\n|$B_1$|$(N, m)$|$B_2$|$(V, m)$|\n|$z_1$|$(N, m)$|$z_2$|$(V, m)$|\n|$relu(z_1)$|$(N, m)$|$softmax(z_2)$|$(V, m)$|\n</center>\n\n$softmax(z_2) \\equiv \\hat{Y}$ ì´ë¯€ë¡œ ì˜ˆì¸¡ê°’ì´ ì…ë ¥ê°’ê³¼ ê°™ì€ ì°¨ì›ì„ ê°€ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì¦‰ ëª¨ë¸ì´ ë°˜í™˜í•˜ëŠ” ë²¡í„°ì˜ ì—´ ë²¡í„°ëŠ” ì…ë ¥ ì—´ ë²¡í„°ì™€ ìˆœì„œê°€ ê°™ì€ ì› í•« ë²¡í„°ì´ë‹¤.\n\n## 2. ëª¨ë¸ì˜ ì „ì²˜ë¦¬\n\nCBOW ëª¨ë¸ë¡œ ë¬¸ì¥ì˜ ë¹ˆì¹¸ì„ ì£¼ìœ„ ë‹¨ì–´ì— ê¸°ë°˜í•´ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì œë¥¼ ìˆ˜í–‰í•´ë³´ì. ë‹¤ìŒ ë¬¸ì¥ì˜ ë¹ˆì¹¸ì— ë­ê°€ ë“¤ì–´ê°ˆê¹Œ?\n\n\"npmì€ Node.jsì˜ ____ ê´€ë¦¬ë¥¼ ìœ„í•œ íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €ì´ë‹¤.\"\n\nCBOW ëª¨ë¸ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„œëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°í™” í•œ í›„, ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë‹¤ìŒ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤.\n\n### ğŸ“–  ì¤‘ì‹¬ì–´(center word)ì™€ ë§¥ë½ ë‹¨ì–´ë“¤(context words)\nìê¸° ì§€ë„ í•™ìŠµì€ ì‚¬ëŒì´ ë¼ë²¨ë§ì„ í•  í•„ìš”ê°€ ì—†ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ì„œëŠ” ê°€ê³µë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í›ˆë ¨ ë°ì´í„°($X$, ì…ë ¥ ë°ì´í„°)ì™€ í›ˆë ¨ íƒ€ê²Ÿ($Y$, ì°¸ê°’)ì„ êµ¬ë¶„í•´ì„œ ìë£Œí™”í•  í•„ìš”ê°€ ìˆë‹¤. \n\nCBOW ëª¨ë¸ì—ì„œ ì˜ˆì¸¡í•  ëŒ€ìƒ(target)ì¸ ë¬¸ì¥ì˜ ë¹ˆì¹¸ì„ `ì¤‘ì‹¬ì–´`ë¡œ, ì´ ë‹¨ì–´ì™€ ë¬¸ì¥ ë‚´ì—ì„œ ì¸ì ‘í•œ ë‹¨ì–´ë¥¼ `ë§¥ë½ ë‹¨ì–´`ë¡œ ì´ë¦„ì§€ì„ ìˆ˜ ìˆë‹¤. `ë§¥ë½ ë‹¨ì–´`ëŠ” ì¤‘ì‹¬ì–´ë¡œ ë¶€í„° ê±°ë¦¬ $C$ ë§Œí¼ ë–¨ì–´ì ¸ ìˆëŠ” ì¸ì ‘í•œ ë‹¨ì–´ë“¤ë¡œ ì •ì˜í•˜ë©°, $C$ë¥¼ `ë§¥ë½ì˜ ì ˆë°˜ í¬ê¸°(context half-size)`ë¼ê³  í•˜ì. $C$ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤‘ í•˜ë‚˜ì´ë‹¤. ì™¼ìª½ ë§¥ë½ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ì™€ ì¤‘ì‹¬ì–´, ì˜¤ë¥¸ìª½ ë§¥ë½ ë¦¬ìŠ¤íŠ¸ì˜ í¬ê¸°ë¥¼ ëª¨ë‘ ë”í•œ ê°’ì„ `ìœˆë„ìš°`ë¼ê³  ì¼ì»«ëŠ”ë‹¤. \n\nì˜ˆë¥¼ ë“¤ë©´, ë¬¸ì¥ í•œê°œë¡œ êµ¬ì„±ëœ ë°ì´í„°ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì´í•´í•  ìˆ˜ ìˆë‹¤. \n```python\n# given tokenized data and context half-size, \n# returns center word and list of context words \ndef center_and_context_word(data, C):\n    for i in range(C, len(data)-C):\n        center_word = data[i]\n        context_words = []\n        for j in range(i-C, i+C+1):\n            if j != i:\n                context_words.append(data[j])\n        yield center_word, context_words\n\nC = 2 # context half-size\ndata = [\"npmì€\", \"Node.jsì˜\", \"íŒ¨í‚¤ì§€\", \"ê´€ë¦¬ë¥¼\", \"ìœ„í•œ\", \"íŒ¨í‚¤ì§€\", \"ë§¤ë‹ˆì €ì´ë‹¤\", \".\"]\n\ncenter_word, context_word = next(center_and_context_word(data, C))\n\nprint(center_word) # \"íŒ¨í‚¤ì§€\"\nprint(context_word) # [\"npmì€\", \"Node.jsì˜\", \"ê´€ë¦¬ë¥¼\", \"ìœ„í•œ\"]\nprint(len(context_word + center_word)) # 5, window\n``` \nëª¨ë¸ì˜ ì…ë ¥ê°’ì€ `ë§¥ë½ ë‹¨ì–´ ë²¡í„°ë“¤ì˜ í‰ê· ê°’`ì„ ì·¨í•œë‹¤. ì‚¬ì‹¤ CBOW ëª¨ë¸ ì´ë¦„ì— Bagì´ ë“¤ì–´ê°€ëŠ” ì´ìœ ëŠ” $C$ì˜ ë²”ìœ„ ë‚´ì— ìˆëŠ” ë§¥ë½ ë‹¨ì–´ë“¤ì´ ë¬¸ì¥ì—ì„œì˜ ìˆœì„œì— ê´€ê³„ì—†ì´ ì—¬ê²¨ì§€ê¸° ë•Œë¬¸ì´ê³ , ì´ íŠ¹ì§•ì€ ì´í›„ì— ë“±ì¥í•˜ëŠ” Sequential ëª¨ë¸ê³¼ êµ¬ë¶„ë˜ëŠ” ì°¨ì´ì ì´ë‹¤.\n\n\n## 3. ëª¨ë¸ í›ˆë ¨í•˜ê¸°\n\nCBOW ëª¨ë¸ì€ ì‹ ê²½ë§ ëª¨ë¸ì´ë¯€ë¡œ ì¼ë°˜ì ì¸ forward propagation, backward propagation, gradient descent ê³¼ì •ì„ ê±°ì¹œë‹¤. ì„¸ê°€ì§€ ê³¼ì •ì„ `keras` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ `Layer` ê°ì²´ë¡œ ë¹„êµì  ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n\n\n### ğŸ“‚ Kerasë¡œ CBOW êµ¬í˜„í•˜ê¸°\n```python\nfrom tf.keras import layers\n\n# Input size: (batch_size, vocab_size)\ncbow_model = tf.keras.Sequential{\n    # ì› í•« ë²¡í„°ì˜ ë°°ì¹˜ë¥¼ ì„ë² ë“œí•œë‹¤\n    input_layer = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim), \n    # relu ì€ë‹‰ì¸µìœ¼ë¡œ ë¹„ìš©ì´ ìŒìˆ˜ê°’ì„ ê°€ì§€ì§€ ì•Šê²Œ í•œë‹¤\n    hidden_layer = layers.Dense(units=embed_dim,activation='relu'), \n    # ì› í•« ë²¡í„°ì˜ ë°°ì¹˜ë¥¼ í™•ë¥ ë¡œ ì¶œë ¥í•œë‹¤\n    output_layer = layers.Dense(input_dim=vocab_size, activation='softmax')\n}\n\nbatch_size = 256\nepochs = 10\n\ncbow_model.compile(\n    optimizer='Adam', \n    loss=tf.keras.losses.CategoricalCrossentropy()\n)\n\ncbow_model.fit(\n    train_data, train_target, \n    batch_size=batch_size, epochs=epochs\n)\n```\n\n## 4. ë‹¨ì–´ ì„ë² ë”© ì¶”ì¶œí•˜ê¸°\n\në‹¨ì–´ ì„ë² ë”©ì€ ì› í•« ë²¡í„°ì— ë¹„í•´ `ë°€ë„ê°€ ë†’ì€(Dense) ë²¡í„°`ë¡œ, ë‹¨ì–´ ì„ë² ë”©ì—ëŠ” ì—¬ëŸ¬ê°€ì§€ ì´ì ì´ ìˆë‹¤. ì²«ì§¸ë¡œ ë‹¨ì–´ ì„ë² ë”© ë²¡í„°ê°„ì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•´ì„œ ì˜ë¯¸ë¡ ì (semantic)ì´ê³  ë¬¸ë²•ë¡ ì ì¸(syntactic) ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ë‘˜ì§¸ë¡œ ì°¨ì›ì„ ì‘ê²Œ ë§Œë“œëŠ” ê²ƒ, ì¦‰ `ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction)`ë¥¼ í†µí•´ ê³„ì‚° íšŸìˆ˜ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ë²¡í„°ì˜ ë°€ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì€ ê°™ì€ ë°ì´í„°ë¥¼ ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ ì°¨ì›ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì„ ëœ»í•œë‹¤. ë°˜ë©´ì— ë²¡í„°ì˜ ì°¨ì›ì´ ì¦ê°€í•¨ì— ë”°ë¼ ë²¡í„°ë¥¼ ê³„ì‚°í•˜ëŠ” íšŸìˆ˜ëŠ” ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ê²Œ ë˜ëŠ”ë°, ì´ í˜„ìƒì„ `ì°¨ì›ì˜ ì €ì£¼(the curse of dimensionality)`ë¼ê³  í•œë‹¤. ê·¸ ì¤‘ì—ì„œ 2ì°¨ì›ì´ë‚˜ 3ì°¨ì› ë²¡í„°ëŠ” ì‹œê°í™”ê°€ ê°€ëŠ¥í•˜ë¯€ë¡œ ì§ê´€ì ì¸ ì´í•´ì— ë„ì›€ì´ ëœë‹¤.\n\në‹¨ì–´ ì„ë² ë”©ì€ CBOW ëª¨ë¸ì˜ ë¶€ì‚°ë¬¼ì´ë¼ê³  í•  ìˆ˜ ìˆëŠ”ë°, ë‹¨ì–´ ì„ë² ë”©ì€ í›ˆë ¨ì´ ëë‚œ í›„ ê·¸ ê²°ê³¼ì¸ ê°€ì¤‘ì¹˜ ë²¡í„°ë¡œ ë¶€í„° ì–»ì„ ìˆ˜ ìˆë‹¤.\n\në‹¨ì–´ ì„ë² ë”©ìœ¼ë¡œ ì„ íƒí•  ìˆ˜ ìˆëŠ” `ì˜µì…˜`ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n- ì²«ë²ˆì§¸ ê°€ì¤‘ì¹˜ ë²¡í„° $W_1$ ì˜ ì—´(column) ë²¡í„°\n- ë‘ë²ˆì§¸ ê°€ì¤‘ì¹˜ ë²¡í„° $W_2$ ì˜ í–‰(row) ë²¡í„°\n- ë‘ ê°€ì¤‘ì¹˜ ë²¡í„°ì˜ í‰ê·  $1/2 *(W_1 + W_2^{T})$ ì˜ ì—´ ë²¡í„°\n\në§ˆì§€ë§‰ ê²½ìš°ëŠ” $1/2 * (W_1^{T} + W_2)$ì˜ í–‰ ë²¡í„°ì™€ ê°™ë‹¤. ìœ„ì˜ ëª¨ë“  ê²½ìš°ì— ëŒ€í•´ `í•œê°œì˜ ë‹¨ì–´ ì„ë² ë”© ë²¡í„°ì˜ í¬ê¸°`ëŠ” ì„ë² ë”© í¬ê¸° $N$ì— ëŒ€í•´ $(N,1)$ ë˜ëŠ” $(1, N)$ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\n\n## 5. ëª¨ë¸ í‰ê°€í•˜ê¸°\nëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ì—ëŠ” í¬ê²Œ ë‘ê°€ì§€ê°€ ìˆë‹¤.\n### ğŸ“–  ë‚´ì¬ì  í‰ê°€ì™€ ì™¸ì¬ì  í‰ê°€\në‚´ì¬ì  í‰ê°€(Intrinsic Evaluation)ëŠ” ì„ë² ë”©ëœ ë‹¨ì–´ë“¤ì˜ ì˜ë¯¸ë¡ ì ì´ê³  ë¬¸ë²•ë¡ ì ì¸ ê´€ê³„ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì´ë‹¤. ìœ ì˜ì–´(Analogies) í‰ê°€ë‚˜ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜, ë˜ëŠ” PCA ê°™ì€ ì‹œê°í™” ê¸°ë²•ë“¤ì´ ë‚´ì¬ì  í‰ê°€ì— í¬í•¨ëœë‹¤. ë°˜ë©´ ì™¸ì¬ì  í‰ê°€(Extrinsic Evaluation)ëŠ” ëª¨ë¸ì˜ ì „ì²´ì ì¸ ì„±ëŠ¥ì„ íŒŒì•…í•˜ëŠ”ë°ì— ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì´ë‹¤. ì „ì²´ ëª¨ë¸ì„ í‰ê°€í•  ìˆ˜ ìˆì§€ë§Œ, í‰ê°€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë©° ê°œì„  ë°©ë²•ì— ëŒ€í•œ ì§ê´€ì„ ì–»ê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.\n\n### ğŸ“‚  í…ŒìŠ¤íŠ¸ ì…‹ì— ëŒ€í•´ (ë‚´ì¬ì ìœ¼ë¡œ) í‰ê°€í•˜ê¸°\n![](Semantic-Syntactic_Word_Relationship_test_set.png)\n*table from Mikolov et al., 2013, Efficient Estimation of Word Representations in Vector Space*\n\nìœ„ì˜ í‘œëŠ” 4ê°œì˜ ëª¨ë¸ì„ ë‘ê°€ì§€ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ í‰ê°€í•œ ê²°ê³¼ì´ë‹¤. ì²«ë²ˆì§¸ í›ˆë ¨ ë°ì´í„°ëŠ” `ì˜ë¯¸ë¡ ì (semantic)`ì´ê³  `ë¬¸ë²•ë¡ ì (syntactic)` ê´€ê³„ ì •í™•ë„ì¸ë°, CBOWê°€ ì˜ë¯¸ë¡ ì  ì •í™•ë„ëŠ” Skip-gramë³´ë‹¤ ë‘ë°° ì´ìƒ ë–¨ì–´ì§€ì§€ë§Œ ë¬¸ë²•ì  ì •í™•ë„ì—ì„œëŠ” ì¡°ê¸ˆ ë” ë‚˜ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ê·¸ë ‡ì§€ë§Œ ì˜ë¯¸ë¡ ì  ì •í™•ë„ì— ë¹„í•´ ë¬¸ë²•ë¡ ì  ì •í™•ë„ì—ì„œ í‰ê°€ ëª¨ë¸ë“¤ì˜ í¸ì°¨ê°€ ë” ì ì—ˆë‹¤. ë‘ë²ˆì§¸ ë°ì´í„° ì…‹ì— ëŒ€í•´ì„œëŠ” CBOWê°€ Skip-gramë³´ë‹¤ ë‹¨ì–´ ê´€ê³„ í‰ê°€ê°€ ì¡°ê¸ˆ ë” ë‚˜ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.\n\n_ì°¸ê³  : ë…¼ë¬¸ì—ì„œëŠ” 1ì–µê°œê°€ ë„˜ì–´ê°€ì§€ ì•ŠëŠ” vocabì— ëŒ€í•´ CBOW ëª¨ë¸ì„ í›ˆë ¨í–ˆìœ¼ë©°, $C=4$ ì„¤ì •ì—ì„œ log-linear ë¶„ë¥˜ë¡œ ìµœì ì˜ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤ê³  í•œë‹¤._\n\n\n## ì¶œì²˜\n1. Mikolov et al., 2013, Efficient Estimation of Word Representations in Vector Space\n2. Coursera, deeplearning.ai, NLP Specialization, Course 2, Natural Language Processing with Probabilistic Models","excerpt":"ì€ 2013ë…„ êµ¬ê¸€ì—ì„œ ê³ ì•ˆí•œ ìì—°ì–´ ì²˜ë¦¬ ì•„ì´ë””ì–´ë¡œ, ì´ì— ê¸°ë°˜í•œ ëª¨ë¸ì€ ì™€  ë‘ê°€ì§€ê°€ ìˆë‹¤. ì´ ê¸€ì€ ê·¸ ì¤‘ì—ì„œ  ëª¨ë¸ì„ ì› ë…¼ë¬¸ê³¼ deeplearning.ai ìˆ˜ì—…ì„ ì°¸ê³ í•˜ì—¬ ì •ë¦¬í•œ ê¸€ì´ë‹¤.  ì› ë…¼ë¬¸: Mikolov et. al., 2013,â€¦","fields":{"slug":"/word2vec_cbow/"},"frontmatter":{"date":"Feb 25, 2022","title":"word2vec - Continuous Bag-of-Words(CBOW)","tags":["NLP","word2vec","Word Embedding"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/42861)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n`ë‘ ì§€ì  ì‚¬ì´`ì— ëŒ€í•´ ê±´ì„¤ ë¹„ìš©ì´ ì‘ì€ ê²ƒë¶€í„° ê±´ì„¤í•˜ë©´ ì „ì²´ ê±´ì„¤ ë¹„ìš©ì´ ê°€ì¥ ì‘ë„ë¡ ì„ íƒí•  ìˆ˜ ìˆë‹¤. ë§Œì•½ ë‘ ì§€ì  ì‚¬ì´ì˜ ê±´ì„¤ ë¹„ìš©ì´ ì•„ë‹ˆë¼ ë¶€ë¶„ ê·¸ë˜í”„ì˜ ê±´ì„¤ ë¹„ìš©ì´ ì£¼ì–´ì¡Œë‹¤ë©´ ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ì—†ë‹¤.\n\n#### ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„:\n- ê±´ì„¤ ë¹„ìš©ì„ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë¯€ë¡œ ê±´ì„¤ ë¹„ìš©ì´ ì €ë ´í•œ ë‹¤ë¦¬ ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ ê±´ì„¤í•œë‹¤.\n- ë‹¨, ë‹¤ë¦¬ì˜ ì–‘ìª½ ì§€ì ì´ ì´ë¯¸ ì—°ê²°ëœ ê²½ìš°ì—ëŠ” ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.\n- ëª¨ë“  ì„¬ì´ ì—°ê²°ë  ë•Œê¹Œì§€ ë‹¤ë¦¬ë¥¼ ì¶”ê°€í•œë‹¤.\n\n\nê·¸ë˜í”„ì˜ ëª¨ë“  ë…¸ë“œì— ëŒ€í•´ ì¶”ê°€í•œ ê²½ë¡œì— ì†í•˜ëŠ” ë…¸ë“œê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ê¹Šì´ ìš°ì„  íƒìƒ‰ì„ êµ¬í•œí˜„ë‹¤.\n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom collections import defaultdict\n\ndef solution(n, costs):\n    cost = 0\n    nodes = list(range(n))\n    graph = defaultdict(list)\n    # ê±´ì„¤ ë¹„ìš©ì´ ì €ë ´í•œ ìˆœìœ¼ë¡œ ë‹¤ë¦¬ë¥¼ ì •ë ¬í•œë‹¤.\n    costs.sort(key=lambda x: x[2])\n    \n    for i in range(len(costs)):\n        # ë‹¤ë¦¬ì˜ ì–‘ìª½ ì§€ì ì´ ì´ë¯¸ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©´ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.\n        node1, node2 = costs[i][:2]\n        if connected(node1, node2, graph):\n            continue\n            \n        # ì–‘ìª½ ì§€ì ì´ ì—°ê²° ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë‹¤ë¦¬ë¥¼ ê±´ì„¤í•œë‹¤.\n        cost += costs[i][2]\n        graph[node1].append(node2)\n        graph[node2].append(node1)\n        \n        # ëª¨ë“  ë…¸ë“œ nodeê°€ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©´ ë©ˆì¶˜ë‹¤. \n        flag = True\n        for node in nodes:\n            if not connected(node1, node, graph):\n                flag = False\n        if flag:\n            break\n    return cost\n\n# graphì— ìˆëŠ” rootì™€ target ë…¸ë“œì˜ ì—°ê²° ì—¬ë¶€ë¥¼ ë°˜í™˜í•œë‹¤.\n# DFS(ê¹Šì´ ìš°ì„  íƒìƒ‰)ìœ¼ë¡œ êµ¬í˜„í•œë‹¤.\ndef connected(root, target, graph):\n    if root == target: \n        return True\n    visited = []\n    stack = [root]\n    while stack:\n        v = stack.pop()\n        if v == target: return True\n        if v not in visited:\n            visited.append(v)\n            for u in graph[v]:\n                stack.append(u)\n    return False\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ì— ëŒ€í•´ ê±´ì„¤ ë¹„ìš©ì´ ì‘ì€ ê²ƒë¶€í„° ê±´ì„¤í•˜ë©´ ì „ì²´ ê±´ì„¤ ë¹„ìš©ì´ ê°€ì¥ ì‘ë„ë¡ ì„ íƒí•  ìˆ˜ ìˆë‹¤. ë§Œì•½ ë‘ ì§€ì  ì‚¬ì´ì˜ ê±´ì„¤ ë¹„ìš©ì´ ì•„ë‹ˆë¼ ë¶€ë¶„ ê·¸ë˜í”„ì˜ ê±´ì„¤ ë¹„ìš©ì´ ì£¼ì–´ì¡Œë‹¤ë©´ ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ì—†ë‹¤. â€¦","fields":{"slug":"/programmers. á„‰á…¥á†· á„‹á…§á†«á„€á…§á†¯á„’á…¡á„€á…µ/"},"frontmatter":{"date":"Feb 11, 2022","title":"programmers. ì„¬ ì—°ê²°í•˜ê¸°","tags":["Algorithms","programmers","Greedy Algorithm","Graph","DFS"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/68646)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- íˆ¬ í¬ì¸í„° ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²° í•  ìˆ˜ ìˆë‹¤.\n\n1. ë°°ì—´ì˜ ì„ì˜ì˜ ì›ì†Œ a[i]ì— ëŒ€í•´ ì™¼ìª½ ì›ì†Œê°’ a[i-1]ê³¼ ì˜¤ë¥¸ìª½ ì›ì†Œê°’ a[i+1]ì´ ëª¨ë‘ a[i]ë³´ë‹¤ ì‘ì€ ê²½ìš° ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ì„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œì™¸í•œë‹¤. \n2. ìŠ¤íƒì— ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ì„ ì›ì†Œê°’ë“¤ì„ ì €ì¥í•œë‹¤. ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•œì¹¸ ë‚˜ì•„ê°ˆ ë•Œ ë§ˆë‹¤ ìŠ¤íƒì— ì €ì¥í•œ ì›ì†Œì™€ ë°°ì—´ aì˜ ë‚¨ì€ ì›ì†Œë“¤ì— ëŒ€í•´ 1ë²ˆì„ ê²€ì‚¬í•œë‹¤.\n3. ìŠ¤íƒì˜ ê¸¸ì´ë¥¼ ë°˜í™˜í•œë‹¤.\n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\ndef solution(a):\n\n    # ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ëŠ”ë‹¤ê³  íŒë‹¨í•œ í’ì„ ë“¤ì˜ ê°’ì„ ì €ì¥í•˜ëŠ” ìŠ¤íƒ\n    stack = [a[0]]\n    i = 1\n\n    while i < len(a) - 1:\n        # a[i] ê°’ì´ a[i-1]ê³¼ a[i-2]ë³´ë‹¤ í¬ë‹¤ë©´ ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ì„ ìˆ˜ ì—†ë‹¤.\n        if stack[-1] < a[i] and a[i+1] < a[i]:\n            # íŒë‹¨í•œ í’ì„ ë“¤ì¸ stackì„ ì˜¤ë¥¸ìª½ë¶€í„° ê²€ì‚¬\n            while len(stack) > 1 and stack[-2] < stack[-1] and a[i+1] < stack[-1]:\n                stack.pop()\n        # ì´ì™¸ì˜ ê²½ìš° ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ stackì— ì €ì¥\n        else:\n            stack.append(a[i])\n        # í•œ ì¹¸ ì˜¤ë¥¸ìª½ ê°’ë“¤ì— ëŒ€í•´ ê²€ì‚¬\n        i += 1\n    \n    # ê°€ì¥ ì˜¤ë¥¸ìª½ í’ì„ ì€ ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ëŠ”ë‹¤.\n    if a[-1] != stack[-1]:\n        stack.append(a[-1])\n\n    return len(stack)\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ íˆ¬ í¬ì¸í„° ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²° í•  ìˆ˜ ìˆë‹¤. ë°°ì—´ì˜ ì„ì˜ì˜ ì›ì†Œ aiì— ëŒ€í•´ ì™¼ìª½ ì›ì†Œê°’ ai-1ê³¼ ì˜¤ë¥¸ìª½ ì›ì†Œê°’ ai+1ì´ ëª¨ë‘ aië³´ë‹¤ ì‘ì€ ê²½ìš° ë§ˆì§€ë§‰ê¹Œì§€ ë‚¨ì„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œì™¸í•œë‹¤.  ìŠ¤íƒì— ë§ˆì§€â€¦","fields":{"slug":"/programmers. á„‘á…®á†¼á„‰á…¥á†« á„á…¥á„„á…³á„…á…µá„€á…µ/"},"frontmatter":{"date":"Feb 11, 2022","title":"programmers. í’ì„  í„°ëœ¨ë¦¬ê¸°","tags":["Algorithms","programmers","Two Pointer Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/64062)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ë¬¸ì œëŠ” k ê¸¸ì´ì˜ êµ¬ê°„(ë˜ëŠ” window) ìµœëŒ€ê°’ ì¤‘ ìµœì†Œê°’ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¡œ ì´í•´ë  ìˆ˜ ìˆë‹¤.\n\n- stones ë°°ì—´ì˜ ê¸¸ì´ê°€ nì´ë¼ í•  ë•Œ, max()í•¨ìˆ˜ë¡œ ìµœëŒ€ê°’ì„ êµ¬í•˜ëŠ”ë°ì— ì„ í˜• ì‹œê°„ì´ ì†Œìš”ë˜ë¯€ë¡œ max()í•¨ìˆ˜ë¡œ êµ¬í˜„ì‹œ ì „ì²´ ì‹œê°„ ë³µì¡ë„ëŠ” $O(k * (n - k))$ ì´ë‹¤. nê³¼ këŠ” ìµœëŒ€ 20,000ì´ë¯€ë¡œ kê°€ 10,000ì¼ ë•Œ ì—°ì‚° íšŸìˆ˜ëŠ” 100,000,000íšŒì´ê¸° ë•Œë¬¸ì— ì´ ë°©ë²•ìœ¼ë¡œëŠ” ì‹œê°„ë‚´ì— ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ì—†ë‹¤.\n\n- êµ¬ê°„ì˜ ìµœëŒ€ê°’ì„ êµ¬í•  ë•Œ kê°œì˜ êµ¬ê°„ì´ ì¤‘ë³µë˜ë¯€ë¡œ ìµœëŒ€ í™ìœ¼ë¡œ ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤. \n- $[0, k)$êµ¬ê°„ì˜ ì›ì†Œë¥¼ í™ìœ¼ë¡œ ì •ë ¬í•œ ë’¤, ë‹¤ìŒ êµ¬ê°„ì— ì¶”ê°€ë˜ëŠ” ì›ì†Œë¥¼ í•˜ë‚˜ì”© pushí•˜ë©°, ë§¤ë²ˆ í™ì˜ ìµœëŒ€ê°’ì„ ì—…ë°ì´íŠ¸ í•œë‹¤. ì´ë•Œ, í™ì˜ ìµœëŒ€ ì›ì†Œì˜ ì¸ë±ìŠ¤ê°€ êµ¬ê°„ ì™¸ì´ë©´ popí•œë‹¤.\n\n- í™ì— nê°œì˜ ì›ì†Œë¥¼ í•œë²ˆ ì”© pushí•˜ê³ , í™ì˜ ìµœëŒ€ê°’ì´ êµ¬ê°„ ì™¸ì¼ ë•Œë§Œ popí•œë‹¤. í™ì—ëŠ” ìµœì†Œ kê°œì˜ ì›ì†Œê°€ ë‚¨ì•„ìˆì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— popì€ ìµœëŒ€ $n-k$ë²ˆ ì¼ì–´ë‚˜ëŠ”ë°, ì´ ìµœì•…ì˜ ê²½ìš°ì— ì´ì „ ì›ì†Œë“¤ì€ popì—†ì´ pushë˜ì—ˆê³ , ì´í›„ ì›ì†Œë“¤ë„ í™ì˜ ê¸¸ì´ kì—ì„œ ë‹¤ì‹œ ì‹œì‘í•˜ë¯€ë¡œ ì„ í˜•ì‹œê°„ì„ ë„˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ì „ì²´ ìˆ˜í–‰ì‹œê°„ì€ $O(nlogn)$ ì´ë‹¤.\n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\nfrom heapq import heappush, heappop\n\ndef solution(stones, k):\n\n    # kê°€ ì „ì²´ êµ¬ê°„ì¼ ë•Œ ì˜ˆì™¸ ì²˜ë¦¬\n    if len(stones) == k:\n        return max(stones)\n\n    # ìµœëŒ€ í™ êµ¬í˜„\n    hq = []\n    for i in range(0, k):\n        heappush(hq, (-stones[i], i))\n    k_maxes = [-hq[0][0]] # k ê¸¸ì´ êµ¬ê°„ì—ì„œì˜ ìµœëŒ€ê°’ ì €ì¥\n\n    # í™ì— ì›ì†Œë¥¼ í•˜ë‚˜ì”© ì—…ë°ì´íŠ¸ í•˜ë©´ì„œ \n    # ë§Œì•½ í™ì˜ ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ê°€ êµ¬ê°„ ì•ˆì— ìˆì§€ ì•Šìœ¼ë©´ í™ì—ì„œ ì œê±°í•œë‹¤.\n    for i in range(k, len(stones)):\n        heappush(hq, (-stones[i], i))\n        while hq[0][1] <= i - k:\n            heappop(hq)\n        k_maxes.append(-hq[0][0])\n        \n    return min(k_maxes) # ì €ì¥ëœ êµ¬ê°„ ìµœëŒ€ê°’ë“¤ ì¤‘ ìµœì†Œê°’ ë°˜í™˜\n```\n","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ë¬¸ì œëŠ” k ê¸¸ì´ì˜ êµ¬ê°„(ë˜ëŠ” window) ìµœëŒ€ê°’ ì¤‘ ìµœì†Œê°’ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¡œ ì´í•´ë  ìˆ˜ ìˆë‹¤. stones ë°°ì—´ì˜ ê¸¸ì´ê°€ nì´ë¼ í•  ë•Œ, max()í•¨ìˆ˜ë¡œ ìµœëŒ€ê°’ì„ êµ¬í•˜ëŠ”ë°ì— ì„ í˜• ì‹œê°„ì´ ì†Œìš”ë˜ë¯€ë¡œ max()í•¨â€¦","fields":{"slug":"/programmers. á„Œá…µá†¼á„€á…¥á†·á„ƒá…¡á„…á…µ á„€á…¥á†«á„‚á…¥á„€á…µ/"},"frontmatter":{"date":"Feb 10, 2022","title":"programmers. ì§•ê²€ë‹¤ë¦¬ ê±´ë„ˆê¸°","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/42898)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ê¸¸ ì°¾ê¸° ë¬¸ì œì´ë©° ë‹¤ì´ë‚˜ë¯¹ í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n- ì˜¤ë¥¸ìª½ê³¼ ì•„ë˜ìª½ìœ¼ë¡œë§Œ ê°ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì™¼ìª½ê³¼ ìœ„ìª½ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼í•œë‹¤. ìµœë‹¨ ê²½ë¡œì˜ ê°œìˆ˜ì´ë¯€ë¡œ ì™¼ìª½ê³¼ ìœ„ìª½ì˜ ê°’ì„ ë”í•˜ë©´ ëœë‹¤.\n- ë°°ì—´ ì´ˆê¸°í™”ë¥¼ 0ìœ¼ë¡œ í–ˆìœ¼ë¯€ë¡œ, puddleì— ëŒ€í•´ì„œ -1ë¡œ ê¸°ë¡í•´ ë‘ì—ˆë‹¤ê°€ í…Œì´ë¸”ì„ ì±„ìš¸ë•Œ ë§ˆì£¼ì¹˜ë©´ ë§ì…ˆì´ ë˜ì§€ ì•Šë„ë¡ 0ìœ¼ë¡œ ë°”ê¿”ë‘”ë‹¤.\n- ìˆ˜í–‰ì‹œê°„ì€ ì´ì¤‘ forë¬¸ìœ¼ë¡œ $O(N^2)$ì´ë‹¤.\n\n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\ndef solution(m, n, puddles):\n\n    # í–‰ n, ì—´ m í¬ê¸°ì˜ 2ì°¨ì› ë°°ì—´ ìƒì„±\n    # road[i][j]ëŠ” (1,1)ì—ì„œ (i,j)ê¹Œì§€ ê°ˆ ìˆ˜ ìˆëŠ” ìµœë‹¨ ê²½ë¡œì˜ ê°œìˆ˜\n    road = [[0 for _ in range(m+1)] for _ in range(n+1)]\n    road[1][1] = 1\n    \n    # puddleë¡œëŠ” ê°ˆ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ -1ë¡œ ì²˜ë¦¬\n    for puddle in puddles:\n        y, x = puddle\n        road[x][y] = -1\n    \n    # roadì˜ ëª¨ë“  ì§€ì ì„ íƒìƒ‰\n    for i in range(n):\n        for j in range(m):\n            # ì‹œì‘ ì§€ì ì€ 1ë¡œ ê³ ì •\n            if i == j == 1:\n                continue\n            # ë§Œì–‘ puddleì´ë©´, ë§ì…ˆì´ ë˜ì§€ ì•Šê²Œ 0ìœ¼ë¡œ ì¬ì²˜ë¦¬\n            if road[i][j] == -1:\n                road[i][j] = 0\n                continue\n            # ì™¼ìª½ê³¼ ìœ„ìª½ì—ì„œ ì˜¬ ìˆ˜ ìˆëŠ” ìµœë‹¨ ê²½ë¡œì˜ ê°œìˆ˜ì˜ í•©ì´ í˜„ì¬ ì§€ì ì˜ ìµœë‹¨ ê²½ë¡œ ê°œìˆ˜\n            road[i][j] = (road[i-1][j] + road[i][j-1]) % 1000000007\n\n    return road[-1][-1]\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ê¸¸ ì°¾ê¸° ë¬¸ì œì´ë©° ë‹¤ì´ë‚˜ë¯¹ í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤. ì˜¤ë¥¸ìª½ê³¼ ì•„ë˜ìª½ìœ¼ë¡œë§Œ ê°ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì™¼ìª½ê³¼ ìœ„ìª½ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼í•œë‹¤. ìµœë‹¨ ê²½ë¡œì˜ ê°œìˆ˜ì´ë¯€ë¡œ ì™¼ìª½ê³¼ ìœ„ìª½ì˜ ê°’ì„ ë”í•˜ë©´ ëœë‹¤. ë°°ì—´ ì´ˆê¸°í™”ë¥¼â€¦","fields":{"slug":"/programmers. á„ƒá…³á†¼á„€á…­á†ºá„€á…µá†¯/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. ë“±êµ£ê¸¸","tags":["Algorithms","programmers","Dynamic Programming"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/12905)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\në³´ë“œì˜ ê°€ë¡œ ì„¸ë¡œ ê¸¸ì´ê°€ ìµœëŒ€ 1,000ì´ë¯€ë¡œ ëª¨ë“  ë³´ë“œì˜ ì›ì†Œì— ëŒ€í•´ êµ¬ê°„ë³„ë¡œ íƒìƒ‰í•˜ë©´ ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ì‹œê°„ì„ ë§ì¶œ ìˆ˜ ì—†ë‹¤. ëŒ€ì‹  ë³´ë“œì˜ ì›ì†Œê°€ ëª¨ë‘ 1 ë˜ëŠ” 0ì´ë¼ëŠ” ê²ƒì„ ì´ìš©í•˜ì—¬ (ê¸¸ ì°¾ê¸° ì˜ˆì œì—ì„œ ìì£¼ êµ¬í˜„í•˜ëŠ” ê²ƒì²˜ëŸ¼) ë‹¤ì´ë‚´ë¯¹ í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤. \n- `board`ë¥¼ `ì˜¤ë¥¸ìª½`ê³¼ `ì•„ë˜ìª½`ìœ¼ë¡œ íƒìƒ‰í•´ê°€ë©´ì„œ,\n- `board[i][j] = 1`ì¸ ì§€ì ì—ì„œ ì™¼ìª½ìœ¼ë¡œ í•œì¹¸, ìœ„ìª½ìœ¼ë¡œ í•œì¹¸, ê·¸ë¦¬ê³  ëŒ€ê°ì„  ì™¼ìª½ ìœ„ë¡œ í•œì¹¸ ì´ë™í•œ ì§€ì ë“¤ì˜ ê°’ ì¤‘ ìµœì†Œì¸ ê°’ì— 1ì„ ë”í•œ ê°’ì„ ì €ì¥í•œë‹¤.\nì´ë•Œ ì„ì˜ì˜ x, yì— ëŒ€í•´ board[x][y]ëŠ” ì™¼ìª½ê³¼ ìœ„ìª½ìœ¼ë¡œ ì¸ì ‘í•´ ìˆëŠ” ì •ì‚¬ê°í˜•ì˜ ê¸¸ì´ë¥¼ ë°˜ì˜í•˜ê²Œ ë˜ë©° 1ì„ ë”í•¨ìœ¼ë¡œì„œ board[i][j]ì˜ ê¸¸ì´ë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆë‹¤.\n\nì˜ˆë¥¼ ë“¤ì–´ boardê°€ ê°€ë¡œ ì„¸ë¡œ 2ì¸ ì •ì‚¬ê°í˜•ì´ê³  board[1][1]=1ì¸ ê²½ìš°, board[0][0], board[0][1] ê·¸ë¦¬ê³  board[1][0] ì¤‘ í•œ ì›ì†Œë¼ë„ 0ì¸ ê²½ìš° board[1][1]=1ì´ê³  boardì˜ ê°€ì¥ ê¸´ ì •ì‚¬ê°í˜•ì˜ ê¸¸ì´ëŠ” 1ì´ë‹¤. ë°˜ë©´ì— ì„¸ ì›ì†Œê°€ ëª¨ë‘ 1ì¸ ê²½ìš° board[1][1]=2ë¡œ ìµœëŒ€ ì •ì‚¬ê°í˜•ì˜ ê¸¸ì´ëŠ” 2ë‹¤.\n\nì´ë•Œ, í–‰ê³¼ ì—´ì˜ ì²«ë²ˆì§¸ ì¸ë±ìŠ¤ì— ëŒ€í•´ì„œëŠ” ê³„ì‚°í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì˜ˆì™¸ì²˜ë¦¬ì— ì‹ ê²½ì“´ë‹¤.\n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\ndef solution(board):\n    \n    # board ê°€ë¡œ ì„¸ë¡œ ê¸¸ì´ê°€ 1ì¸ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬\n    if len(board) == 1 or len(board[0]) == 1:\n        if max(board) == 0:\n            return 0\n        else:\n            return 1\n        \n    answer = 0\n    for i in range(1, len(board)):\n        for j in range(1, len(board[0])):\n            # board[i][j] : ì™¼ìª½ê³¼ ìœ„ìª½ì˜ boardì— ëŒ€í•´ ì¸ì ‘í•œ ì •ì‚¬ê°í˜•ì˜ ìµœëŒ€ ê¸¸ì´\n            # ë”í•´ì§€ëŠ” 1ì€ board[i][j]ë¥¼ í¬í•¨í•´ ë”í•´ì§€ëŠ” ê¸¸ì´\n            if board[i][j] != 0:\n                board[i][j] = min(board[i-1][j], board[i][j-1], board[i-1][j-1]) + 1\n            answer = max(answer, board[i][j])\n\n    return answer ** 2\n````\n\nìœ„ì˜ ë°©ë²•ìœ¼ë¡œ êµ¬í˜„í•  ê²½ìš° ì´ì¤‘ forë¬¸ì— ì˜í•´ ìˆ˜í–‰ì‹œê°„ì€ $O(N^2)$ì´ë©°, ë”°ë¼ì„œ ë³´ë“œì˜ ê°€ë¡œ ì„¸ë¡œ ê¸¸ì´ê°€ 1,000ì´ë”ë¼ë„ ì‹œê°„ ì œí•œì„ í†µê³¼í•  ìˆ˜ ìˆë‹¤.\n\n\n","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ë³´ë“œì˜ ê°€ë¡œ ì„¸ë¡œ ê¸¸ì´ê°€ ìµœëŒ€ 1,000ì´ë¯€ë¡œ ëª¨ë“  ë³´ë“œì˜ ì›ì†Œì— ëŒ€í•´ êµ¬ê°„ë³„ë¡œ íƒìƒ‰í•˜ë©´ ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ì‹œê°„ì„ ë§ì¶œ ìˆ˜ ì—†ë‹¤. ëŒ€ì‹  ë³´ë“œì˜ ì›ì†Œê°€ ëª¨ë‘ 1 ë˜ëŠ” 0ì´ë¼ëŠ” ê²ƒì„ ì´ìš©í•˜ì—¬ (ê¸¸ ì°¾ê¸° ì˜ˆì œì—ì„œ â€¦","fields":{"slug":"/programmers. á„€á…¡á„Œá…¡á†¼ á„á…³á†« á„Œá…¥á†¼á„‰á…¡á„€á…¡á†¨á„’á…§á†¼ á„á…¡á†½á„€á…µ/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. ê°€ì¥ í° ì •ì‚¬ê°í˜• ì°¾ê¸°","tags":["Algorithms","programmers","Dynamic Programming"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/86052)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\nêµ¬í˜„ ë¬¸ì œì™€ ê·¸ë˜í”„ ì‚¬ì´í´ì— ëŒ€í•œ ë¬¸ì œê°€ í•©ì³ì ¸ ìˆë‹¤.\n\n1. êµ¬í˜„ ë¬¸ì œëŠ” ë¹›ì„ ì¢ŒíšŒì „, ìš°íšŒì „í•˜ëŠ” ê²ƒìœ¼ë¡œ, `delta = [(-1,0), (0,1), (1,0), (0,-1)]`ë¼ê³  í–ˆì„ ë•Œ ì¢ŒíšŒì „ì€ delta ë°°ì—´ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ í•œ ì¹¸ ì˜®ê¸°ëŠ” ê²ƒìœ¼ë¡œ, ìš°íšŒì „ì€ ì¸ë±ìŠ¤ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•œ ì¹¸ ì˜®ê¸°ëŠ” ê²ƒìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n\n2. gridì˜ ì„¸ë¡œê¸¸ì´ n, ê°€ë¡œ ê¸¸ì´ mì— ëŒ€í•´ ëª¨ë“  ì‚¬ì´í´ ê¸¸ì´ì˜ í•©ì€ $4 x n x m$ì´ë‹¤. ì¦‰ ëª¨ë“  ê°€ëŠ¥í•œ ì´ë™ì— ëŒ€í•´ ì‚¬ì´í´ì´ ì„±ë¦½í•œë‹¤.\n\n3. ê²©ìì—ì„œ ê°™ì€ ë…¸ë“œë¼ í•˜ë”ë¼ë„ ë¹›ì´ ì§€ë‚˜ê°€ëŠ” ë°©í–¥ì´ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì—¬ê²¨ì§„ë‹¤. ë”°ë¼ì„œ ëª¨ë“  ì§€ì ì— ëŒ€í•´ ì˜¤ë¥¸ìª½, ì™¼ìª½, ìœ„ìª½, ì•„ë˜ìª½ **4ê°œ ê²½ë¡œ**ë¥¼ í†µí•´ ë¹›ì´ **ë“¤ì–´ì˜¨** ê²½ë¡œë¥¼ ê¸°ë¡í•œë‹¤(ë‚˜ê°„ ê²½ë¡œë¥¼ ê¸°ë¡í•  ìˆ˜ë„ ìˆë‹¤). ë¹›ì´ ê°™ì€ ê²½ë¡œë¡œ ì§€ë‚˜ê°„ë‹¤ë©´ ê°™ì€ ì‚¬ì´í´ì´ ë˜ë¯€ë¡œ ì¤‘ë³µí•´ì„œ ì„¸ì§€ ì•Šê²Œ ì£¼ì˜í•œë‹¤.\n\nì¢…í•©í•´ë³´ë©´, ì„ì˜ì˜ ë…¸ë“œì— 4ê°œ ë°©í–¥ìœ¼ë¡œ ë¹›ì„ ì˜ë˜ í•´ë‹¹ ë…¸ë“œì— ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì˜ì•„ì§„ ë¹›ì´ ìˆëŠ” ê²½ìš°ëŠ” ì œì™¸í•œë‹¤. ê°™ì€ ê²½ë¡œë¡œ ëŒì•„ì˜¬ ë•Œê¹Œì§€ ê²½ë¡œë¥¼ ì´ë™í•˜ë©° ê¸°ë¡ì„ ë‚¨ê¸°ê³ , ì‚¬ì´í´ì´ ëë‚  ë•Œ ë§ˆë‹¤ ì‚¬ì´í´ì˜ ê¸¸ì´ë¥¼ ê¸°ë¡í•œë‹¤.\n\n2ë²ˆì— ì˜í•´ ì´ì¤‘ forë¬¸ ë‚´ì˜ ì—°ì‚°ì€ ëª¨ë“  i of n, j of mì— ëŒ€í•´ í•©í•´ì„œ $4 * n * m$ë²ˆì´ë‹¤. nê³¼ mì€ ìµœëŒ€ 500ì´ë¯€ë¡œ ì‹œê°„ ì œí•œì„ í†µê³¼í•  ìˆ˜ ìˆë‹¤.\n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\ndef solution(grid):\n\n    ret = []\n    n, m = len(grid), len(grid[0])\n    arr = [[[] for _ in range(m)] for _ in range(n)]\n    # ì¸ë±ìŠ¤ë¥¼ ëŠ˜ë¦¬ë©´ ì˜¤ë¥¸ìª½ìœ¼ë¡œ, ì¸ë±ìŠ¤ë¥¼ ì¤„ì´ë©´ ì™¼ìª½ìœ¼ë¡œ ì´ë™í•˜ë„ë¡ ë°°ì¹˜\n    delta = [(-1,0), (0,1), (1,0), (0,-1)]\n\n    # ëª¨ë“  ë…¸ë“œì— ëŒ€í•´ 4ê°€ì§€ ë°©í–¥ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì‚¬ì´í´ ê²€í† \n    for i in range(n):\n        for j in range(m):\n            for k in range(4):\n                # í•´ë‹¹ ë…¸ë“œì— ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ê¸°ë¡ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ\n                if k in arr[i][j]:\n                    continue\n\n                cnt = 0\n                x, y, d = i, j, k\n                dx, dy = delta[d]\n                # í•´ë‹¹ ë…¸ë“œì— ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ê¸°ë¡ì´ ì—†ì„ ë•Œê¹Œì§€ ê²½ë¡œ ì´ë™\n                while d not in arr[x][y]:\n                    arr[x][y].append(d)\n                    cnt += 1\n\n                    if grid[x][y] == 'L':\n                        dx, dy = delta[(d - 1) % 4]\n                    elif grid[x][y] == 'R':\n                        dx, dy = delta[(d + 1) % 4]\n\n                    x, y = (x + dx) % n, (y + dy) % m\n                    d = delta.index((dx, dy))\n                # ì‚¬ì´í´ì˜ ê¸¸ì´ë¥¼ ì €ì¥\n                ret.append(cnt)\n    return sorted(ret)\n```\n\n\n\n","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ êµ¬í˜„ ë¬¸ì œì™€ ê·¸ë˜í”„ ì‚¬ì´í´ì— ëŒ€í•œ ë¬¸ì œê°€ í•©ì³ì ¸ ìˆë‹¤. êµ¬í˜„ ë¬¸ì œëŠ” ë¹›ì„ ì¢ŒíšŒì „, ìš°íšŒì „í•˜ëŠ” ê²ƒìœ¼ë¡œ, ë¼ê³  í–ˆì„ ë•Œ ì¢ŒíšŒì „ì€ delta ë°°ì—´ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ì™¼ìª½ìœ¼ë¡œ í•œ ì¹¸ ì˜®ê¸°ëŠ” ê²ƒìœ¼ë¡œ, ìš°íšŒì „ì€ ì¸ë±ìŠ¤ë¥¼ ì˜¤ë¥¸â€¦","fields":{"slug":"/programmers. á„‡á…µá†¾á„‹á…´ á„€á…§á†¼á„…á…© á„‰á…¡á„‹á…µá„á…³á†¯/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. ë¹›ì˜ ê²½ë¡œ ì‚¬ì´í´","tags":["Algorithms","programmers","Implementation","Graph","Cyclic Graph"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/42895)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ë‹¤ì´ë‚´ë¯¹ í”„ë¡œê·¸ë˜ë°ì„ í™œìš©í•˜ì—¬ í•´ê²° í•  ìˆ˜ ìˆë‹¤. \n- ìµœëŒ€ 8ë²ˆê¹Œì§€ Nì˜ íšŸìˆ˜ë¥¼ ì„¸ì–´ì•¼ í•˜ë¯€ë¡œ, DP í…Œì´ë¸”ì„ ê¸¸ì´ 8ì¸ 1ì°¨ì› ë°°ì—´ë¡œ ë§Œë“ ë‹¤.\n- DP í…Œì´ë¸” dp[i]ì— Nì„ ië²ˆ ì´ìš©í•´ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìˆ˜ì˜ ë°°ì—´ì„ ì €ì¥í•œë‹¤. dpí…Œì´ë¸”ì€ í…Œì´ë¸” ì¸ë±ìŠ¤ iì— ëŒ€í•´ Nì„ ië²ˆ ë°˜ë³µí•˜ëŠ” ìˆ˜ë¡œ ì´ˆê¸°í™”í•œë‹¤. \n- Nì„ ì‚¬ìš©í•˜ëŠ” íšŸìˆ˜ì˜ ìµœì†Œê°’ì„ ë°˜í™˜í•´ì•¼ í•˜ë¯€ë¡œ dpë¥¼ ì‘ì€ ìˆ˜ ë¶€í„° ì±„ì›Œë‚˜ê°„ë‹¤. dp[j]ì— ìˆëŠ” ì›ì†Œì— ëŒ€í•´ dp[i-j]ì— ìˆëŠ” ì›ì†Œë¥¼ ì—°ì‚°í•˜ë¯€ë¡œ, `dp[j] {ì‚¬ì¹™ì—°ì‚°} dp[i-j]`ëŠ” Nì„ ì´ $j + (i - j) = i$ë²ˆ ì‚¬ìš©í•œë‹¤.\n\n\n\n#### íŒŒì´ì¬ ì½”ë“œ\n```python\ndef solution(N, number):\n    \n    # dp[i] : Nì„ ië²ˆ ì´ìš©í•´ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìˆ˜ì˜ ë°°ì—´\n    # ì´ˆê¸°ê°’ì€ Nì„ ië²ˆ ì‚¬ìš©í•œ ìˆ˜ë¡œ ì •ì˜í•œë‹¤.\n    dp = [[]] + [[int(str(N) * i)] for i in range(1, 9)]\n\n    if [number] in dp:\n      return dp.index([number])\n\n    # dp[j] {ì‚¬ì¹™ì—°ì‚°} dp[i-j]ëŠ” Nì„ ì´ ië²ˆ ì‚¬ìš©í•œë‹¤.\n    for i in range(2, 9):\n        for j in range(1, i):\n          for a in dp[j]:\n            for b in dp[i-j]:\n                dp[i].append(a + b)\n                dp[i].append(a - b)\n                dp[i].append(a * b)\n                if b != 0: # 0ìœ¼ë¡œ ë‚˜ëˆ„ì§€ ì•Šë„ë¡ í•œë‹¤.\n                    dp[i].append(a // b)\n        # íƒìƒ‰ ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´ ì¤‘ë³µ ì œê±°í•œë‹¤.\n        dp[i] = list(set(dp[i]))\n        if number in dp[i]:\n            return i\n\n    return -1\n```\n","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ë‹¤ì´ë‚´ë¯¹ í”„ë¡œê·¸ë˜ë°ì„ í™œìš©í•˜ì—¬ í•´ê²° í•  ìˆ˜ ìˆë‹¤.  ìµœëŒ€ 8ë²ˆê¹Œì§€ Nì˜ íšŸìˆ˜ë¥¼ ì„¸ì–´ì•¼ í•˜ë¯€ë¡œ, DP í…Œì´ë¸”ì„ ê¸¸ì´ 8ì¸ 1ì°¨ì› ë°°ì—´ë¡œ ë§Œë“ ë‹¤. DP í…Œì´ë¸” dpiì— Nì„ ië²ˆ ì´ìš©í•´ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìˆ˜ì˜ ë°°ì—´ì„â€¦","fields":{"slug":"/programmers. Ná„‹á…³á„…á…© á„‘á…­á„’á…§á†«/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. Nìœ¼ë¡œ í‘œí˜„","tags":["Algorithms","programmers","Dynamic Programming"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> ë¬¸ì œ : [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤](https://programmers.co.kr/learn/courses/30/lessons/43164)\n\n\n### ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´\n- ê·¸ë˜í”„ì—ì„œ `ì£¼ì–´ì§„ ë¶€ë¶„ ê²½ë¡œë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ë„ë¡` ì „ì²´ ê²½ë¡œë¥¼ ë§Œë“ ë‹¤.\n- í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ìˆëŠ” ê²½ìš° ìŠ¤íƒì— ì €ì¥í•˜ê³  í‹°ì¼“ì„ ì‚¬ìš© ì²˜ë¦¬í•œë‹¤.\n- í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ì—†ëŠ” ê²½ìš° í•´ë‹¹ ìœ„ì¹˜ì—ëŠ” ë„ì°©ë§Œ ê°€ëŠ¥í•˜ë‹¤. í•´ë‹¹ ê³µí•­ì„ ìˆœì„œëŒ€ë¡œ ë°©ë¬¸ ê¸°ë¡í•˜ë©´ ê°€ëŠ¥í•œ ë°©ë¬¸ ìˆœì„œë¥¼ ì—­ìˆœìœ¼ë¡œ ë’¤ì§‘ì–´ ì €ì¥í•˜ëŠ” ê²ƒì´ ëœë‹¤.\n- ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ì—†ëŠ” ê²½ìš°ë¶€í„° ë°©ë¬¸ì²˜ë¦¬ë¥¼ í•˜ë¯€ë¡œ, ê¸°ë¡í•œ ìˆœì„œë¥¼ ì—­ìˆœìœ¼ë¡œ ì¶œë ¥í•œë‹¤. \n\n\n### íŒŒì´ì¬ ì½”ë“œ\n```python\ndef solution(tickets):\n\n    # í‹°ì¼“ì˜ ê²½ë¡œ ì •ë³´ë¥¼ í•´ì‹œë¡œ ì €ì¥í•œë‹¤.\n    routes = {}\n    for t in tickets:\n        routes[t[0]] = routes.get(t[0], []) + [t[1]]\n    \n    # stackì€ ì˜¤ë¥¸ìª½ì—ì„œë¶€í„° ì›ì†Œë¥¼ ì œê±°í•˜ë¯€ë¡œ\n    # ì•ŒíŒŒë²³ ìˆœì„œê°€ ì•ì„œëŠ” í‹°ì¼“ì„ ë¨¼ì € ì„ íƒí•˜ê¸° ìœ„í•´ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•œë‹¤.\n    for r in routes:\n        routes[r].sort(reverse=True)\n\n    # ICNì—ì„œ ì¶œë°œ\n    stack = [\"ICN\"]\n    path = []\n    while len(stack) > 0:\n        now = stack[-1]\n        # í˜„ì¬ ìœ„ì¹˜ nowì—ì„œ ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ì—†ìœ¼ë©´ ë°©ë¬¸í•œë‹¤.\n        if now not in routes or len(routes[now]) == 0:\n            path.append(stack.pop())\n        # nowì—ì„œ ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ìˆìœ¼ë©´ í‹°ì¼“ì˜ ë„ì°©ì§€ì ì„ stackì— ì €ì¥í•œë‹¤.\n        else:\n            stack.append(routes[now].pop())\n\n    # pathì— ì €ì¥ëœ ìˆœì„œì˜ ë°˜ëŒ€ë¡œ returní•œë‹¤.\n    return path[::-1]\n```","excerpt":"ë¬¸ì œ : í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ í•´ê²° ì•„ì´ë””ì–´ ê·¸ë˜í”„ì—ì„œ  ì „ì²´ ê²½ë¡œë¥¼ ë§Œë“ ë‹¤. í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ìˆëŠ” ê²½ìš° ìŠ¤íƒì— ì €ì¥í•˜ê³  í‹°ì¼“ì„ ì‚¬ìš© ì²˜ë¦¬í•œë‹¤. í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì¶œë°œí•˜ëŠ” í‹°ì¼“ì´ ì—†ëŠ” ê²½ìš° í•´ë‹¹ ìœ„ì¹˜ì—ëŠ” ë„ì°©ë§Œ ê°€ëŠ¥í•˜ë‹¤. í•´ë‹¹ ê³µí•­ì„ ìˆœì„œëŒ€ë¡œâ€¦","fields":{"slug":"/programmers. á„‹á…§á„’á…¢á†¼á„€á…§á†¼á„…á…©/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. ì—¬í–‰ê²½ë¡œ","tags":["Algorithms","programmers","Graph"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\në¶„ì‚° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œì¸ ê¹ƒ ëª…ë ¹ì–´(git commands)ë¥¼ ì‰½ê²Œ ë³¼ ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n\n\n## 0. ê¹ƒ í”„ë¡œì íŠ¸ì˜ ì„¸ ë‹¨ê³„\n* ì›Œí‚¹ íŠ¸ë¦¬ (working tree) : íŒŒì¼ì„ ìˆ˜ì •í•˜ëŠ” ê³µê°„ì´ë‹¤. ìŠ¤í…Œì´ì§•ì„ í†µí•´ ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ë¡œ ìˆ˜ì •ì‚¬í•­ì„ ë³´ë‚¸ë‹¤.\n* ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ (staging area) : ì»¤ë°‹ì„ ìœ„í•œ ì„ì‹œ ìŠ¤ëƒ…ìƒ·ì„ ì €ì¥í•˜ëŠ” ê³µê°„ì´ë‹¤. ì»¤ë°‹ì„ í†µí•´ ê¹ƒ ë¦¬í¬ì§€í† ë¦¬ë¡œ ìˆ˜ì •ì‚¬í•­ì„ ì „ë‹¬í•´ì„œ ì˜êµ¬ì ì¸ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.\n* ê¹ƒ ë¦¬í¬ì§€í† ë¦¬, ì¦‰ ê¹ƒ ë¥´í¬ (git repository) : ì»¤ë°‹ëœ ìŠ¤ëƒ…ìƒ·ì„ ëª¨ë‘ ë³´ê´€í•˜ê³  ìˆëŠ” ê³µê°„ì´ë‹¤. í•„ìš”ì— ë”°ë¼ì„œ ë²„ì „ì„ ë˜ëŒë¦¬ê±°ë‚˜ ë³€í™”í•´ì˜¨ ìˆ˜ì • ë‚´ì—­ì„ ì‚´í´ë³¼ ìˆ˜ ìˆë‹¤.\n\n\n## 1. ë°°ì‹œ ì‰˜ ëª…ë ¹ì–´ (Bash shell commands)\n* ë””ë ‰í† ë¦¬ .git ë‚´ ëª¨ë“  íŒŒì¼ ì¶œë ¥\n```bash\n# look inside a git directory\nls -l .git/\n```\n* ìˆ¨ê²¨ì§„ íŒŒì¼ì„ í¬í•¨í•´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜í•œ ëª¨ë“  íŒŒì¼ ì¶œë ¥\n```bash\n# list files with a dot (hidden files)\nls -la\n```\n* íŒŒì¼ file_name.py ìƒì„±í•˜ê¸°\n```bash\n# create a file\ntouch file_name.py\n```\n* atom ì—ë””í„°ë¡œ íŒŒì¼ file_name.py ì—´ê¸°\n```bash\n# open a file with atom editor\natom file_name.py\n```\n* íŒŒì¼ file_name.py ë‚´ìš© ì‰˜ì—ì„œ ë³´ê¸°\n```bash\n# lookup a file\ncat file_name.py\n```\n\n## 2. ì„¤ì • ëª…ë ¹ì–´ (Configuration commands)\n* ê¹ƒ í˜„ì¬ ì„¤ì • ì¶œë ¥í•˜ê¸° \n```bash\n# check current configuration\ngit config -l\n```\n* ê¹ƒì˜ ì´ë¦„, ì´ë©”ì¼ ì„¤ì • ë³€ê²½í•˜ê¸°\n```bash\n# change configuration\ngit config --global user.name \"user_name\"\ngit config --global user.email \"user_email\"\n```\n* ê¹ƒí—ˆë¸Œ í‚¤ë¥¼ 15ë¶„ ë™ì•ˆ ìºì‹œí•˜ê¸°\n```bash\n# cache github key for 15 minutes\ngit config --global credential.helper cache\n```\n\n## 3. ì»¤ë°‹ ëª…ë ¹ì–´ (Commit commands)\n* í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ìƒˆë¡œìš´ ê¹ƒ ë¥´í¬ ìƒì„±í•˜ê¸°\n```bash\n# initialize an empty git repository in current directory\ngit init\n```\n* í˜„ì¬ ì›Œí‚¹ íŠ¸ë¦¬ì˜ ì •ë³´ ì¶œë ¥í•˜ê¸°\n```bash\n# get information of current working tree\ngit status\n```\n\n### ì»¤ë°‹í•˜ê¸°\n* íŒŒì¼ file_name.pyë¥¼ ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ì— ì˜¬ë¦¬ê¸° (ì»¤ë°‹ ì¤€ë¹„)\n```bash\n# command git to track follwing file\ngit add file_name.py\n```\n* ì»¤ë°‹ ë©”ì‹œì§€ ì°½ì„ ì—´ë©° í˜„ì¬ ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ì— ìˆëŠ” ê²ƒì„ ì „ë¶€ ì»¤ë°‹í•˜ê¸°\n```bash\n# commit everything in current staging area\n# opens a text editor to enter a commit message\ngit commit\n```\n* ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì§€ ì•Šê³  ì»¤ë°‹í•˜ê¸°\n```bash\n# stage changes to tracked file & commit in one step\ngit commit -a\n```\n* ê°„ëµí•œ ì»¤ë°‹ ë©”ì‹œì§€ commit messageì™€ í•¨ê»˜ ì»¤ë°‹í•˜ê¸°\n```bash\n# stage & commit & enter message\ngit commit -a -m \"commit message\"\n```\n\n### ì»¤ë°‹ ì§„í–‰ìƒí™© ë³´ê¸°\n* ëª¨ë“  ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ì¶œë ¥í•˜ê¸°\n```bash\n# check history of all commits\ngit log\n```\n* ê° ì»¤ë°‹ì—ì„œ ìˆ˜ì •ëœ ì‚¬í•­ì„ ì¤„ ë³„ë¡œ ì¶œë ¥í•˜ê¸°\n```bash\n# show actual lines that changed in each commit\ngit log -p\n```\n* ì»¤ë°‹ì˜ í†µê³„ ì •ë³´ ì¶œë ¥í•˜ê¸°\n```bash\n# show statistics about the changes in the commit\ngit log --stat\n```\n* ì»¤ë°‹ì˜ ë¸Œëœì¹˜ íŠ¸ë¦¬ ì¶œë ¥í•˜ê¸°\n```bash\n# show commit branch tree\ngit log --graph --oneline --all\n```\n* ì»¤ë°‹ ì•„ì´ë”” commit_idì— í•´ë‹¹í•˜ëŠ” ì»¤ë°‹ ì •ë³´ ì¶œë ¥í•˜ê¸°\n```bash\n# show the information about the commit and associated petches\ngit show [commit_id]\n```\n* commit_ id1ê³¼ commit_ id2ì— í•´ë‹¹í•˜ëŠ” ë‘ ì»¤ë°‹ ë¹„êµí•˜ê¸°\n```bash\n# similar to Linux diff command\ngit diff [commit_id1] [commit_id2]\n```\n* ìŠ¤í…Œì´ì§• ë˜ì—ˆì§€ë§Œ ì»¤ë°‹ë˜ì§€ ì•Šì€ íŒŒì¼ ì¶œë ¥í•˜ê¸°\n```bash\n# alias to --cached, show all staged but not commited files\ngit diff --staged\n```\n* íŒŒì¼ file1.pyì˜ ì´ë¦„ì„ file2.pyë¡œ ë³€ê²½í•˜ê¸°\n```bash\n# rename file1 with file2\n# similar to Linux mv command\ngit mv [file1.py] [file2.py]\n```\n* íŒŒì¼ file_name.py ì‚­ì œí•˜ê¸°\n```bash\n# remove file_name.py from working space\n# similar to Linux rm command\ngit rm [file_name.py]\n```\n\n### ì»¤ë°‹ ë˜ëŒë¦¬ê¸°\n* HEADê°€ ê°€ë¦¬í‚¤ëŠ” ë¸Œëœì¹˜ê°€ commit_idë¥¼ ê°€ë¦¬í‚¤ê²Œ í•˜ê¸°\n```bash\n# resets the repo in the Index, the next snapshot to commit\ngit reset --soft [commit_id]\n```\n* HEAD ë¸Œëœì¹˜ë¥¼ ì´ë™í•˜ê³  ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ë¥¼ ë¦¬ì…‹í•˜ê¸°\n```bash\n# update Index to the snapshot that HEAD is pointing \ngit reset --mixed [commit_id]\n```\n* HEAD ë¸Œëœì¹˜ë¥¼ ì´ë™í•˜ê³  ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ì™€ ì›Œí‚¹ ë””ë ‰í† ë¦¬ë¥¼ ë¦¬ì…‹í•˜ê¸°\n```bash\n# update Index to the snapshot that HEAD is pointing \ngit reset --hard [commit_id]\n```\n* í˜„ì¬ ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ì— ìˆëŠ” ë‚´ìš©ì„ ì»¤ë°‹ ë‚´ìš©ìœ¼ë¡œ ë®ì–´ì“°ê¸°\n```bash\n# make changes to commits after-the-fact on local commits\ngit commit --amend\n```\n* íˆìŠ¤í† ë¦¬ë¥¼ ìœ ì§€í•œì±„ ìƒˆë¡œìš´ ì»¤ë°‹ìœ¼ë¡œ ì»¤ë°‹ commit_idë¡œ ë˜ëŒë¦¬ê¸°\n```bash\n# make a new commit which rolls back a previous commit\ngit revert HEAD/[commit_id]\n```\n\n\n## 4. ë¸Œëœì¹˜ ëª…ë ¹ì–´ (Branch commands)\n* ëª¨ë“  ë¸Œëœì¹˜ ì¶œë ¥í•˜ê¸°\n```bash\n# list all branches\ngit branch\n```\n* ì½ê¸° ì „ìš© ì›ê²© ë¸Œëœì¹˜ ì¶œë ¥í•˜ê¸°\n```bash\n# shows read-only remote branches\ngit branch -r\n```\n* ë¸Œëœì¹˜ branch_name ìƒì„±í•˜ê¸°\n```bash\n# creates the branch_name branch\ngit branch [branch_name]\n```\n* ë¸Œëœì¹˜ branch_nameìœ¼ë¡œ ì´ë™í•˜ê¸°\n```bash\n# switch to branch_name\ngit checkout [branch_name]\n```\n* ë¸Œëœì¹˜ branch_nameì„ ìƒì„±í•˜ê³  ê·¸ ë¸Œëœì¹˜ë¡œ ìœ„ì¹˜ ì´ë™í•˜ê¸°\n```bash\n# creates a new branch and switches to it\ngit checkout -b [branch_name]\n```\n* ë¸Œëœì¹˜ branch_name ì‚­ì œí•˜ê¸°\n```bash\n# deletes the branch branch_name\ngit branch -d [branch_name]\n```\n* ë¸Œëœì¹˜ branch_name ì‚­ì œ ê°•ì œí•˜ê¸°\n```bash\n# forcibly deletes the branch\ngit branch -D [branch_name]\n```\n* ë¸Œëœì¹˜ branch_nameì„ ë§ˆìŠ¤í„° ë¸Œëœì¹˜ë¡œ í•©ì¹˜ê¸°\n```bash\n# joins branches together to the master branch\ngit merge [branch_name]\n```\n* ë¸Œëœì¹˜ ì¶©ëŒ(merge conflicts)ì´ ë°œìƒí–ˆì„ ë•Œ, ë¨¸ì§€ ì·¨ì†Œí•˜ê¸°\n```bash\n# when merge conflicts, abort merge action\ngit merge --abort\n```\n\n\n## 5. ê¹ƒí—ˆë¸Œ ëª…ë ¹ì–´ (Github commands)\n\n* ë¡œì»¬ í™˜ê²½ì— URLë¡œ ì›ê²© ë¥´í¬ ë³µì œí•˜ê¸°\n```bash\n# clone a remote repository into a local workspace\ngit clone [URL] \n```\n* ë¡œì»¬ íŒŒì¼ì„ ì›ê²© ë¥´í¬ì— í‘¸ì‹œí•˜ê¸°\n```bash\n# push commits from local repo to a remote repo\ngit push\n```\n* ì›ê²© ë¥´í¬ì˜ ì»¤ë°‹ì„ ë¡œì»¬ í™˜ê²½ì— ë³„ë„ì˜ ë¸Œëœì¹˜ë¡œ ë³µì‚¬í•´ì˜¤ê¸°\n```bash\n# copy the commits done in the remote repository\ngit fetch\n```\n* ì›ê²© ë¥´í¬ì˜ ì»¤ë°‹ì„ ë¡œì»¬ í™˜ê²½ì˜ ë¸Œëœì¹˜ì™€ ë¨¸ì§€í•˜ê¸°\n```bash\n# fetch from remote & merge\ngit pull\n```\n* ì›ê²© ë¥´í¬ ì¶œë ¥í•˜ê¸°\n```bash\n# List remote repos\ngit remote\n```\n* ì›ê²© ë¥´í¬ URL ì¶œë ¥í•˜ê¸°\n```bash\n# show URL of remote repo\ngit remote -v\n```\n* ì›ê²© ë¥´í¬ remote_name ì •ë³´ ì¶œë ¥í•˜ê¸°\n```bash\n# Describes a single remote repo\ngit remote show [remote_URL]\n```\n* ì›ê²© ë¥´í¬ì˜ ì—…ë°ì´íŠ¸ë¥¼ ë¡œì»¬ í™˜ê²½ì— ë¶ˆëŸ¬ì˜¤ê¸°\n```bash\n# Fetches the most up-to-date objects\ngit remote update\n```\n* ë¡œì»¬ ë¥´í¬ê°€ ì—°ê²°ëœ ì›ê²© ë¥´í¬ new-urlë¡œ ì´ì „í•˜ê¸°\n```bash\n# transfer a repository from origin to [new-url]\ngit remote set-url origin [new-url]\n```\n* ë¸Œëœì¹˜ branch_nameì˜ ë² ì´ìŠ¤ ì»¤ë°‹ì„ ë°”ê¾¸ê¸°\n```bash\n# change the base commit used for the branch [branch_name]\ngit rebase [branch_name]\n```\n\n\n\n## ë” ì°¸ê³ í•  ìë£Œ\n1. Git Docs ([link](https://git-scm.com/doc))\n2. GitHub Docs ([link](https://docs.github.com/en))\n3. Coursera, Google, Introduction to Git and Github ([link](https://www.coursera.org/learn/introduction-git-github))\n","excerpt":"ë¶„ì‚° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œì¸ ê¹ƒ ëª…ë ¹ì–´(git commands)ë¥¼ ì‰½ê²Œ ë³¼ ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤. 0. ê¹ƒ í”„ë¡œì íŠ¸ì˜ ì„¸ ë‹¨ê³„ ì›Œí‚¹ íŠ¸ë¦¬ (working tree) : íŒŒì¼ì„ ìˆ˜ì •í•˜ëŠ” ê³µê°„ì´ë‹¤. ìŠ¤í…Œì´ì§•ì„ í†µí•´ ìŠ¤í…Œì´ì§• ì—ë¦¬ì–´ë¡œ ìˆ˜ì •ì‚¬í•­ì„ ë³´ë‚¸ë‹¤â€¦","fields":{"slug":"/git_cheat_sheet/"},"frontmatter":{"date":"Feb 04, 2022","title":"ê¹ƒ ì¹˜íŠ¸ ì‹œíŠ¸ (Git Cheat Sheet)","tags":["Git"],"update":"Mar 01, 2022"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}